%% need no \usepackage{Sweave.sty}
<<setup,cache=FALSE,include=FALSE>>=
source("setup.R")
@


\section[Individual case reports]{\code{twinstim}: individual case reports} \label{sec:twinstim}


  \begin{itemize}
  \item Permutation test to evaluate importance of epidemic component
    
  \item variables are allowed to appear in both components.
    no issues with coefficient correlation
    
  \end{itemize}

  
\subsection{Data I/O}



\subsection{Visualization}
  
  
  


\subsection{Computational issues with the spatial kernel}



\subsubsection{Numerical integration}
\label{twinstim:polyCub}

Evaluation of both the log-likelihood and the score function involves solution
of the spatial integrals
\[
\iint_{\bm{W}-\bm{s}_j} f_{2D}(\bm{s}) \,d\bm{s} =
\iint_{\bm{W}-\bm{s}_j} f(\norm{\bm{s}}) \,d\bm{s}
\]
of the interaction kernel over translated versions of the observation region
$\bm{W}$ with origin at the events' locations.
The score function
further requires the integral of the partial derivatives
$\frac{\partial f(\norm{\bm{s}})}{\partial \tilde{\sigma}}$ and
$\frac{\partial f(\norm{\bm{s}})}{\partial \tilde{d}}$ over these polygonal
domains.
The spatial integrations are only trivial for constant $f$ but otherwise
require some cubature method.

For the previously used Gaussian kernel, the two-dimensional midpoint rule was
found to be best suited if combined with an adaptive choice of the bandwidth
depending on the (current) value of the kernel's standard deviation $\sigma$.
However, this is not appropriate for the power law kernel, which results in
rather ``spiky hills'' to integrate and which would require a very small
bandwidth (high number of cubature nodes) to obtain enough accuracy.
Furthermore, a trick was used for the Gaussian kernel, in case a
$6\sigma$ (i.e., very high quantile) circle around $\bm{s}_j$ lay completely
inside $\bm{W}$. Then, the spatial integral was approximated by the integral
over this circular domain only, which is available analytically for the
Gaussian density via the $\chi^2$ distribution
\citep[Formula 26.3.24]{Abramowitz.Stegun1972}.
Although analytical integration
over circular domains is also possible for the power-law kernels (see
Appendix \ref{appendix:twinstim:Fcircle}),
it is not directly applicable since power
laws feature a heavy tail and thus very large quantiles such that a 99.9\%
circle would rarely fall completely inside $\bm{W}$. This trick was only used to
get initial parameter estimates by truncating the spatial interaction function
at 200 km (runtime ??? minutes, compared to
??? seconds for the previous model with
Gaussian $f$), but for the 
final model integration over the whole of $\bm{W}$ has to be performed for all
observations (runtime ??? minutes)
to capture occasional long-range transmissions
enabled by the power law. Therefore, a more sophisticated cubature method is
needed.

\citet{sommariva.vianello2007} proposed a cubature rule over
polygonal domains which is exact for all bivariate polynomials up to a
degree $2n-1$. The number of required cubature nodes depends on the specific
shape of the polygon, but is bounded above by $Ln(n+1)$ with $L$ being the
number of vertices. Their cubature rule actually incorporates appropriately
transformed weights and nodes of one-dimensional Gauss-Legendre quadrature
in both dimensions (with $n$ and $n+1$ nodes, respectively),
thus the name ``product Gauss cubature''. 
%Let $\Pi$ denote an arbitrary polygon with vertices $V_1,\dots,V_L$ (and $V_{L+1} := V_1$).
The method is briefly illustrated in \citet[Section 3.2.5]{meyer2009}
and available either in its original \proglang{MATLAB} implementation by
\citet{sommariva.vianello2007:code}
or as an \proglang{R} port in package \pkg{polyCub} \citep{R:polyCub}.

Benchmark experiments of the product Gauss cubature are conducted for both
$f_{2D}(\bm{s})$ and its partial derivatives prior to optimisation to 
determine the required number of cubature nodes.
For the Lomax kernel, $n=40$ has been used for all three functions, whereas
$n=60$ was necessary for the lagged power law.
The cubature method additionally
requires the setting of a ``baseline'' in the first dimension, which was chosen
as the abscissa of the absolute maximum of the respective function $f(x)$,
$\frac{\partial f(x)}{\partial \tilde{\sigma}}$ or
$\frac{\partial f(x)}{\partial \tilde{d}}$ to have more nodes in that region.
%% An additional coordinate rotation proposed by \citet{sommariva.vianello2007}
%% would guarantee that all nodes fall inside the polygon at least for convex
%% polygons; however, this is no requirement for the integrands in question and in
%% our setting the potential gain in precision was small and did not justify
%% increased computational cost. \marginnote{clarify}
Convergence of the log-likelihood
optimisation can finally be verified by rerunning optimisation with a higher
number of nodes using the estimates from the previous fit as initial values.







\subsubsection{Numerical integration over circular domains}
\label{twinstim:Fcircle}


The integration of the isotropic ``hill'' $f_{2D}(\bm{s})$ over a circular
domain can be solved by cutting the hill into circular
slices from the bottom to the top and integrating the area of these slices along
the height, i.e.
\[
\int_{b(\bm{0},r)} f_{2D}(\bm{s}) \,d\bm{s} = \pi r^2 f(r) + \int_{f(r)}^{f(0)}
\pi [f^{-1}(z)]^2 \,dz 
\]
The first term corresponds to the basement plateau of radius $r$ and height
$f(r)$, whereas the integrand of the second term corresponds to the area of the
circular slice at height $z$.
Note that $f^{-1}$ exists since $f$ is strictly decreasing, for instance the
Lomax kernel \eqref{eqn:siaf.powerlaw} has the inverse
$f^{-1}(z) = z^{-\frac{1}{d}} - \sigma$ for $z > 0$.
Simple calculus yields
\[
\int \left(f^{-1}(z)\right)^2 \,dz =
\begin{cases}
  \log(z) - 4 \sigma \sqrt{z} + \sigma^2 z & \text{, if } d = 2,\\
  -z^{-1} - 2 \sigma \log(z) + \sigma^2 z & \text{, if } d = 1,\\
z^{\frac{d-2}{d}} \frac{d}{d-2} -
2 \sigma z^{\frac{d-1}{d}} \frac{d}{d-1} + \sigma^2 z & \text{, otherwise.}
\end{cases}
\]

A similar formula can also be derived for the lagged power law
\eqref{eqn:siaf.powerlawL}. For $r < \sigma$, integration is trivial since the
integrand is just constantly 1 in this domain; otherwise, integration works as
above via the inverse of the power-law part $f_L^{-1}(z) = \sigma z^{-\frac{1}{d}}$
for $z \in (0;1]$ and
\[
\int_{f(r)}^{f(0)} \left(f_L^{-1}(z)\right)^2 \,dz =
\sigma^2 \int_{f(r)}^1 z^{-\frac{2}{d}} \,dz = 
\sigma^2 \cdot \begin{cases}
  -d \log\left( \frac{\sigma}{r} \right) & \text{, if } d = 2,\\
  \frac{d}{d-2} \left[ 1 - \left(\frac{\sigma}{r}\right)^{d-2} \right] & \text{, otherwise.}
\end{cases}
\]




\subsection{Simulation}
\label{twinstim:simulation}

To simulate epidemics from (fitted) \code{twinstim}'s, an
algorithm which returns random points drawn proportional to the spatial
interaction function $f_{2D}(\bm{s})$ is additionally required.
In this specific case, it is convenient to switch to polar coordinates
$(r,\theta)$, which have a density proportional to
$r \cdot f_{2D}((r \cos(\theta), r \sin(\theta))^\top) = r \cdot f(r)$ (independent
of the angle $\theta$ since it is an isotropic kernel). The angle is drawn
uniformly in $[0,2\pi)$ and $r$ can be sampled by the inversion method with
two pitfalls: firstly, the density is improper on $\IR_0^+$ for $d \le 2$
but we only need to sample in the truncated domain $[0,\delta]$, and secondly,
the quantile function is not accessible in closed form such that numeric root
finding is used.
