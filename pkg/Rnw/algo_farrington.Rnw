
%anscombe


\name{anscombe.residuals}
\alias{anscombe.residuals}
\encoding{latin1}

\title{Compute Anscombe residuals}
\description{
  The residuals of \code{m} are transformed to form Anscombe residuals.
  which makes them approximately standard normal distributed.
}
\usage{
anscombe.residuals(m, phi)
}
\arguments{
  \item{m}{\code{m} is a glm object of the fit }
  \item{phi}{\code{phi} is the current estimated over-dispersion}
}
\value{Standardized Anscombe residuals of \code{m}}
\references{McCullagh & Nelder, Generalized Linear Models, 1989}
\keyword{}

<<echo=F>>=
anscombe.residuals <- function(m,phi) {
  y <- m$y
  mu <- fitted.values(m)
  
  #Compute raw Anscombe residuals
  a <- 3/2*(y^(2/3) * mu^(-1/6) - mu^(1/2))
  #Compute standardized residuals
  a <- a/sqrt(phi * (1-hatvalues(m)))
  return(a)
}
@ 


%algo.farrington.assign.weights


\name{algo.farrington.assign.weights}
\alias{algo.farrington.assign.weights}
\encoding{latin1}

\title{Assign weights to base counts}
\description{
  Weights are assigned according to the Anscombe residuals
}
\usage{
algo.farrington.assign.weights(s)
}
\arguments{
  \item{s}{Vector of standardized Anscombe residuals}
}
\value{Weights according to the residuals}
\seealso{See Also as \code{\link{anscombe.residuals}}}
\keyword{}

<<echo=F>>=
algo.farrington.assign.weights <- function(s) {
  #s_i^(-2) for s_i<1 and 1 otherwise
  gamma <- length(s)/(sum(  (s^(-2))^(s>1) ))
  omega <- numeric(length(s)) 
  omega[s>1] <- gamma*(s[s>1]^(-2))
  omega[s<=1] <- gamma
  return(omega)
}
@ 

\name{algo.farrington.fitGLM}
\alias{algo.farrington.fitGLM}
\encoding{latin1}

\title{Fit the Poisson GLM of the Farrington procedure for a single
  time point}
\description{
  The function fits a Poisson regression model (GLM) with mean predictor
  \deqn{\log \mu_t = \alpha + \beta w_t}{
        log mu_t = alpha + beta * w}
  as specified by the Farrington procedure. That way we are able to
  predict the value \eqn{c_0}{c0}. If 
  requested Anscombe residuals are computed based on an initial fit
  and a 2nd fit is made using weights, where base counts suspected to
  be caused by earlier outbreaks are downweighted.
}
\usage{
  algo.farrington.fitGLM(response, wtime, timeTrend = TRUE, 
                         reweight = TRUE)
}
\arguments{
  \item{response}{The vector of observed base counts}
  \item{wtime}{Vector of week numbers corresponding to \code{response}}
  \item{timeTrend}{Boolean whether to fit the \eqn{\beta t}{beta*t} or not}
  \item{reweight}{Fit twice -- 2nd time with Anscombe residuals}
}
%
\details{Compute weights from an initial fit and rescale using
  Anscombe based residuals as described in the
  \code{\link{anscombe.residuals}} function.}
%
\value{An object of class GLM with additional fields \code{wtime},
  \code{response} and \code{phi}. If the \code{glm} returns without
  convergence \code{NULL} is returned.}
%
\seealso{\code{\link{anscombe.residuals}}}
\keyword{}

<<echo=F>>=
algo.farrington.fitGLM <- function(response,wtime,timeTrend=TRUE,reweight=TRUE) {
  #Model formula depends on whether to include a time trend or not.
  theModel <- as.formula(ifelse(timeTrend, "response~1+wtime","response~1"))

  #Fit it.
  model <- glm(theModel, family = quasipoisson(link="log"))
    
 #Check convergence - if no convergence we return empty handed.
  if (!model$converged) {
    #Try without time dependence
    if (timeTrend) {
     model <- glm(response ~ 1, family = quasipoisson(link="log"))
     cat("Warning: No convergence with timeTrend -- trying without.\n")
    } 

    if (!model$converged) {
      cat("Warning: No convergence in this case.\n")
      print(cbind(response,wtime))
      return(NULL)
    }
  }

  #Overdispersion parameter phi
  phi <- max(summary(model)$dispersion,1)
  
  #In case reweighting using Anscome residuals is requested
  if (reweight) {
    s <- anscombe.residuals(model,phi)
    omega <- algo.farrington.assign.weights(s)
    model <- glm(theModel,family=quasipoisson(link="log"),weights=omega)
    #Here, the overdispersion often becomes small, so we use the max
    #to ensure we don't operate with quantities less than 1.
    phi <- max(summary(model)$dispersion,1)
  } # end of refit.
  

  #Add wtime, response and phi to the model
  model$phi <- phi
  model$wtime <- wtime
  model$response <- response
  #Done
  return(model)
}
@ 

\name{algo.farrington.threshold}
\alias{algo.farrington.threshold}
\encoding{latin1}

\title{Threshold computations using a two sided confidence interval}
\description{
Depending on the current transformation \eqn{h(y)= \{y, \sqrt{y}, y^{2/3}\}},

  \deqn{V(h(y_0)-h(\mu_0))=V(h(y_0))+V(h(\mu_0))}

  is used to compute a prediction interval. The prediction variance
  consists of a component due to the variance of having a single
  observation and a prediction variance.  }

\usage{
algo.farrington.threshold(pred,phi,alpha=0.01,skewness.transform="none")
}
\arguments{
\item{pred}{A GLM prediction object}
\item{phi}{Current overdispersion (superflous?)}
\item{alpha}{Quantile level in Gaussian based CI, i.e. an \eqn{(1-\alpha)\%}
    confidence interval is computed. }
\item{skewness.transform}{Skewness correction, i.e. one of
    \code{"none"}, \code{"sqrt"}, or \code{"2/3"}.}
}
\value{\item{vector}{
        Vector of length 2 with lower and upper bounds of an \eqn{(1-\alpha)\%} confidence interval.
        }
}
\keyword{}

<<echo=F>>=

algo.farrington.threshold <- function(pred,phi,alpha=0.01,skewness.transform="none") {
  #Fetch mu0 and var(mu0) from the prediction object
  mu0 <- pred$fit
  tau <- phi + (pred$se.fit^2)/mu0
  #Standard deviation of prediction, i.e. sqrt(var(h(Y_0)-h(\mu_0))) 
  switch(skewness.transform,
         "none" = { se <- sqrt(mu0*tau); exponent <- 1},
         "sqrt" = { se <- sqrt(1/4*tau); exponent <- 1/2},
         "2/3"  = { se <- sqrt(4/9*mu0^(1/3)*tau); exponent <- 2/3})

  #Note that lu can contain NA's if e.g. (-1.47)^(3/2)
  lu <- sort((mu0^exponent + c(-1,1)*qnorm(1-alpha/2)*se)^(1/exponent),na.last=FALSE)

  #Ensure that lower bound is non-negative
  lu[1] <- max(0,lu[1],na.rm=TRUE)

  #Return lower and upper bounds
  return(lu)
}
@ 

\name{algo.farrington}
\alias{algo.farrington}
\encoding{latin1}

\title{Surveillance for a time series using the Farrington procedure.}
\description{
  The function takes \code{range} values of the time series \code{counts} and for each uses a GLM to predict the number of counts according to the procedure by Farrington et. al. This is then compared to the observed number of counts and in case an exceedance of the confidence interval calculated is seen an alarm is raised. 
}
\usage{
  algo.farrington(disProgObj, control=list(range=NULL, b=3, w=3,
  reweight=TRUE,verbose=FALSE,alpha=0.01,powertrans="2/3"))
}
\arguments{
\item{disProgObj}{object of class disProgObj (including the observed and the state chain)}
\item{control}{Control object
    \itemize{
    \item{range}{Specifies the index of all timepoints which should be tested. If range is \code{NULL} the maximum number of possible weeks is used.}
    \item{b}{how many years back in time to include when forming the base counts.}
    \item{w}{windows size, i.e. number of weeks to include before and after the current week}
    \item{reweight}{Boolean specifying whether to perform reweight step}
    \item{trend}{If \code{true} a trend is included and kept in case
        the conditions in the Farrington et. al. paper are met (see
        the results). If \code{false} then NO trend is fit.}
    \item{verbose}{show extra debugging information}
    \item{plot}{shows the final GLM model fit graphically (use History|Recording to see all pictures)}
    \item{powertrans}{Power transformation to apply to the data. Use either "2/3" for skewness correction (Default), "1/2" for variance stabilizing transformation or "none" for no transformation}
    \item{alpha}{An approximate (two-sided) \eqn{(1-\alpha)\%}\ confidence interval is calculated}
    \item{limit54}{to avoid alarms in scenarios going from zero to 1-2 cases the algorithm uses the following criterion (see Section 3.8 of the Farrington paper): no alarm is sounded if fewer than \eqn{cases=5} reports were received in the past \eqn{period=4} weeks. \code{limit54=c(cases,period)} is a vector allowing the user to change these numbers. Note: As of version 0.9-7 The term "last" period of weeks includes the current week - otherwise no alarm is sounded for horrible large numbers if the four weeks before that are too low.}
    }}
}
\details{
  The following steps are perfomed according to the Farrington
  et. al. paper.
\enumerate{
\item fit of the initial model and initial estimation of mean and overdispersion.
\item calculation of the weights omega (correction for past outbreaks)
\item refitting of the model
\item revised estimation of overdispersion
\item rescaled model
\item omission of the trend, if it is not significant
\item repetition of the whole procedure
\item calculation of the threshold value
\item computation of exceedance score
}
}
\value{
An object of class \code{SurvRes}.
}

\examples{
#Read Salmonella Agona data
data("salmonella.agona")

#Do surveillance for the last 100 weeks.
n <- length(salmonella.agona$observed)
#Set control parameters.
control <- list(b=4,w=3,range=(n-100):n,reweight=TRUE, verbose=FALSE,alpha=0.01)
res <- algo.farrington(salmonella.agona,control=control)
#Plot the result.
plot(res,disease="Salmonella Agona",method="Farrington")
}
\author{M. Höhle}
\seealso{\code{\link{algo.farrington.fitGLM}},\code{\link{algo.farrington.threshold}}}
\keyword{}
\source{A statistical algorithm for the early detection of outbreaks of infectious disease, Farrington, C.P., Andrews, N.J, Beale A.D. and Catchpole, M.A. (1996). , J. R. Statist. Soc. A, 159, 547-563.}
<<echo=F>>=
algo.farrington <- function(disProgObj, control=list(range=NULL, b=3, w=3, reweight=TRUE, verbose=FALSE,alpha=0.01,powertrans="2/3")) { 
  #Fetch observed
  observed <- disProgObj$observed
  freq <- disProgObj$freq

  ######################################################################
  # Fix missing control options
  ######################################################################
  if (is.null(control$range)) {
    control$range <- (freq*control$b - control$w):length(observed)
  }
  if (is.null(control$b))        {control$b=5}
  if (is.null(control$w))        {control$w=3}
  if (is.null(control$reweight)) {control$reweight=TRUE}
  if (is.null(control$verbose))  {control$verbose=FALSE}
  if (is.null(control$alpha))    {control$alpha=0.05}
  if (is.null(control$trend))    {control$trend=TRUE}
  if (is.null(control$plot))     {control$plot=FALSE}
  if (is.null(control$limit54))  {control$limit54=c(5,4)}
  if (is.null(control$powertrans)){control$powertrans="2/3"}

  #check options
  if (!((control$limit54[1] >= 0) &  (control$limit54[2] > 0))) {
    stop("The limit54 arguments are out of bounds: cases >= 0 and perior > 0.")
  }

  # initialize the necessary vectors
  alarm <- matrix(data = 0, nrow = length(control$range), ncol = 1)
  trend <- matrix(data = 0, nrow = length(control$range), ncol = 1)
  upperbound <- matrix(data = 0, nrow = length(control$range), ncol = 1)
  
  # Define objects
  n <- control$b*(2*control$w+1)
  
  # 2: Fit of the initial model and first estimation of mean and dispersion
  #    parameter
  for(k in control$range) {
    # transform the observed vector in the way
    # that the timepoint to be evaluated is at last position
    #shortObserved <- observed[1:(maxRange - k + 1)]

    if (control$verbose) { cat("k=",k,"\n")}

    #Find all weeks with index k-w,..,k+w 
    #in the years (current year)-1,...,(current year)-b
    wtime <- NULL
    for (i in control$b:1){
      wtime <- append(wtime,seq(k-freq*i-control$w,k-freq*i+control$w,by=1))
    }
    response <- NULL # die Responsespalte
    for (i in (control$b:1)) {
      if (control$verbose) {cat("b=",i,"\trange=",((k-i*freq)-control$w):((k-i*freq)+control$w),"\n")}

      for (j in (((k-i*freq)-control$w):((k-i*freq)+control$w))){
        if (j<1) {
          cat("Warning: Selection index less than 1!\n")
        }
        else {
          response <- append(response,observed[j])
        }
      }
    } 
    if (control$verbose) { print(response)}

    ######################################################################
    #Fit the model with overdispersion -- the initial fit
    ######################################################################
    model <- algo.farrington.fitGLM(response,wtime,timeTrend=control$trend,reweight=control$reweight)

    #Stupid check to pass on NULL values from the algo.farrington.fitGLM proc.
    if (is.null(model)) return(model)

    ######################################################################
    #Time trend
    #
    #Check whether to include time trend, to do this we need to check whether
    #1) wtime is signifcant at the 95lvl
    #2) the predicted value is not larger than any observed value
    #3) the historical data span at least 3 years.
    doTrend <- control$trend
    if (control$trend) {
      #is the p-value for the trend significant (0.05) level
      p <- summary.glm(model)$coefficients["wtime",4]
      significant <- (p < 0.05)
      #prediction for time k
      mu0Hat <- predict.glm(model,data.frame(wtime=c(k)),type="response")
      #have to use at least three years of data to allow for a trend
      atLeastThreeYears <- (control$b>=3)
      #no horrible predictions
      noExtrapolation <- mu0Hat <= max(response)
     
      #All 3 criteria have to be met in order to include the trend. Otherwise
      #it is removed. Only necessary to check this if a trend is requested.
      if (!(atLeastThreeYears && significant && noExtrapolation)) {
        doTrend <- FALSE
        model <- algo.farrington.fitGLM(response,wtime,timeTrend=FALSE,reweight=control$reweight)
      }
    } else {
      doTrend <- FALSE
    }
    #done with time trend
    ######################################################################
    
    ######################################################################
    # Calculate prediction & confidence interval                         #
    ######################################################################
    #Predict value - note that the se is the mean CI
    #and not the prediction error of a single observation
    pred <- predict.glm(model,data.frame(wtime=c(k)),dispersion=model$phi,
                        type="response",se.fit=TRUE)
    #Calculate lower and upper threshold
    lu <- algo.farrington.threshold(pred,model$phi,skewness.transform=control$powertrans,alpha=control$alpha)

    ######################################################################
    # If requested show a plot of the fit.
    ######################################################################
    if (control$plot) {
      #Compute all predictions
      data <- data.frame(wtime=seq(min(wtime),k,length=1000))
      preds <- predict(model,data,type="response",dispersion=model$phi)

      #Show a plot of the model fit.
      plot(c(wtime, k), c(response,observed[k]),ylim=range(c(observed[data$wtime],lu)),,xlab="time",ylab="No. infected",main=paste("Prediction at time t=",k," with b=",control$b,",w=",control$w,sep=""),pch=c(rep(1,length(wtime)),16))
      #Add the prediction
      lines(data$wtime,preds,col=1,pch=2)

      #Add the thresholds
      #points(c(k,k),lu,cex=1,pch=3,col=3)
      lines(rep(k,2),lu,col=3,lty=2)
    }


    ######################################################################
    #Postprocessing steps
    ######################################################################

    #Compute exceedance score unless less than 5 reports during last 4 weeks.
    #enoughCases <- (sum(observed[(k-control$limit54[2]):(k-1)])>=control$limit54[1])
    #Changed in version 0.9-7 - current week is included now
    enoughCases <- (sum(observed[(k-control$limit54[2]+1):k])>=control$limit54[1])

    #18 May 2006: Bug/unexpected feature found by Y. Le Strat. 
    #the okHistory variable meant to protect against zero count problems,
    #but instead it resulted in exceedance score == 0 for low counts. 
    #Now removed to be concordant with the Farrington 1996 paper.
    X <- ifelse(enoughCases,(observed[k] - pred$fit) / (max(lu) - pred$fit),0)

    #Do we have an alarm -- i.e. is observation beyond CI??
    #upperbound only relevant if we can have an alarm (enoughCases)
    trend[k-min(control$range)+1] <- doTrend
    alarm[k-min(control$range)+1] <- (X>1)
    upperbound[k-min(control$range)+1] <- ifelse(enoughCases,lu[2],0)
  }#done looping over all time points

  #Add name and data name to control object.
  control$name <- paste("farrington(",control$w,",",0,",",control$b,")",sep="")
  control$data <- paste(deparse(substitute(disProgObj)))

  # return alarm and upperbound vectors 
  result <- list(alarm = alarm, upperbound = upperbound, trend=trend, 
                 disProgObj=disProgObj, control=control) 
  class(result) <- "survRes" 

  #Done
  return(result) 
}

@ 


