
R version 4.4.1 (2024-06-14) -- "Race for Your Life"
Copyright (C) 2024 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "surveillance"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> base::assign(".ExTimings", "surveillance-Ex.timings", pos = 'CheckExEnv')
> base::cat("name\tuser\tsystem\telapsed\n", file=base::get(".ExTimings", pos = 'CheckExEnv'))
> base::assign(".format_ptime",
+ function(x) {
+   if(!is.na(x[4L])) x[1L] <- x[1L] + x[4L]
+   if(!is.na(x[5L])) x[2L] <- x[2L] + x[5L]
+   options(OutDec = '.')
+   format(x[1L:3L], digits = 7L)
+ },
+ pos = 'CheckExEnv')
> 
> ### * </HEADER>
> library('surveillance')
Loading required package: sp
Loading required package: xtable
This is surveillance 1.23.1; see ‘package?surveillance’ or
https://surveillance.R-Forge.R-project.org/ for an overview.
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("LRCUSUM.runlength")
> ### * LRCUSUM.runlength
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: LRCUSUM.runlength
> ### Title: Run length computation of a CUSUM detector
> ### Aliases: LRCUSUM.runlength
> ### Keywords: regression
> 
> ### ** Examples
> 
> ######################################################
> #Run length of a time constant negative binomial CUSUM
> ######################################################
> 
> #In-control and out of control parameters
> mu0 <- 10
> alpha <- 1/2
> kappa <- 2
> 
> #Density for comparison in the negative binomial distribution
> dY <- function(y,mu,log=FALSE, alpha, ...) {
+   dnbinom(y, mu=mu, size=1/alpha, log=log)
+ }
> 
> #In this case "n" is the maximum value to investigate the LLR for
> #It is assumed that beyond n the LLR is too unlikely to be worth
> #computing.
> LRCUSUM.runlength( mu=t(mu0), mu0=t(mu0), mu1=kappa*t(mu0), h=5,
+   dfun = dY, n=rep(100,length(mu0)), alpha=alpha)
$P
, , (-Inf,0]

   (-Inf,0]  (0,1.25] (1.25,2.5] (2.5,3.75] (3.75,5] >=h
1 0.7403781 0.3869451          0          0        0   0

, , (0,1.25]

   (-Inf,0]  (0,1.25] (1.25,2.5] (2.5,3.75] (3.75,5] >=h
1 0.2301328 0.5085153  0.3869451          0        0   0

, , (1.25,2.5]

    (-Inf,0]   (0,1.25] (1.25,2.5] (2.5,3.75] (3.75,5] >=h
1 0.02627352 0.09250495  0.5085153  0.3869451        0   0

, , (2.5,3.75]

     (-Inf,0]   (0,1.25] (1.25,2.5] (2.5,3.75]  (3.75,5] >=h
1 0.002942926 0.01076956 0.09250495  0.5085153 0.3869451   0

, , (3.75,5]

      (-Inf,0]    (0,1.25] (1.25,2.5] (2.5,3.75]  (3.75,5] >=h
1 0.0002467183 0.001159071 0.01076956 0.09250495 0.5085153   0

, , >=h

      (-Inf,0]     (0,1.25] (1.25,2.5] (2.5,3.75]  (3.75,5] >=h
1 2.587579e-05 0.0001060095 0.00126508 0.01203464 0.1045396   1


$pmf
[1] 2.587579e-05

$cdf
[1] 2.587579e-05

$arl
(-Inf,0] 
519.6001 

> 
> h.grid <- seq(3,6,by=0.3)
> arls <- sapply(h.grid, function(h) {
+   LRCUSUM.runlength( mu=t(mu0), mu0=t(mu0), mu1=kappa*t(mu0), h=h,
+   dfun = dY, n=rep(100,length(mu0)), alpha=alpha,g=20)$arl
+ })
> plot(h.grid, arls,type="l",xlab="threshold h",ylab=expression(ARL[0]))
> 
> ######################################################
> #Run length of a time varying negative binomial CUSUM
> ######################################################
> 
> mu0 <- matrix(5*sin(2*pi/52 * 1:150) + 10,ncol=1)
> 
> rl <- LRCUSUM.runlength( mu=t(mu0), mu0=t(mu0), mu1=kappa*t(mu0), h=2,
+   dfun = dY, n=rep(100,length(mu0)), alpha=alpha,g=20)
Looking at t = 1 / 150 
Looking at t = 2 / 150 
Looking at t = 3 / 150 
Looking at t = 4 / 150 
Looking at t = 5 / 150 
Looking at t = 6 / 150 
Looking at t = 7 / 150 
Looking at t = 8 / 150 
Looking at t = 9 / 150 
Looking at t = 10 / 150 
Looking at t = 11 / 150 
Looking at t = 12 / 150 
Looking at t = 13 / 150 
Looking at t = 14 / 150 
Looking at t = 15 / 150 
Looking at t = 16 / 150 
Looking at t = 17 / 150 
Looking at t = 18 / 150 
Looking at t = 19 / 150 
Looking at t = 20 / 150 
Looking at t = 21 / 150 
Looking at t = 22 / 150 
Looking at t = 23 / 150 
Looking at t = 24 / 150 
Looking at t = 25 / 150 
Looking at t = 26 / 150 
Looking at t = 27 / 150 
Looking at t = 28 / 150 
Looking at t = 29 / 150 
Looking at t = 30 / 150 
Looking at t = 31 / 150 
Looking at t = 32 / 150 
Looking at t = 33 / 150 
Looking at t = 34 / 150 
Looking at t = 35 / 150 
Looking at t = 36 / 150 
Looking at t = 37 / 150 
Looking at t = 38 / 150 
Looking at t = 39 / 150 
Looking at t = 40 / 150 
Looking at t = 41 / 150 
Looking at t = 42 / 150 
Looking at t = 43 / 150 
Looking at t = 44 / 150 
Looking at t = 45 / 150 
Looking at t = 46 / 150 
Looking at t = 47 / 150 
Looking at t = 48 / 150 
Looking at t = 49 / 150 
Looking at t = 50 / 150 
Looking at t = 51 / 150 
Looking at t = 52 / 150 
Looking at t = 53 / 150 
Looking at t = 54 / 150 
Looking at t = 55 / 150 
Looking at t = 56 / 150 
Looking at t = 57 / 150 
Looking at t = 58 / 150 
Looking at t = 59 / 150 
Looking at t = 60 / 150 
Looking at t = 61 / 150 
Looking at t = 62 / 150 
Looking at t = 63 / 150 
Looking at t = 64 / 150 
Looking at t = 65 / 150 
Looking at t = 66 / 150 
Looking at t = 67 / 150 
Looking at t = 68 / 150 
Looking at t = 69 / 150 
Looking at t = 70 / 150 
Looking at t = 71 / 150 
Looking at t = 72 / 150 
Looking at t = 73 / 150 
Looking at t = 74 / 150 
Looking at t = 75 / 150 
Looking at t = 76 / 150 
Looking at t = 77 / 150 
Looking at t = 78 / 150 
Looking at t = 79 / 150 
Looking at t = 80 / 150 
Looking at t = 81 / 150 
Looking at t = 82 / 150 
Looking at t = 83 / 150 
Looking at t = 84 / 150 
Looking at t = 85 / 150 
Looking at t = 86 / 150 
Looking at t = 87 / 150 
Looking at t = 88 / 150 
Looking at t = 89 / 150 
Looking at t = 90 / 150 
Looking at t = 91 / 150 
Looking at t = 92 / 150 
Looking at t = 93 / 150 
Looking at t = 94 / 150 
Looking at t = 95 / 150 
Looking at t = 96 / 150 
Looking at t = 97 / 150 
Looking at t = 98 / 150 
Looking at t = 99 / 150 
Looking at t = 100 / 150 
Looking at t = 101 / 150 
Looking at t = 102 / 150 
Looking at t = 103 / 150 
Looking at t = 104 / 150 
Looking at t = 105 / 150 
Looking at t = 106 / 150 
Looking at t = 107 / 150 
Looking at t = 108 / 150 
Looking at t = 109 / 150 
Looking at t = 110 / 150 
Looking at t = 111 / 150 
Looking at t = 112 / 150 
Looking at t = 113 / 150 
Looking at t = 114 / 150 
Looking at t = 115 / 150 
Looking at t = 116 / 150 
Looking at t = 117 / 150 
Looking at t = 118 / 150 
Looking at t = 119 / 150 
Looking at t = 120 / 150 
Looking at t = 121 / 150 
Looking at t = 122 / 150 
Looking at t = 123 / 150 
Looking at t = 124 / 150 
Looking at t = 125 / 150 
Looking at t = 126 / 150 
Looking at t = 127 / 150 
Looking at t = 128 / 150 
Looking at t = 129 / 150 
Looking at t = 130 / 150 
Looking at t = 131 / 150 
Looking at t = 132 / 150 
Looking at t = 133 / 150 
Looking at t = 134 / 150 
Looking at t = 135 / 150 
Looking at t = 136 / 150 
Looking at t = 137 / 150 
Looking at t = 138 / 150 
Looking at t = 139 / 150 
Looking at t = 140 / 150 
Looking at t = 141 / 150 
Looking at t = 142 / 150 
Looking at t = 143 / 150 
Looking at t = 144 / 150 
Looking at t = 145 / 150 
Looking at t = 146 / 150 
Looking at t = 147 / 150 
Looking at t = 148 / 150 
Looking at t = 149 / 150 
Looking at t = 150 / 150 
> 
> plot(1:length(mu0),rl$pmf,type="l",xlab="t",ylab="PMF")
> plot(1:length(mu0),rl$cdf,type="l",xlab="t",ylab="CDF")
> 
> ########################################################
> # Further examples contain the binomial, beta-binomial
> # and multinomial CUSUMs. Hopefully, these will be added
> # in the future.
> ########################################################
> 
> #dfun function for the multinomial distribution (Note: Only k-1 categories are specified).
> dmult <- function(y, size,mu, log = FALSE) {
+     return(dmultinom(c(y,size-sum(y)), size = size, prob=c(mu,1-sum(mu)), log = log))
+ }
> 
> #Example for the time-constant multinomial distribution
> #with size 100 and in-control and out-of-control parameters as below.
> n <- 100
> pi0 <- as.matrix(c(0.5,0.3,0.2))
> pi1 <- as.matrix(c(0.38,0.46,0.16))
> 
> #ARL_0
> LRCUSUM.runlength(mu=pi0[1:2,,drop=FALSE],mu0=pi0[1:2,,drop=FALSE],mu1=pi1[1:2,,drop=FALSE],
+                   h=5,dfun=dmult, n=n, g=15)$arl
(-Inf,0] 
1057.149 
> #ARL_1
> LRCUSUM.runlength(mu=pi1[1:2,,drop=FALSE],mu0=pi0[1:2,,drop=FALSE],mu1=pi1[1:2,,drop=FALSE],
+                   h=5,dfun=dmult, n=n, g=15)$arl
(-Inf,0] 
1.521172 
> 
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("LRCUSUM.runlength", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("R0")
> ### * R0
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: R0
> ### Title: Computes reproduction numbers from fitted models
> ### Aliases: R0 R0.twinstim R0.simEpidataCS simpleR0
> ### Keywords: methods univar
> 
> ### ** Examples
> 
> ## load the 'imdepi' data and a model fit
> data("imdepi", "imdepifit")
> 
> ## calculate individual and type-specific reproduction numbers
> R0s <- R0(imdepifit)
> tapply(R0s, imdepi$events@data[names(R0s), "type"], summary)
$B
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
0.05058 0.13767 0.17516 0.21499 0.31908 0.35489 

$C
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
0.03029 0.05551 0.07063 0.09543 0.14309 0.14309 

> 
> ## untrimmed R0 for specific event settings
> refevent <- data.frame(agegrp = "[0,3)", type = "B", eps.s = Inf, eps.t = 30)
> setting2 <- data.frame(agegrp = "[3,19)", type = "C", eps.s = Inf, eps.t = 14)
> newevents <- rbind("ref" = refevent, "event2" = setting2)
> (R0_examples <- R0(imdepifit, newevents = newevents, trimmed = FALSE))
       ref     event2 
0.17516101 0.06677711 
> stopifnot(all.equal(R0_examples[["ref"]],
+                     simpleR0(imdepifit)))
> 
> 
> ### compute a Monte Carlo confidence interval
> 
> ## use a simpler model with constant 'siaf' for speed
> simplefit <- update(imdepifit, epidemic=~type, siaf=NULL, subset=NULL)
marked point pattern of 2 types
assuming constant spatial interaction 'siaf.constant()'
assuming constant temporal interaction 'tiaf.constant()'

minimizing the negative log-likelihood using 'nlminb()' ...
initial parameters:
            h.(Intercept)      h.I(start/365 - 3.5) h.sin(2 * pi * start/365) 
             -20.52869499               -0.04574093                0.21728211 
h.cos(2 * pi * start/365)             e.(Intercept)                   e.typeC 
               0.31810266              -12.51659414               -0.90832081 
negative log-likelihood and parameters in each iteration:
  0:     12600.831: -20.5287 -0.0457409 0.217282 0.318103 -12.5166 -0.908321
  1:     10498.547: -20.5793 -0.0296470 0.206515 0.308021 -13.3944 -1.13825
  2:     9807.1641: -20.6512 -0.0242134 0.189555 0.295827 -14.2903 -1.29305
  3:     9619.4124: -20.6350 -0.0373679 0.189252 0.311188 -15.2476 -1.32641
  4:     9587.6496: -20.4974 -0.0385582 0.232759 0.344954 -16.1187 -1.11033
  5:     9584.2990: -20.4765 -0.0392810 0.239223 0.350553 -16.7026 -0.353417
  6:     9584.2839: -20.4811 -0.0392990 0.238631 0.349806 -16.7324 -0.309915
  7:     9584.2839: -20.4811 -0.0393087 0.238567 0.349770 -16.7322 -0.310105

MLE:
            h.(Intercept)      h.I(start/365 - 3.5) h.sin(2 * pi * start/365) 
             -20.48113429               -0.03930866                0.23856692 
h.cos(2 * pi * start/365)             e.(Intercept)                   e.typeC 
               0.34977011              -16.73224435               -0.31010516 
loglik(MLE) = -9584.284 

Done.
> 
> ## we'd like to compute the mean R0's by event type
> meanR0ByType <- function (newcoef) {
+     R0events <- R0(simplefit, newcoef=newcoef)
+     tapply(R0events, imdepi$events@data[names(R0events),"type"], mean)
+ }
> (meansMLE <- meanR0ByType(newcoef=NULL))
       B        C 
0.123285 0.102628 
> 
> ## sample B times from asymptotic multivariate normal of the MLE
> B <- 5  # CAVE: toy example! In practice this has to be much larger
> set.seed(123)
> parsamples <- MASS::mvrnorm(B, mu=coef(simplefit), Sigma=vcov(simplefit))
> 
> ## for each sample compute the 'meanR0ByType'
> meansMC <- apply(parsamples, 1, meanR0ByType)
> 
> ## get the quantiles and print the result
> cisMC <- apply(cbind(meansMLE, meansMC), 1, quantile, probs=c(0.025,0.975))
> print(rbind(MLE=meansMLE, cisMC))
              B          C
MLE   0.1232850 0.10262804
2.5%  0.1096727 0.05466118
97.5% 0.1492947 0.18623290
> 
> 
> ### R0 for a simple epidemic model
> ### without epidemic covariates, i.e., all individuals are equally infectious
> 
> mepi1 <- update(simplefit, epidemic = ~1, subset = type == "B",
+                 model = TRUE, verbose = FALSE)
negative log-likelihood and parameters in each iteration:
  0:     4991.1207: -20.4811 -0.0393087 0.238567 0.349770 -16.7322
  1:     4989.7183: -20.4345 -0.0232096 0.205048 0.461474 -16.8845
  2:     4989.7111: -20.4293 -0.0222626 0.213322 0.457735 -16.9084
  3:     4989.7111: -20.4295 -0.0223814 0.213038 0.458727 -16.9087
> ## using the default spatial and temporal ranges of interaction
> (R0B <- simpleR0(mepi1))  # eps.s=200, eps.t=30
[1] 0.1709992
> stopifnot(identical(R0B, R0(mepi1, trimmed = FALSE)[[1]]))
> ## assuming smaller interaction ranges (but same infection intensity)
> simpleR0(mepi1, eps.s = 50, eps.t = 15)
[1] 0.005343725
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("R0", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("abattoir")
> ### * abattoir
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: abattoir
> ### Title: Abattoir Data
> ### Aliases: abattoir
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("abattoir")
> plot(abattoir)
> population(abattoir) 
       observed1
  [1,]      4200
  [2,]      4900
  [3,]      4700
  [4,]      5100
  [5,]      4900
  [6,]      5000
  [7,]      4700
  [8,]      4500
  [9,]      4500
 [10,]      4400
 [11,]      4300
 [12,]      4500
 [13,]      4500
 [14,]      4800
 [15,]      3000
 [16,]      3600
 [17,]      4200
 [18,]      4300
 [19,]      2900
 [20,]      4000
 [21,]      3000
 [22,]      4500
 [23,]      3300
 [24,]      4700
 [25,]      4300
 [26,]      4100
 [27,]      3100
 [28,]      2500
 [29,]      3700
 [30,]      3300
 [31,]      3700
 [32,]      4200
 [33,]      4200
 [34,]      4100
 [35,]      4000
 [36,]      5000
 [37,]      3900
 [38,]      3700
 [39,]      4600
 [40,]      4400
 [41,]      4500
 [42,]      5000
 [43,]      4100
 [44,]      3800
 [45,]      2300
 [46,]      3000
 [47,]      3700
 [48,]      3200
 [49,]      2000
 [50,]      2500
 [51,]      4000
 [52,]      1500
 [53,]      1700
 [54,]      3000
 [55,]      3000
 [56,]      2500
 [57,]      2300
 [58,]      3100
 [59,]      2600
 [60,]      1300
 [61,]      4100
 [62,]      1800
 [63,]      2600
 [64,]      2900
 [65,]      1100
 [66,]      1300
 [67,]      3700
 [68,]      2700
 [69,]      1700
 [70,]      2700
 [71,]      1100
 [72,]      3300
 [73,]      1800
 [74,]      3500
 [75,]      4100
 [76,]      3300
 [77,]      4100
 [78,]      2500
 [79,]      3000
 [80,]      2400
 [81,]       800
 [82,]      3300
 [83,]      3100
 [84,]      3000
 [85,]      3100
 [86,]      2500
 [87,]      3300
 [88,]      3200
 [89,]      2700
 [90,]      2700
 [91,]      1500
 [92,]      1400
 [93,]      2200
 [94,]      1600
 [95,]      2700
 [96,]      1700
 [97,]      4200
 [98,]      3900
 [99,]      8100
[100,]      5900
[101,]      4800
[102,]       300
[103,]         0
[104,]         0
[105,]         0
[106,]       200
[107,]      5000
[108,]      5400
[109,]      6100
[110,]      5500
[111,]      4300
[112,]      4100
[113,]      8000
[114,]      8200
[115,]      7700
[116,]      2500
[117,]      5200
[118,]      7200
[119,]      7400
[120,]      5000
[121,]      6500
[122,]      3900
[123,]      5300
[124,]      4100
[125,]      6600
[126,]      6600
[127,]      5400
[128,]      6300
[129,]      6100
[130,]      5000
[131,]      5000
[132,]      4700
[133,]      4900
[134,]      5200
[135,]      4800
[136,]      4900
[137,]      4900
[138,]      4900
[139,]      5000
[140,]      5000
[141,]      4900
[142,]      4900
[143,]       900
[144,]       800
[145,]      1300
[146,]       200
[147,]       700
[148,]      1200
[149,]      2300
[150,]      1600
[151,]      2900
[152,]      2600
[153,]      3600
[154,]      4000
[155,]      2000
[156,]         0
[157,]         0
[158,]         0
[159,]         0
[160,]         0
[161,]       100
[162,]         0
[163,]         0
[164,]       100
[165,]      2200
[166,]      2900
[167,]      3100
[168,]      3200
[169,]      3900
[170,]      4300
[171,]      1000
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("abattoir", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("addSeason2formula")
> ### * addSeason2formula
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: addSeason2formula
> ### Title: Add Harmonics to an Existing Formula
> ### Aliases: addSeason2formula
> 
> ### ** Examples
> 
> # add 2 sine/cosine terms to a model with intercept and linear trend
> addSeason2formula(f = ~ 1 + t, S = 2)
~1 + t + sin(2 * pi * t/52) + cos(2 * pi * t/52) + sin(4 * pi * 
    t/52) + cos(4 * pi * t/52)
> 
> # the same for monthly data
> addSeason2formula(f = ~ 1 + t, S = 2, period = 12)
~1 + t + sin(2 * pi * t/12) + cos(2 * pi * t/12) + sin(4 * pi * 
    t/12) + cos(4 * pi * t/12)
> 
> # different number of seasons for a bivariate time series
> addSeason2formula(f = ~ 1, S = c(3, 1), period = 52)
~1 + fe(sin(2 * pi * t/52), which = c(TRUE, TRUE)) + fe(cos(2 * 
    pi * t/52), which = c(TRUE, TRUE)) + fe(sin(4 * pi * t/52), 
    which = c(TRUE, FALSE)) + fe(cos(4 * pi * t/52), which = c(TRUE, 
    FALSE)) + fe(sin(6 * pi * t/52), which = c(TRUE, FALSE)) + 
    fe(cos(6 * pi * t/52), which = c(TRUE, FALSE))
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("addSeason2formula", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("aggregate.disProg")
> ### * aggregate.disProg
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: aggregate.disProg
> ### Title: Aggregate a 'disProg' Object
> ### Aliases: aggregate.disProg
> ### Keywords: internal
> 
> ### ** Examples
> 
> data(ha)
> dim(ha$observed)
[1] 290  12
> dim(aggregate(ha)$observed)
[1] 290   1
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("aggregate.disProg", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("algo.bayes")
> ### * algo.bayes
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: algo.bayes
> ### Title: The Bayes System
> ### Aliases: algo.bayes algo.bayesLatestTimepoint algo.bayes1 algo.bayes2
> ###   algo.bayes3
> ### Keywords: classif
> 
> ### ** Examples
> 
>     disProg <- sim.pointSource(p = 0.99, r = 0.5, length = 208, A = 1,
+                                     alpha = 1, beta = 0, phi = 0,
+                                     frequency = 1, state = NULL, K = 1.7)
> 
>     # Test for bayes 1 the latest timepoint
>     algo.bayesLatestTimepoint(disProg)
$alarm
[1] FALSE

$upperbound
[1] 5

$disProgObj
-- An object of class disProg -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 

Head of observed:
[1] 1

attr(,"class")
[1] "survRes"
> 
>     # Test week 200 to 208 for outbreaks with a selfdefined bayes
>     algo.bayes(disProg, control = list(range = 200:208, b = 1,
+                                                 w = 5, actY = TRUE,alpha=0.05))
$alarm
      [,1]
 [1,]    0
 [2,]    0
 [3,]    0
 [4,]    0
 [5,]    0
 [6,]    0
 [7,]    0
 [8,]    0
 [9,]    0

$upperbound
      [,1]
 [1,]    4
 [2,]    4
 [3,]    4
 [4,]    4
 [5,]    5
 [6,]    4
 [7,]    5
 [8,]    5
 [9,]    6

$disProgObj
-- An object of class disProg -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 

Head of observed:
[1] 1

$control
$control$range
[1] 200 201 202 203 204 205 206 207 208

$control$b
[1] 1

$control$w
[1] 5

$control$actY
[1] TRUE

$control$alpha
[1] 0.05

$control$name
[1] "bayes(5,5,1)"

$control$data
[1] "disProg"


attr(,"class")
[1] "survRes"
>     # The same for bayes 1 to bayes 3
>     algo.bayes1(disProg, control = list(range = 200:208,alpha=0.05))
$alarm
      [,1]
 [1,]    0
 [2,]    0
 [3,]    0
 [4,]    0
 [5,]    0
 [6,]    0
 [7,]    0
 [8,]    0
 [9,]    0

$upperbound
      [,1]
 [1,]    5
 [2,]    5
 [3,]    5
 [4,]    5
 [5,]    5
 [6,]    5
 [7,]    4
 [8,]    4
 [9,]    5

$disProgObj
-- An object of class disProg -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 

Head of observed:
[1] 1

$control
$control$range
[1] 200 201 202 203 204 205 206 207 208

$control$b
[1] 0

$control$w
[1] 6

$control$actY
[1] TRUE

$control$alpha
[1] 0.05

$control$name
[1] "bayes(6,6,0)"

$control$data
[1] "disProgObj"


attr(,"class")
[1] "survRes"
>     algo.bayes2(disProg, control = list(range = 200:208,alpha=0.05))
$alarm
      [,1]
 [1,]    0
 [2,]    0
 [3,]    0
 [4,]    0
 [5,]    0
 [6,]    0
 [7,]    0
 [8,]    0
 [9,]    0

$upperbound
      [,1]
 [1,]    4
 [2,]    4
 [3,]    4
 [4,]    4
 [5,]    5
 [6,]    5
 [7,]    5
 [8,]    5
 [9,]    6

$disProgObj
-- An object of class disProg -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 

Head of observed:
[1] 1

$control
$control$range
[1] 200 201 202 203 204 205 206 207 208

$control$b
[1] 1

$control$w
[1] 6

$control$actY
[1] TRUE

$control$alpha
[1] 0.05

$control$name
[1] "bayes(6,6,1)"

$control$data
[1] "disProgObj"


attr(,"class")
[1] "survRes"
>     algo.bayes3(disProg, control = list(range = 200:208,alpha=0.05))
$alarm
      [,1]
 [1,]    0
 [2,]    0
 [3,]    0
 [4,]    0
 [5,]    0
 [6,]    0
 [7,]    0
 [8,]    0
 [9,]    0

$upperbound
      [,1]
 [1,]    4
 [2,]    4
 [3,]    4
 [4,]    4
 [5,]    4
 [6,]    6
 [7,]    7
 [8,]    7
 [9,]    8

$disProgObj
-- An object of class disProg -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 

Head of observed:
[1] 1

$control
$control$range
[1] 200 201 202 203 204 205 206 207 208

$control$b
[1] 2

$control$w
[1] 4

$control$actY
[1] FALSE

$control$alpha
[1] 0.05

$control$name
[1] "bayes(4,0,2)"

$control$data
[1] "disProgObj"


attr(,"class")
[1] "survRes"
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("algo.bayes", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("algo.call")
> ### * algo.call
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: algo.call
> ### Title: Query Transmission to Specified Surveillance Algorithm
> ### Aliases: algo.call
> ### Keywords: classif
> 
> ### ** Examples
> 
> # Create a test object
> disProg <- sim.pointSource(p = 0.99, r = 0.5, length = 400, A = 1,
+                            alpha = 1, beta = 0, phi = 0,
+                            frequency = 1, state = NULL, K = 1.7)
> 
> # Let this object be tested from any methods in range = 200:400
> range <- 200:400
> survRes <- algo.call(disProg,
+                      control = list(
+                          list(funcName = "rki1", range = range),
+                          list(funcName = "rki2", range = range),
+                          list(funcName = "rki3", range = range),
+                          list(funcName = "rki", range = range,
+                               b = 3, w = 2, actY = FALSE),
+                          list(funcName = "rki", range = range,
+                               b = 2, w = 9, actY = TRUE),
+                          list(funcName = "bayes1", range = range),
+                          list(funcName = "bayes2", range = range),
+                          list(funcName = "bayes3", range = range),
+                          list(funcName = "bayes",
+                               range = range, b = 1, w = 5, actY = TRUE,alpha=0.05)
+                      ))
> # show selected survRes objects
> names(survRes)
[1] "rki(6,6,0)"   "rki(6,6,1)"   "rki(4,0,2)"   "rki(2,0,3)"   "rki(9,9,2)"  
[6] "bayes(6,6,0)" "bayes(6,6,1)" "bayes(4,0,2)" "bayes(5,5,1)"
> plot(survRes[["rki(6,6,0)"]])
> survRes[["bayes(5,5,1)"]]
$alarm
       [,1]
  [1,]    0
  [2,]    0
  [3,]    0
  [4,]    0
  [5,]    0
  [6,]    0
  [7,]    0
  [8,]    0
  [9,]    0
 [10,]    0
 [11,]    0
 [12,]    0
 [13,]    0
 [14,]    0
 [15,]    0
 [16,]    0
 [17,]    0
 [18,]    0
 [19,]    0
 [20,]    0
 [21,]    0
 [22,]    0
 [23,]    0
 [24,]    0
 [25,]    0
 [26,]    0
 [27,]    0
 [28,]    0
 [29,]    0
 [30,]    0
 [31,]    0
 [32,]    0
 [33,]    0
 [34,]    0
 [35,]    0
 [36,]    0
 [37,]    0
 [38,]    0
 [39,]    0
 [40,]    0
 [41,]    0
 [42,]    0
 [43,]    0
 [44,]    0
 [45,]    0
 [46,]    0
 [47,]    0
 [48,]    0
 [49,]    0
 [50,]    0
 [51,]    0
 [52,]    0
 [53,]    0
 [54,]    0
 [55,]    0
 [56,]    0
 [57,]    0
 [58,]    0
 [59,]    0
 [60,]    0
 [61,]    0
 [62,]    0
 [63,]    0
 [64,]    1
 [65,]    0
 [66,]    0
 [67,]    0
 [68,]    0
 [69,]    0
 [70,]    0
 [71,]    0
 [72,]    0
 [73,]    0
 [74,]    0
 [75,]    0
 [76,]    0
 [77,]    0
 [78,]    0
 [79,]    0
 [80,]    0
 [81,]    0
 [82,]    0
 [83,]    0
 [84,]    0
 [85,]    0
 [86,]    0
 [87,]    0
 [88,]    0
 [89,]    0
 [90,]    0
 [91,]    0
 [92,]    0
 [93,]    0
 [94,]    0
 [95,]    0
 [96,]    0
 [97,]    0
 [98,]    0
 [99,]    0
[100,]    0
[101,]    0
[102,]    0
[103,]    0
[104,]    0
[105,]    0
[106,]    0
[107,]    0
[108,]    1
[109,]    0
[110,]    0
[111,]    0
[112,]    0
[113,]    0
[114,]    0
[115,]    0
[116,]    0
[117,]    0
[118,]    0
[119,]    0
[120,]    0
[121,]    0
[122,]    0
[123,]    0
[124,]    0
[125,]    0
[126,]    1
[127,]    1
[128,]    1
[129,]    1
[130,]    1
[131,]    0
[132,]    0
[133,]    0
[134,]    0
[135,]    0
[136,]    0
[137,]    0
[138,]    0
[139,]    0
[140,]    0
[141,]    0
[142,]    0
[143,]    0
[144,]    0
[145,]    0
[146,]    0
[147,]    0
[148,]    0
[149,]    0
[150,]    0
[151,]    0
[152,]    0
[153,]    0
[154,]    0
[155,]    0
[156,]    0
[157,]    0
[158,]    0
[159,]    0
[160,]    0
[161,]    0
[162,]    0
[163,]    0
[164,]    0
[165,]    1
[166,]    0
[167,]    0
[168,]    0
[169,]    0
[170,]    0
[171,]    1
[172,]    0
[173,]    0
[174,]    0
[175,]    0
[176,]    0
[177,]    0
[178,]    0
[179,]    0
[180,]    0
[181,]    0
[182,]    0
[183,]    0
[184,]    0
[185,]    0
[186,]    0
[187,]    0
[188,]    0
[189,]    0
[190,]    0
[191,]    0
[192,]    0
[193,]    0
[194,]    0
[195,]    0
[196,]    0
[197,]    0
[198,]    0
[199,]    0
[200,]    0
[201,]    0

$upperbound
       [,1]
  [1,]    4
  [2,]    4
  [3,]    4
  [4,]    5
  [5,]    5
  [6,]    5
  [7,]    5
  [8,]    5
  [9,]    6
 [10,]    6
 [11,]    7
 [12,]    7
 [13,]    8
 [14,]    9
 [15,]    9
 [16,]    9
 [17,]   10
 [18,]   10
 [19,]   11
 [20,]   11
 [21,]   11
 [22,]   11
 [23,]   11
 [24,]   11
 [25,]   11
 [26,]   11
 [27,]   11
 [28,]   11
 [29,]   11
 [30,]   10
 [31,]    9
 [32,]    9
 [33,]    8
 [34,]    7
 [35,]    6
 [36,]    6
 [37,]    5
 [38,]    4
 [39,]    5
 [40,]    4
 [41,]    5
 [42,]    5
 [43,]    4
 [44,]    4
 [45,]    3
 [46,]    3
 [47,]    3
 [48,]    4
 [49,]    4
 [50,]    4
 [51,]    4
 [52,]    4
 [53,]    4
 [54,]    4
 [55,]    4
 [56,]    4
 [57,]    4
 [58,]    5
 [59,]    5
 [60,]    6
 [61,]    5
 [62,]    6
 [63,]    6
 [64,]    6
 [65,]    8
 [66,]    8
 [67,]    8
 [68,]    9
 [69,]    9
 [70,]   10
 [71,]   10
 [72,]   11
 [73,]   11
 [74,]   11
 [75,]   12
 [76,]   11
 [77,]   11
 [78,]   11
 [79,]   11
 [80,]   10
 [81,]   10
 [82,]    9
 [83,]    9
 [84,]    8
 [85,]    7
 [86,]    7
 [87,]    6
 [88,]    6
 [89,]    5
 [90,]    4
 [91,]    4
 [92,]    5
 [93,]    4
 [94,]    4
 [95,]    4
 [96,]    4
 [97,]    4
 [98,]    3
 [99,]    4
[100,]    4
[101,]    4
[102,]    4
[103,]    4
[104,]    4
[105,]    3
[106,]    3
[107,]    3
[108,]    4
[109,]    5
[110,]    5
[111,]    6
[112,]    6
[113,]    6
[114,]    6
[115,]    6
[116,]    7
[117,]    7
[118,]    8
[119,]    8
[120,]    9
[121,]   10
[122,]   10
[123,]   10
[124,]   11
[125,]   12
[126,]   12
[127,]   14
[128,]   17
[129,]   19
[130,]   22
[131,]   23
[132,]   20
[133,]   17
[134,]   14
[135,]   10
[136,]    7
[137,]    7
[138,]    6
[139,]    6
[140,]    5
[141,]    5
[142,]    5
[143,]    5
[144,]    5
[145,]    4
[146,]    4
[147,]    4
[148,]    4
[149,]    4
[150,]    3
[151,]    4
[152,]    3
[153,]    4
[154,]    4
[155,]    5
[156,]    4
[157,]    4
[158,]    4
[159,]    4
[160,]    4
[161,]    5
[162,]    5
[163,]    5
[164,]    6
[165,]    5
[166,]    5
[167,]    6
[168,]    7
[169,]    7
[170,]    8
[171,]    8
[172,]   10
[173,]   13
[174,]   17
[175,]   20
[176,]   24
[177,]   25
[178,]   24
[179,]   24
[180,]   24
[181,]   24
[182,]   23
[183,]   23
[184,]   19
[185,]   17
[186,]   13
[187,]   10
[188,]    8
[189,]    8
[190,]    7
[191,]    7
[192,]    6
[193,]    5
[194,]    5
[195,]    5
[196,]    4
[197,]    4
[198,]    4
[199,]    4
[200,]    4
[201,]    3

$disProgObj
-- An object of class disProg -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 

Head of observed:
[1] 1

$control
$control$funcName
[1] "bayes"

$control$range
  [1] 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217
 [19] 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235
 [37] 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253
 [55] 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271
 [73] 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289
 [91] 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307
[109] 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325
[127] 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343
[145] 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361
[163] 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379
[181] 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397
[199] 398 399 400

$control$b
[1] 1

$control$w
[1] 5

$control$actY
[1] TRUE

$control$alpha
[1] 0.05

$control$name
[1] "bayes(5,5,1)"

$control$data
[1] "disProgObj"


attr(,"class")
[1] "survRes"
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("algo.call", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("algo.cdc")
> ### * algo.cdc
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: algo.cdc
> ### Title: The CDC Algorithm
> ### Aliases: algo.cdcLatestTimepoint algo.cdc
> ### Keywords: classif
> 
> ### ** Examples
> 
> # Create a test object
> disProgObj <- sim.pointSource(p = 0.99, r = 0.5, length = 500, 
+                               A = 1,alpha = 1, beta = 0, phi = 0,
+                               frequency = 1, state = NULL, K = 1.7)
> 
> # Test week 200 to 208 for outbreaks with a selfdefined cdc
> algo.cdc(disProgObj, control = list(range = 400:500,alpha=0.025))
$alarm
       [,1]
  [1,]    0
  [2,]    0
  [3,]    0
  [4,]    0
  [5,]    0
  [6,]    0
  [7,]    0
  [8,]    0
  [9,]    0
 [10,]    0
 [11,]    0
 [12,]    0
 [13,]    1
 [14,]    1
 [15,]    1
 [16,]    1
 [17,]    0
 [18,]    0
 [19,]    0
 [20,]    0
 [21,]    0
 [22,]    0
 [23,]    0
 [24,]    0
 [25,]    0
 [26,]    0
 [27,]    0
 [28,]    0
 [29,]    0
 [30,]    0
 [31,]    0
 [32,]    0
 [33,]    0
 [34,]    0
 [35,]    0
 [36,]    0
 [37,]    0
 [38,]    0
 [39,]    0
 [40,]    0
 [41,]    0
 [42,]    0
 [43,]    0
 [44,]    0
 [45,]    0
 [46,]    0
 [47,]    0
 [48,]    0
 [49,]    0
 [50,]    0
 [51,]    0
 [52,]    0
 [53,]    0
 [54,]    0
 [55,]    0
 [56,]    0
 [57,]    0
 [58,]    0
 [59,]    0
 [60,]    0
 [61,]    0
 [62,]    0
 [63,]    0
 [64,]    0
 [65,]    0
 [66,]    0
 [67,]    0
 [68,]    0
 [69,]    0
 [70,]    0
 [71,]    0
 [72,]    0
 [73,]    0
 [74,]    0
 [75,]    0
 [76,]    0
 [77,]    0
 [78,]    0
 [79,]    0
 [80,]    0
 [81,]    0
 [82,]    0
 [83,]    0
 [84,]    0
 [85,]    0
 [86,]    0
 [87,]    0
 [88,]    0
 [89,]    0
 [90,]    0
 [91,]    0
 [92,]    0
 [93,]    0
 [94,]    0
 [95,]    0
 [96,]    0
 [97,]    0
 [98,]    0
 [99,]    0
[100,]    0
[101,]    0

$upperbound
             [,1]
  [1,]  10.533695
  [2,]   8.922510
  [3,]   9.044215
  [4,]   9.533996
  [5,]   9.921405
  [6,]   9.472499
  [7,]   9.068488
  [8,]  10.994002
  [9,]  10.803788
 [10,]  10.968432
 [11,]  13.917722
 [12,]  13.748650
 [13,]  14.937285
 [14,]  16.618035
 [15,]  18.437560
 [16,]  16.874586
 [17,]  19.050595
 [18,]  21.287788
 [19,]  25.505502
 [20,]  29.250444
 [21,]  32.432697
 [22,]  35.966990
 [23,]  38.891378
 [24,]  42.158259
 [25,]  42.067511
 [26,]  51.965874
 [27,]  75.954741
 [28,] 100.303770
 [29,] 121.963130
 [30,] 127.637926
 [31,] 112.260147
 [32,] 114.914689
 [33,] 125.483327
 [34,] 127.600438
 [35,] 112.718708
 [36,] 115.083453
 [37,] 124.656481
 [38,] 123.658217
 [39,]  95.176684
 [40,]  72.861632
 [41,]  47.859765
 [42,]  26.621273
 [43,]  24.601240
 [44,]  20.825153
 [45,]  19.106705
 [46,]  15.217629
 [47,]  14.828627
 [48,]  11.682399
 [49,]  12.006424
 [50,]  11.357922
 [51,]  10.567818
 [52,]   8.868485
 [53,]  10.834622
 [54,]   8.846327
 [55,]   8.446327
 [56,]   8.764931
 [57,]   9.483835
 [58,]   9.225135
 [59,]   9.252113
 [60,]  11.248422
 [61,]  17.719801
 [62,]  19.595277
 [63,]  19.654813
 [64,]  21.304168
 [65,]  20.405110
 [66,]  22.472994
 [67,]  21.842892
 [68,]  22.491052
 [69,]  22.250841
 [70,]  24.649178
 [71,]  27.807083
 [72,]  30.460437
 [73,]  32.361617
 [74,]  36.197662
 [75,]  39.062565
 [76,]  43.235971
 [77,]  43.218487
 [78,]  52.625695
 [79,]  75.821484
 [80,] 100.435324
 [81,] 122.242056
 [82,] 127.770226
 [83,] 112.251286
 [84,] 114.826134
 [85,] 125.717612
 [86,] 127.685618
 [87,] 112.745752
 [88,] 114.961750
 [89,] 124.854932
 [90,] 123.771856
 [91,]  95.383513
 [92,]  73.633039
 [93,]  48.782757
 [94,]  28.234002
 [95,]  25.492769
 [96,]  23.232203
 [97,]  22.091835
 [98,]  17.782283
 [99,]  16.093250
[100,]  12.359238
[101,]  11.802473

$disProgObj
-- An object of class disProg -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 

Head of observed:
[1] 1

$control
$control$range
  [1] 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417
 [19] 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435
 [37] 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453
 [55] 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471
 [73] 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489
 [91] 490 491 492 493 494 495 496 497 498 499 500

$control$alpha
[1] 0.025

$control$b
[1] 5

$control$m
[1] 1

$control$name
[1] "cdc(4*,0,5)"

$control$data
[1] "disProgObj"


$aggr
       [,1]
  [1,]    0
  [2,]    1
  [3,]    3
  [4,]    4
  [5,]    4
  [6,]    3
  [7,]    2
  [8,]    1
  [9,]    3
 [10,]    5
 [11,]    7
 [12,]    8
 [13,]   22
 [14,]   25
 [15,]   22
 [16,]   25
 [17,]   13
 [18,]   12
 [19,]   14
 [20,]   14
 [21,]   14
 [22,]   15
 [23,]   22
 [24,]   22
 [25,]   23
 [26,]   26
 [27,]   26
 [28,]   33
 [29,]   35
 [30,]   37
 [31,]   34
 [32,]   28
 [33,]   32
 [34,]   25
 [35,]   24
 [36,]   24
 [37,]   18
 [38,]   21
 [39,]   22
 [40,]   24
 [41,]   24
 [42,]   19
 [43,]   14
 [44,]   10
 [45,]    9
 [46,]   10
 [47,]   10
 [48,]   10
 [49,]    6
 [50,]    5
 [51,]    4
 [52,]    2
 [53,]    3
 [54,]    2
 [55,]    3
 [56,]    2
 [57,]    1
 [58,]    2
 [59,]    3
 [60,]    7
 [61,]    9
 [62,]   13
 [63,]   12
 [64,]    9
 [65,]   11
 [66,]    6
 [67,]    5
 [68,]    4
 [69,]    3
 [70,]    7
 [71,]   12
 [72,]   14
 [73,]   13
 [74,]   19
 [75,]   19
 [76,]   21
 [77,]   25
 [78,]   22
 [79,]   23
 [80,]   38
 [81,]   39
 [82,]   36
 [83,]   37
 [84,]   26
 [85,]   24
 [86,]   24
 [87,]   25
 [88,]   23
 [89,]   22
 [90,]   21
 [91,]   16
 [92,]   14
 [93,]   14
 [94,]   13
 [95,]   16
 [96,]   13
 [97,]    9
 [98,]    9
 [99,]    5
[100,]    7
[101,]    9

attr(,"class")
[1] "survRes"
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("algo.cdc", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("algo.compare")
> ### * algo.compare
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: algo.compare
> ### Title: Comparison of Specified Surveillance Systems using Quality
> ###   Values
> ### Aliases: algo.compare
> ### Keywords: classif
> 
> ### ** Examples
> 
> # Create a test object
> disProgObj <- sim.pointSource(p = 0.99, r = 0.5, length = 400,
+                               A = 1, alpha = 1, beta = 0, phi = 0,
+                               frequency = 1, state = NULL, K = 1.7)
> 
> # Let this object be tested from any methods in range = 200:400
> range <- 200:400
> survRes <- algo.call(disProgObj,
+                      control = list(
+                          list(funcName = "rki1", range = range),
+                          list(funcName = "rki2", range = range),
+                          list(funcName = "rki3", range = range),
+                          list(funcName = "rki", range = range,
+                               b = 3, w = 2, actY = FALSE),
+                          list(funcName = "rki", range = range,
+                               b = 2, w = 9, actY = TRUE),
+                          list(funcName = "bayes1", range = range),
+                          list(funcName = "bayes2", range = range),
+                          list(funcName = "bayes3", range = range),
+                          list(funcName = "bayes",
+                               range = range, b = 1, w = 5, actY = TRUE,alpha=0.05)
+                      ))
> algo.compare(survRes)
             TP FP TN  FN sens      spec      dist       mlag
rki(6,6,0)   4  4  191 2  0.6666667 0.9794872 0.3339639  0   
rki(6,6,1)   6  2  193 0  1         0.9897436 0.01025641 0   
rki(4,0,2)   6  2  193 0  1         0.9897436 0.01025641 0   
rki(2,0,3)   6  2  193 0  1         0.9897436 0.01025641 0   
rki(9,9,2)   6  2  193 0  1         0.9897436 0.01025641 0   
bayes(6,6,0) 5  7  188 1  0.8333333 0.9641026 0.1704887  0   
bayes(6,6,1) 6  2  193 0  1         0.9897436 0.01025641 0   
bayes(4,0,2) 6  3  192 0  1         0.9846154 0.01538462 0   
bayes(5,5,1) 6  3  192 0  1         0.9846154 0.01538462 0   
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("algo.compare", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("algo.cusum")
> ### * algo.cusum
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: algo.cusum
> ### Title: CUSUM method
> ### Aliases: algo.cusum
> ### Keywords: classif
> 
> ### ** Examples
> 
> # Xi ~ Po(5), i=1,...,500
> set.seed(321)
> stsObj <- sts(observed = rpois(500,lambda=5))
> # there should be no alarms as mean doesn't change
> res <- cusum(stsObj, control = list(range = 100:500, trans = "anscombe"))
> plot(res, xaxis.labelFormat = NULL)
> 
> # simulated data
> disProgObj <- sim.pointSource(p = 1, r = 1, length = 250,
+                               A = 0, alpha = log(5), beta = 0, phi = 10,
+                               frequency = 10, state = NULL, K = 0)
> plot(disProgObj)
> 
> # Test weeks 200 to 250 for outbreaks
> surv0 <- algo.cusum(disProgObj, control = list(range = 200:250))
> plot(surv0, xaxis.years = FALSE)
> 
> # alternatively, using the newer "sts" interface
> stsObj <- disProg2sts(disProgObj)
> surv <- cusum(stsObj, control = list(range = 200:250))
> plot(surv)
> stopifnot(upperbound(surv) == surv0$upperbound)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("algo.cusum", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("algo.farrington")
> ### * algo.farrington
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: algo.farrington
> ### Title: Surveillance for Count Time Series Using the Classic Farrington
> ###   Method
> ### Aliases: algo.farrington farrington
> ### Keywords: classif
> 
> ### ** Examples
> 
> #load "disProg" data
> data("salmonella.agona")
> 
> #Do surveillance for the last 42 weeks
> n <- length(salmonella.agona$observed)
> control <- list(b=4,w=3,range=(n-42):n,reweight=TRUE, verbose=FALSE,alpha=0.01)
> res <- algo.farrington(salmonella.agona,control=control)
> plot(res)
> 
> #Generate Poisson counts and create an "sts" object
> set.seed(123)
> x <- rpois(520,lambda=1)
> stsObj <- sts(observed=x, frequency=52)
> 
> if (surveillance.options("allExamples")) {
+ #Compare timing of the two possible fitters for algo.farrington
+   range <- 312:520
+   system.time( sts1 <- farrington(stsObj, control=list(range=range,
+                          fitFun="algo.farrington.fitGLM.fast"), verbose=FALSE))
+   system.time( sts2 <- farrington(stsObj, control=list(range=range,
+                          fitFun="algo.farrington.fitGLM"), verbose=FALSE))
+   #Check if results are the same
+   stopifnot(upperbound(sts1) == upperbound(sts2))
+ }
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("algo.farrington", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("algo.glrnb")
> ### * algo.glrnb
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: algo.glrnb
> ### Title: Count Data Regression Charts
> ### Aliases: algo.glrnb algo.glrpois
> ### Keywords: classif
> 
> ### ** Examples
> 
> ##Simulate data and apply the algorithm
> S <- 1 ; t <- 1:120 ; m <- length(t)
> beta <- c(1.5,0.6,0.6)
> omega <- 2*pi/52
> #log mu_{0,t}
> base <- beta[1] + beta[2] * cos(omega*t) + beta[3] * sin(omega*t)
> #Generate example data with changepoint and tau=tau
> tau <- 100
> kappa <- 0.4
> mu0 <- exp(base)
> mu1 <- exp(base  + kappa)
> 
> 
> ## Poisson example
> #Generate data
> set.seed(42)
> x <- rpois(length(t),mu0*(exp(kappa)^(t>=tau)))
> s.ts <- sts(observed=x, state=(t>=tau))
> #Plot the data
> plot(s.ts, xaxis.labelFormat=NULL)
> #Run
> cntrl = list(range=t,c.ARL=5, Mtilde=1, mu0=mu0,
+              change="intercept",ret="value",dir="inc")
> glr.ts <- glrpois(s.ts,control=cntrl)
> plot(glr.ts, xaxis.labelFormat=NULL, dx.upperbound=0.5)
> lr.ts  <- glrpois(s.ts,control=c(cntrl,theta=0.4))
> plot(lr.ts, xaxis.labelFormat=NULL, dx.upperbound=0.5)
> 
> #using the legacy interface for "disProg" data
> lr.ts0  <- algo.glrpois(sts2disProg(s.ts), control=c(cntrl,theta=0.4))
> stopifnot(upperbound(lr.ts) == lr.ts0$upperbound)
> 
> 
> ## NegBin example
> #Generate data
> set.seed(42)
> alpha <- 0.2
> x <- rnbinom(length(t),mu=mu0*(exp(kappa)^(t>=tau)),size=1/alpha)
> s.ts <- sts(observed=x, state=(t>=tau))
> 
> #Plot the data
> plot(s.ts, xaxis.labelFormat=NULL)
> 
> #Run GLR based detection
> cntrl = list(range=t,c.ARL=5, Mtilde=1, mu0=mu0, alpha=alpha,
+              change="intercept",ret="value",dir="inc")
> glr.ts <- glrnb(s.ts, control=cntrl)
> plot(glr.ts, xaxis.labelFormat=NULL, dx.upperbound=0.5)
> 
> #CUSUM LR detection with backcalculated number of cases
> cntrl2 = list(range=t,c.ARL=5, Mtilde=1, mu0=mu0, alpha=alpha,
+               change="intercept",ret="cases",dir="inc",theta=1.2)
> glr.ts2 <- glrnb(s.ts, control=cntrl2)
> plot(glr.ts2, xaxis.labelFormat=NULL)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("algo.glrnb", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("algo.hmm")
> ### * algo.hmm
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: algo.hmm
> ### Title: Hidden Markov Model (HMM) method
> ### Aliases: algo.hmm
> ### Keywords: classif
> 
> ### ** Examples
> 
> #Simulate outbreak data from HMM
> set.seed(123)
> counts <- sim.pointSource(p = 0.98, r = 0.8, length = 3*52,
+                               A = 1, alpha = 1, beta = 0, phi = 0,
+                               frequency = 1, state = NULL, K = 1.5)
> 
> ## Not run: 
> ##D #Do surveillance using a two state HMM without trend component and
> ##D #the effect of the harmonics being the same in both states. A sliding
> ##D #window of two years is used to fit the HMM
> ##D surv <- algo.hmm(counts, control=list(range=(2*52):length(counts$observed),
> ##D                                    Mtilde=2*52,noStates=2,trend=FALSE,
> ##D                                    covEffectsEqual=TRUE,extraMSMargs=list()))
> ##D plot(surv,legend.opts=list(x="topright"))
> ## End(Not run)
> 
> if (require("msm")) {
+ #Retrospective use of the function, i.e. monitor only the last time point
+ #but use option saveHMMs to store the output of the HMM fitting
+ surv <- algo.hmm(counts,control=list(range=length(counts$observed),Mtilde=-1,noStates=2,
+                           trend=FALSE,covEffectsEqual=TRUE, saveHMMs=TRUE))
+ 
+ #Compute most probable state using the viterbi algorithm - 1 is "normal", 2 is "outbreak".
+ viterbi.msm(surv$control$hmms[[1]])$fitted
+ 
+ #How often correct?
+ tab <- cbind(truth=counts$state + 1 ,
+              hmm=viterbi.msm(surv$control$hmm[[1]])$fitted)
+ table(tab[,1],tab[,2])
+ }
Loading required package: msm
i=1 (out of 1)
   
      1   2
  1 142   0
  2   1  13
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("algo.hmm", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()

detaching ‘package:msm’

> nameEx("algo.outbreakP")
> ### * algo.outbreakP
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: algo.outbreakP
> ### Title: Semiparametric surveillance of outbreaks
> ### Aliases: algo.outbreakP calc.outbreakP.statistic
> ### Keywords: classif
> 
> ### ** Examples
> 
> #Use data from outbreakP manual (http://www.hgu.gu.se/item.aspx?id=16857)
> y <- matrix(c(1,0,3,1,2,3,5,4,7,3,5,8,16,23,33,34,48),ncol=1)
> 
> #Generate sts object with these observations
> mysts <- sts(y, alarm=y*0)
> 
> #Run the algorithm and present results
> #Only the value of outbreakP statistic
> upperbound(outbreakP(mysts, control=list(range=1:length(y),k=100,
+            ret="value")))
         observed1
 [1,] 1.000000e+00
 [2,] 1.000000e+00
 [3,] 4.271484e+00
 [4,] 2.621440e+00
 [5,] 3.035664e+00
 [6,] 5.224278e+00
 [7,] 2.927288e+01
 [8,] 4.762310e+01
 [9,] 5.650812e+02
[10,] 2.486477e+02
[11,] 4.335553e+02
[12,] 4.718875e+03
[13,] 1.319796e+08
[14,] 2.287919e+15
[15,] 6.435270e+26
[16,] 2.007350e+36
[17,] 7.533165e+51
> 
> #Graphical illustration with number-needed-before-alarm (NNBA) upperbound.
> res <- outbreakP(mysts, control=list(range=1:length(y),k=100,
+            ret="cases"))
> plot(res,dx.upperbound=0,lwd=c(1,1,3),legend.opts=list(legend=c("Infected",
+       "NNBA","Outbreak","Alarm"),horiz=TRUE))
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("algo.outbreakP", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("algo.quality")
> ### * algo.quality
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: algo.quality
> ### Title: Computation of Quality Values for a Surveillance System Result
> ### Aliases: algo.quality xtable.algoQV
> ### Keywords: misc
> 
> ### ** Examples
> 
> # Create a test object
> disProgObj <- sim.pointSource(p = 0.99, r = 0.5, length = 200, A = 1,
+                               alpha = 1, beta = 0, phi = 0,
+                               frequency = 1, state = NULL, K = 1.7)
> 
> # Let this object be tested from rki1
> survResObj <- algo.rki1(disProgObj, control = list(range = 50:200))
> 
> # Compute the list of quality values
> quality <- algo.quality(survResObj)
> quality # the list is printed in matrix form
     TP FP TN  FN Sens Spec      dist       mlag
[1,] 3  6  142 0  1    0.9594595 0.04054054 0   
> 
> ## Don't show: 
> .opt <- options(xtable.comment = FALSE)
> ## End(Don't show)
> # Format as an "xtable", which is printed with LaTeX markup (by default)
> library("xtable")
> xtable(quality)
\begin{table}[ht]
\centering
\begin{tabular}{rrrrrrrrr}
  \hline
 & TP & FP & TN & FN & sens & spec & dist & mlag \\ 
  \hline
1 & 3.00 & 6.00 & 142.00 & 0.00 & 1.00 & 0.96 & 0.04 & 0.00 \\ 
   \hline
\end{tabular}
\end{table}
> ## Don't show: 
> options(.opt)
> ## End(Don't show)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("algo.quality", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("algo.rki")
> ### * algo.rki
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: algo.rki
> ### Title: The system used at the RKI
> ### Aliases: algo.rkiLatestTimepoint algo.rki algo.rki1 algo.rki2 algo.rki3
> ### Keywords: classif
> 
> ### ** Examples
> 
> # Create a test object
> disProgObj <- sim.pointSource(p = 0.99, r = 0.5, length = 208, A = 1,
+                               alpha = 1, beta = 0, phi = 0,
+                               frequency = 1, state = NULL, K = 1.7)
> 
> # Test week 200 to 208 for outbreaks with a selfdefined rki
> algo.rki(disProgObj, control = list(range = 200:208, b = 1,
+                                     w = 5, actY = TRUE))
$alarm
      [,1]
 [1,]    0
 [2,]    0
 [3,]    0
 [4,]    0
 [5,]    0
 [6,]    0
 [7,]    0
 [8,]    0
 [9,]    0

$upperbound
       [,1]
 [1,] 5.323
 [2,] 5.323
 [3,] 5.323
 [4,] 5.323
 [5,] 6.686
 [6,] 5.323
 [7,] 6.686
 [8,] 6.686
 [9,] 6.686

$disProgObj
-- An object of class disProg -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 

Head of observed:
[1] 1

$control
$control$range
[1] 200 201 202 203 204 205 206 207 208

$control$b
[1] 1

$control$w
[1] 5

$control$actY
[1] TRUE

$control$name
[1] "rki(5,5,1)"

$control$data
[1] "disProgObj"


attr(,"class")
[1] "survRes"
> # The same for rki 1 to rki 3
> algo.rki1(disProgObj, control = list(range = 200:208))
$alarm
      [,1]
 [1,]    0
 [2,]    0
 [3,]    0
 [4,]    0
 [5,]    0
 [6,]    0
 [7,]    0
 [8,]    0
 [9,]    0

$upperbound
       [,1]
 [1,] 5.323
 [2,] 5.323
 [3,] 6.686
 [4,] 6.686
 [5,] 6.686
 [6,] 6.686
 [7,] 5.323
 [8,] 5.323
 [9,] 5.323

$disProgObj
-- An object of class disProg -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 

Head of observed:
[1] 1

$control
$control$range
[1] 200 201 202 203 204 205 206 207 208

$control$b
[1] 0

$control$w
[1] 6

$control$actY
[1] TRUE

$control$name
[1] "rki(6,6,0)"

$control$data
[1] "disProgObj"


attr(,"class")
[1] "survRes"
> algo.rki2(disProgObj, control = list(range = 200:208))
$alarm
      [,1]
 [1,]    0
 [2,]    0
 [3,]    0
 [4,]    0
 [5,]    0
 [6,]    0
 [7,]    0
 [8,]    0
 [9,]    0

$upperbound
       [,1]
 [1,] 5.323
 [2,] 5.323
 [3,] 5.323
 [4,] 5.323
 [5,] 6.686
 [6,] 6.686
 [7,] 6.686
 [8,] 6.686
 [9,] 6.686

$disProgObj
-- An object of class disProg -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 

Head of observed:
[1] 1

$control
$control$range
[1] 200 201 202 203 204 205 206 207 208

$control$b
[1] 1

$control$w
[1] 6

$control$actY
[1] TRUE

$control$name
[1] "rki(6,6,1)"

$control$data
[1] "disProgObj"


attr(,"class")
[1] "survRes"
> algo.rki3(disProgObj, control = list(range = 200:208))
$alarm
      [,1]
 [1,]    0
 [2,]    0
 [3,]    0
 [4,]    0
 [5,]    0
 [6,]    0
 [7,]    0
 [8,]    0
 [9,]    0

$upperbound
       [,1]
 [1,] 5.323
 [2,] 5.323
 [3,] 5.323
 [4,] 5.323
 [5,] 5.323
 [6,] 6.686
 [7,] 8.102
 [8,] 8.102
 [9,] 9.598

$disProgObj
-- An object of class disProg -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 

Head of observed:
[1] 1

$control
$control$range
[1] 200 201 202 203 204 205 206 207 208

$control$b
[1] 2

$control$w
[1] 4

$control$actY
[1] FALSE

$control$name
[1] "rki(4,0,2)"

$control$data
[1] "disProgObj"


attr(,"class")
[1] "survRes"
> 
> # Test for rki 1 the latest timepoint
> algo.rkiLatestTimepoint(disProgObj)
$alarm
[1] FALSE

$upperbound
[1] 9.598

attr(,"class")
[1] "survRes"
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("algo.rki", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("algo.rogerson")
> ### * algo.rogerson
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: algo.rogerson
> ### Title: Modified CUSUM method as proposed by Rogerson and Yamada (2004)
> ### Aliases: algo.rogerson
> ### Keywords: classif
> 
> ### ** Examples
> 
> # simulate data (seasonal Poisson)
> set.seed(123)
> t <- 1:300
> lambda <- exp(-0.5 + 0.4 * sin(2*pi*t/52) + 0.6 * cos(2*pi*t/52))
> data <- sts(observed = rpois(length(lambda), lambda))
> 
> # determine a matrix with h values
> hVals <- hValues(theta0 = 10:150/100, ARL0=500, s = 1, distr = "poisson")
> 
> # convert to legacy "disProg" class and apply modified Poisson CUSUM
> disProgObj <- sts2disProg(data)
> res <- algo.rogerson(disProgObj, control=c(hVals, list(theta0t=lambda, range=1:300)))
> plot(res, xaxis.years = FALSE)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("algo.rogerson", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("algo.summary")
> ### * algo.summary
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: algo.summary
> ### Title: Summary Table Generation for Several Disease Chains
> ### Aliases: algo.summary
> ### Keywords: print
> 
> ### ** Examples
> 
> # Create a test object
> disProgObj1 <- sim.pointSource(p = 0.99, r = 0.5, length = 400,
+                                A = 1, alpha = 1, beta = 0, phi = 0,
+                                frequency = 1, state = NULL, K = 1.7)
> disProgObj2 <- sim.pointSource(p = 0.99, r = 0.5, length = 400,
+                                A = 1, alpha = 1, beta = 0, phi = 0,
+                                frequency = 1, state = NULL, K = 5)
> disProgObj3 <- sim.pointSource(p = 0.99, r = 0.5, length = 400,
+                                A = 1, alpha = 1, beta = 0, phi = 0,
+                                frequency = 1, state = NULL, K = 17)
> 
> # Let this object be tested from any methods in range = 200:400
> range <- 200:400
> control <- list(list(funcName = "rki1", range = range),
+                 list(funcName = "rki2", range = range),
+                 list(funcName = "rki3", range = range))
> 
> compMatrix1 <- algo.compare(algo.call(disProgObj1, control=control))
> compMatrix2 <- algo.compare(algo.call(disProgObj2, control=control))
> compMatrix3 <- algo.compare(algo.call(disProgObj3, control=control))
> 
> algo.summary( list(a=compMatrix1, b=compMatrix2, c=compMatrix3) )
           TP FP  TN FN sens      spec        dist mlag
rki(6,6,0)  9 14 577  3 0.75 0.9763113 0.251119798    0
rki(6,6,1) 12  3 588  0 1.00 0.9949239 0.005076142    0
rki(4,0,2) 12  6 585  0 1.00 0.9898477 0.010152284    0
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("algo.summary", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("algo.twins")
> ### * algo.twins
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: algo.twins
> ### Title: Fit a Two-Component Epidemic Model using MCMC
> ### Aliases: algo.twins
> ### Keywords: ts regression
> 
> ### ** Examples
> 
> # Load the data used in the Held et al. (2006) paper
> data("hepatitisA")
> 
> # Fix seed - this is used for the MCMC samplers in twins
> set.seed(123)
> 
> # Call algorithm and save result (use short chain without filtering for speed)
> oldwd <- setwd(tempdir())  # where logfiles will be written
> otwins <- algo.twins(hepatitisA,
+                      control=list(burnin=500, filter=1, sampleSize=1000))
MCMC Estimation in BPLE Model v1.0.1 (using R API).
dim(x) = 208	1
logfile is in "twins.log".
logfile2 is in "twins.log2".
burnin = 500 (500)
filter = 1 (1)
sampleSize = 1000 (1000)
T = 52
nfreq = 1
alpha_xi = 10.000000
beta_xi = 10.000000
psiRWSigma = 0.250000
alpha_psi = 1.000000
beta_psi = 0.100000
nu_trend = 0
 ====== The data =======
0	0	
0	24	
0	43	
0	51	
0	61	
0	76	
0	63	
0	53	
0	32	
0	47	
0	43	
0	39	
0	33	
0	50	
0	34	
0	27	
0	18	
0	38	
0	35	
0	30	
0	39	
0	27	
0	53	
0	25	
0	32	
0	27	
0	37	
0	26	
0	26	
0	25	
0	22	
0	26	
0	34	
0	40	
0	36	
0	50	
0	57	
0	68	
0	69	
0	86	
0	58	
0	76	
0	83	
0	78	
0	49	
0	54	
0	51	
0	37	
0	43	
0	31	
0	40	
0	53	
0	17	
0	19	
0	43	
0	42	
0	34	
0	34	
0	26	
0	36	
0	32	
0	29	
0	12	
0	32	
0	23	
0	12	
0	17	
0	24	
0	19	
0	21	
0	18	
0	15	
0	19	
0	15	
0	7	
0	22	
0	25	
0	13	
0	17	
0	12	
0	7	
0	14	
0	19	
0	11	
0	10	
0	17	
0	36	
0	25	
0	38	
0	43	
0	40	
0	47	
0	41	
0	73	
0	49	
0	39	
0	32	
0	57	
0	41	
0	37	
0	47	
0	33	
0	38	
0	44	
0	24	
0	19	
0	36	
0	33	
0	31	
0	36	
0	22	
0	35	
0	36	
0	22	
0	30	
0	35	
0	25	
0	28	
0	15	
0	24	
0	19	
0	20	
0	20	
0	24	
0	20	
0	20	
0	16	
0	36	
0	22	
0	13	
0	17	
0	17	
0	15	
0	13	
0	16	
0	15	
0	16	
0	24	
0	10	
0	14	
0	25	
0	28	
0	27	
0	48	
0	31	
0	30	
0	37	
0	35	
0	36	
0	28	
0	45	
0	32	
0	32	
0	47	
0	46	
0	32	
0	15	
0	17	
0	33	
0	31	
0	33	
0	36	
0	29	
0	35	
0	28	
0	20	
0	32	
0	22	
0	25	
0	21	
0	50	
0	36	
0	37	
0	39	
0	23	
0	22	
0	27	
0	30	
0	29	
0	27	
0	13	
0	26	
0	20	
0	17	
0	23	
0	34	
0	19	
0	27	
0	22	
0	54	
0	99	
0	86	
0	99	
0	61	
0	82	
0	62	
0	69	
0	38	
0	50	
0	39	
0	38	
0	30	
0	37	
0	27	
0	33	
0	33	
0	26	
0	28	
0	27	
------------------------------------------------
psi:     Ga(1.000000, 0.100000)-->	10.000000
------------------------------------------------
Total number of samples = 500 + 1 * 1000 = 1500
..................................................
Current psiRWSigma= 0.250000 --> acc rate = 0.416000
Corrected psiRWSigma= 0.375000
..................................................
Current psiRWSigma= 0.375000 --> acc rate = 0.294000
Corrected psiRWSigma= 0.187500
..................................................
Current psiRWSigma= 0.187500 --> acc rate = 0.512000
Corrected psiRWSigma= 0.281250
..................................................
Current psiRWSigma= 0.281250 --> acc rate = 0.374000
Corrected psiRWSigma= 0.281250
.34%.35%..36%.37%..38%.39%..40%.41%..42%.43%..44%.45%..46%.47%..48%.49%..50%.51%..52%.53%..54%.55%..56%.57%..58%.59%..60%.61%..62%.63%..64%.65%..66%.67%..68%.69%..70%.71%..72%.73%..74%.75%..76%.77%..78%.79%..80%.81%..82%.83%..84%.85%..86%.87%..88%.89%..90%.91%..92%.93%..94%.95%..96%.97%..98%.99%..100%
Done with twins -- going back to R.
> setwd(oldwd)
> 
> # This shows the entire output (use ask=TRUE for pause between plots)
> plot(otwins, ask=FALSE)
> 
> # Direct access to MCMC output
> hist(otwins$logFile$psi,xlab=expression(psi),main="")
> if (require("coda")) {
+     print(summary(mcmc(otwins$logFile[,c("psi","xipsi","K")])))
+ }
Loading required package: coda

Iterations = 1:1000
Thinning interval = 1 
Number of chains = 1 
Sample size per chain = 1000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

       Mean    SD Naive SE Time-series SE
psi   21.73 4.497  0.14222          0.716
xipsi  1.00 0.000  0.00000          0.000
K     11.60 2.834  0.08962          1.218

2. Quantiles for each variable:

       2.5%   25%   50%   75% 97.5%
psi   14.35 18.63 21.02 24.36 33.25
xipsi  1.00  1.00  1.00  1.00  1.00
K      8.00  9.00 11.00 14.00 17.00

> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("algo.twins", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()

detaching ‘package:coda’

> nameEx("backprojNP")
> ### * backprojNP
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: backprojNP
> ### Title: Non-parametric back-projection of incidence cases to exposure
> ###   cases using a known incubation time as in Becker et al (1991)
> ### Aliases: backprojNP
> ### Keywords: models optimize
> 
> ### ** Examples
> 
> #Generate an artificial outbreak of size n starting at time t0 and being of length
> n <- 1e3 ; t0 <- 23 ; l <- 10
> 
> #PMF of the incubation time is an interval censored gamma distribution
> #with mean 15 truncated at 25.
> dmax <- 25
> inc.pmf <- c(0,(pgamma(1:dmax,15,1.4) - pgamma(0:(dmax-1),15,1.4))/pgamma(dmax,15,1.4))
> #Function to sample from the incubation time
> rincu <- function(n) {
+   sample(0:dmax, size=n, replace=TRUE, prob=inc.pmf)
+ }
> #Sample time of exposure and length of incubation time
> set.seed(123)
> exposureTimes <- t0 + sample(x=0:(l-1),size=n,replace=TRUE)
> symptomTimes <- exposureTimes + rincu(n)
> 
> #Time series of exposure (truth) and symptom onset (observed)
> X <- table( factor(exposureTimes,levels=1:(max(symptomTimes)+dmax)))
> Y <- table( factor(symptomTimes,levels=1:(max(symptomTimes)+dmax)))
> #Convert Y to an sts object
> Ysts <- sts(Y)
> 
> #Plot the outbreak
> plot(Ysts, xaxis.labelFormat=NULL, legend=NULL)
> #Add true number of exposures to the plot
> lines(1:length(Y)+0.2,X,col="red",type="h",lty=2)
> 
> 
> #Helper function to show the EM step
> plotIt <- function(cur.sts) {
+   plot(cur.sts,xaxis.labelFormat=NULL, legend.opts=NULL,ylim=c(0,140))
+ }
> 
> #Call non-parametric back-projection function with hook function but
> #without bootstrapped confidence intervals
> bpnp.control <- list(k=0,eps=rep(0.005,2),iter.max=rep(250,2),B=-1,hookFun=plotIt,verbose=TRUE)
> 
> #Fast C version (use argument: eq3a.method="C")! 
> sts.bp <- backprojNP(Ysts, incu.pmf=inc.pmf,
+     control=modifyList(bpnp.control,list(eq3a.method="C")), ylim=c(0,max(X,Y)))
Back-projecting with k= 0  to get lambda estimate.
Convergence criterion @ iteration i= 1 :  1.842964 
Convergence criterion @ iteration i= 2 :  0.2031237 
Convergence criterion @ iteration i= 3 :  0.08834012 
Convergence criterion @ iteration i= 4 :  0.0478789 
Convergence criterion @ iteration i= 5 :  0.02859904 
Convergence criterion @ iteration i= 6 :  0.01823245 
Convergence criterion @ iteration i= 7 :  0.01249007 
Convergence criterion @ iteration i= 8 :  0.009456387 
Convergence criterion @ iteration i= 9 :  0.008026149 
Convergence criterion @ iteration i= 10 :  0.007439062 
Convergence criterion @ iteration i= 11 :  0.007216644 
Convergence criterion @ iteration i= 12 :  0.007115377 
Convergence criterion @ iteration i= 13 :  0.007032734 
Convergence criterion @ iteration i= 14 :  0.00693317 
Convergence criterion @ iteration i= 15 :  0.006809 
Convergence criterion @ iteration i= 16 :  0.006662864 
Convergence criterion @ iteration i= 17 :  0.00650042 
Convergence criterion @ iteration i= 18 :  0.006327482 
Convergence criterion @ iteration i= 19 :  0.006149032 
Convergence criterion @ iteration i= 20 :  0.005968994 
Convergence criterion @ iteration i= 21 :  0.0057903 
Convergence criterion @ iteration i= 22 :  0.005615049 
Convergence criterion @ iteration i= 23 :  0.005444682 
Convergence criterion @ iteration i= 24 :  0.005280132 
Convergence criterion @ iteration i= 25 :  0.005121957 
Convergence criterion @ iteration i= 26 :  0.004970437 
No bootstrap CIs calculated as requested.
> 
> #Show result
> plot(sts.bp,xaxis.labelFormat=NULL,legend=NULL,lwd=c(1,1,2),lty=c(1,1,1),main="")
> lines(1:length(Y)+0.2,X,col="red",type="h",lty=2)
> 
> #Do the convolution for the expectation
> mu <- matrix(0,ncol=ncol(sts.bp),nrow=nrow(sts.bp))
> #Loop over all series
> for (j in 1:ncol(sts.bp)) { 
+   #Loop over all time points
+   for (t in 1:nrow(sts.bp)) {
+     #Convolution, note support of inc.pmf starts at zero (move idx by 1)
+     i <- seq_len(t)
+     mu[t,j] <- sum(inc.pmf[t-i+1] * upperbound(sts.bp)[i,j],na.rm=TRUE)
+   }
+ }
> #Show the fit
> lines(1:nrow(sts.bp)-0.5,mu[,1],col="green",type="s",lwd=3)
> 
> #Non-parametric back-projection including bootstrap CIs
> bpnp.control2 <- modifyList(bpnp.control, list(hookFun=NULL, k=2,
+   B=10, # in practice, use B >= 1000 !
+   eq3a.method="C"))
> sts.bp2 <- backprojNP(Ysts, incu.pmf=inc.pmf, control=bpnp.control2)
Back-projecting with k= 2  to get lambda estimate.
Convergence criterion @ iteration i= 1 :  1.831091 
Convergence criterion @ iteration i= 2 :  0.1947594 
Convergence criterion @ iteration i= 3 :  0.08059626 
Convergence criterion @ iteration i= 4 :  0.04101743 
Convergence criterion @ iteration i= 5 :  0.02263035 
Convergence criterion @ iteration i= 6 :  0.01295074 
Convergence criterion @ iteration i= 7 :  0.007533817 
Convergence criterion @ iteration i= 8 :  0.004415311 
Back-projecting with k= 0  to get lambda estimate for parametric bootstrap.
Convergence criterion @ iteration i= 1 :  1.842964 
Convergence criterion @ iteration i= 2 :  0.2031237 
Convergence criterion @ iteration i= 3 :  0.08834012 
Convergence criterion @ iteration i= 4 :  0.0478789 
Convergence criterion @ iteration i= 5 :  0.02859904 
Convergence criterion @ iteration i= 6 :  0.01823245 
Convergence criterion @ iteration i= 7 :  0.01249007 
Convergence criterion @ iteration i= 8 :  0.009456387 
Convergence criterion @ iteration i= 9 :  0.008026149 
Convergence criterion @ iteration i= 10 :  0.007439062 
Convergence criterion @ iteration i= 11 :  0.007216644 
Convergence criterion @ iteration i= 12 :  0.007115377 
Convergence criterion @ iteration i= 13 :  0.007032734 
Convergence criterion @ iteration i= 14 :  0.00693317 
Convergence criterion @ iteration i= 15 :  0.006809 
Convergence criterion @ iteration i= 16 :  0.006662864 
Convergence criterion @ iteration i= 17 :  0.00650042 
Convergence criterion @ iteration i= 18 :  0.006327482 
Convergence criterion @ iteration i= 19 :  0.006149032 
Convergence criterion @ iteration i= 20 :  0.005968994 
Convergence criterion @ iteration i= 21 :  0.0057903 
Convergence criterion @ iteration i= 22 :  0.005615049 
Convergence criterion @ iteration i= 23 :  0.005444682 
Convergence criterion @ iteration i= 24 :  0.005280132 
Convergence criterion @ iteration i= 25 :  0.005121957 
Convergence criterion @ iteration i= 26 :  0.004970437 
Bootstrap sample  1 / 10 
Convergence criterion @ iteration i= 1 :  0.03069816 
Convergence criterion @ iteration i= 2 :  0.01448365 
Convergence criterion @ iteration i= 3 :  0.01138973 
Convergence criterion @ iteration i= 4 :  0.0088825 
Convergence criterion @ iteration i= 5 :  0.006899077 
Convergence criterion @ iteration i= 6 :  0.005350269 
Convergence criterion @ iteration i= 7 :  0.00414878 
Bootstrap sample  2 / 10 
Convergence criterion @ iteration i= 1 :  0.03761089 
Convergence criterion @ iteration i= 2 :  0.01421946 
Convergence criterion @ iteration i= 3 :  0.008715432 
Convergence criterion @ iteration i= 4 :  0.006536467 
Convergence criterion @ iteration i= 5 :  0.005151208 
Convergence criterion @ iteration i= 6 :  0.004055925 
Bootstrap sample  3 / 10 
Convergence criterion @ iteration i= 1 :  0.01791799 
Convergence criterion @ iteration i= 2 :  0.01313083 
Convergence criterion @ iteration i= 3 :  0.009596378 
Convergence criterion @ iteration i= 4 :  0.00706357 
Convergence criterion @ iteration i= 5 :  0.005222114 
Convergence criterion @ iteration i= 6 :  0.003873547 
Bootstrap sample  4 / 10 
Convergence criterion @ iteration i= 1 :  0.0296806 
Convergence criterion @ iteration i= 2 :  0.01124356 
Convergence criterion @ iteration i= 3 :  0.005261372 
Convergence criterion @ iteration i= 4 :  0.002724633 
Bootstrap sample  5 / 10 
Convergence criterion @ iteration i= 1 :  0.03421202 
Convergence criterion @ iteration i= 2 :  0.006127767 
Convergence criterion @ iteration i= 3 :  0.004646345 
Bootstrap sample  6 / 10 
Convergence criterion @ iteration i= 1 :  0.03489537 
Convergence criterion @ iteration i= 2 :  0.01741871 
Convergence criterion @ iteration i= 3 :  0.01067975 
Convergence criterion @ iteration i= 4 :  0.007128054 
Convergence criterion @ iteration i= 5 :  0.005032651 
Convergence criterion @ iteration i= 6 :  0.003672013 
Bootstrap sample  7 / 10 
Convergence criterion @ iteration i= 1 :  0.02609449 
Convergence criterion @ iteration i= 2 :  0.009216108 
Convergence criterion @ iteration i= 3 :  0.004010391 
Bootstrap sample  8 / 10 
Convergence criterion @ iteration i= 1 :  0.03679822 
Convergence criterion @ iteration i= 2 :  0.02276645 
Convergence criterion @ iteration i= 3 :  0.01503013 
Convergence criterion @ iteration i= 4 :  0.01015091 
Convergence criterion @ iteration i= 5 :  0.006962184 
Convergence criterion @ iteration i= 6 :  0.004831525 
Bootstrap sample  9 / 10 
Convergence criterion @ iteration i= 1 :  0.06670921 
Convergence criterion @ iteration i= 2 :  0.003465956 
Bootstrap sample  10 / 10 
Convergence criterion @ iteration i= 1 :  0.03320252 
Convergence criterion @ iteration i= 2 :  0.01363987 
Convergence criterion @ iteration i= 3 :  0.007134633 
Convergence criterion @ iteration i= 4 :  0.004155202 
> 
> ######################################################################
> # Plot the result. This is currently a manual routine.
> # ToDo: Need to specify a plot method for stsBP objects which also
> #       shows the CI.
> #
> # Parameters:
> #  stsBP - object of class stsBP which is to be plotted.
> ######################################################################
> 
> plot.stsBP <- function(stsBP) {
+   maxy <- max(observed(stsBP),upperbound(stsBP),stsBP@ci,na.rm=TRUE)
+   plot(upperbound(stsBP),type="n",ylim=c(0,maxy), ylab="Cases",xlab="time")
+   if (!all(is.na(stsBP@ci))) {
+     polygon( c(1:nrow(stsBP),rev(1:nrow(stsBP))),
+              c(stsBP@ci[2,,1],rev(stsBP@ci[1,,1])),col="lightgray")
+   }
+   lines(upperbound(stsBP),type="l",lwd=2)
+   legend(x="topright",c(expression(lambda[t])),lty=c(1),col=c(1),fill=c(NA),border=c(NA),lwd=c(2))
+ 
+   invisible()
+ }
> 
> #Plot the result of k=0 and add truth for comparison. No CIs available
> plot.stsBP(sts.bp)
> lines(1:length(Y),X,col=2,type="h")
> #Same for k=2
> plot.stsBP(sts.bp2)
> lines(1:length(Y),X,col=2,type="h")
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("backprojNP", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("boda")
> ### * boda
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: boda
> ### Title: Bayesian Outbreak Detection Algorithm (BODA)
> ### Aliases: boda
> ### Keywords: classif
> 
> ### ** Examples
> 
> ## Not run: 
> ##D   ## running this example takes a couple of minutes
> ##D 
> ##D   #Load the campylobacteriosis data for Germany
> ##D   data("campyDE")
> ##D   #Make an sts object from the data.frame
> ##D   cam.sts <-  sts(epoch=campyDE$date,
> ##D                   observed=campyDE$case, state=campyDE$state)
> ##D 
> ##D   #Define monitoring period
> ##D #  range <- which(epoch(cam.sts)>=as.Date("2007-01-01"))
> ##D #  range <- which(epoch(cam.sts)>=as.Date("2011-12-10"))
> ##D   range <- tail(1:nrow(cam.sts),n=2)
> ##D 
> ##D   control <- list(range=range, X=NULL, trend=TRUE, season=TRUE,
> ##D                   prior='iid', alpha=0.025, mc.munu=100, mc.y=10,
> ##D                   samplingMethod = "joint")
> ##D 
> ##D   #Apply the boda algorithm in its simples form, i.e. spline is
> ##D   #described by iid random effects and no extra covariates
> ##D   library("INLA")  # needs to be attached
> ##D   cam.boda1 <- boda(cam.sts, control=control)
> ##D 
> ##D   plot(cam.boda1, xlab='time [weeks]', ylab='No. reported', dx.upperbound=0)
> ## End(Not run)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("boda", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("bodaDelay")
> ### * bodaDelay
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: bodaDelay
> ### Title: Bayesian Outbreak Detection in the Presence of Reporting Delays
> ### Aliases: bodaDelay
> 
> ### ** Examples
> 
> ## Not run: 
> ##D data("stsNewport")
> ##D salm.Normal <- list()
> ##D salmDelayAsym <- list()
> ##D for (week in 43:45){
> ##D   listWeeks <- as.Date(row.names(stsNewport@control$reportingTriangle$n))
> ##D   dateObs <- listWeeks[isoWeekYear(listWeeks)$ISOYear==2011 &
> ##D                        isoWeekYear(listWeeks)$ISOWeek==week]
> ##D   stsC <- sts_observation(stsNewport,
> ##D                           dateObservation=dateObs,
> ##D                           cut=TRUE)
> ##D   inWeeks <- with(isoWeekYear(epoch(stsC)),
> ##D                   ISOYear == 2011 & ISOWeek >= 40 & ISOWeek <= 48)
> ##D   
> ##D   rangeTest <- which(inWeeks)
> ##D   alpha <- 0.07
> ##D 
> ##D   # Control slot for Noufaily method          
> ##D   controlNoufaily <- list(range=rangeTest,noPeriods=10,
> ##D                           b=4,w=3,weightsThreshold=2.58,pastWeeksNotIncluded=26,
> ##D                           pThresholdTrend=1,thresholdMethod="nbPlugin",alpha=alpha*2,
> ##D                           limit54=c(0,50))
> ##D   
> ##D   # Control slot for the Proposed algorithm with D=0 correction
> ##D   controlNormal <- list(range = rangeTest, b = 4, w = 3,
> ##D                         reweight = TRUE, mc.munu=10000, mc.y=100,
> ##D                         verbose = FALSE,
> ##D                         alpha = alpha, trend = TRUE,
> ##D                         limit54=c(0,50), 
> ##D                         noPeriods = 10, pastWeeksNotIncluded = 26,
> ##D                         delay=FALSE)
> ##D   
> ##D   # Control slot for the Proposed algorithm with D=10 correction
> ##D   controlDelayNorm <-  list(range = rangeTest, b = 4, w = 3,
> ##D                             reweight = FALSE, mc.munu=10000, mc.y=100,
> ##D                             verbose = FALSE,
> ##D                             alpha = alpha, trend = TRUE,
> ##D                             limit54=c(0,50), 
> ##D                             noPeriods = 10, pastWeeksNotIncluded = 26,
> ##D                             delay=TRUE,inferenceMethod="asym")
> ##D   
> ##D   set.seed(1)
> ##D   salm.Normal[[week]] <- farringtonFlexible(stsC, controlNoufaily)
> ##D   salmDelayAsym[[week]] <- bodaDelay(stsC, controlDelayNorm)
> ##D }
> ##D 
> ##D opar <- par(mfrow=c(2,3))
> ##D lapply(salmDelayAsym[c(43,44,45)],plot, legend=NULL, main="", ylim=c(0,35))
> ##D lapply(salm.Normal[c(43,44,45)],plot, legend=NULL, main="", ylim=c(0,35))
> ##D par(opar)
> ## End(Not run)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("bodaDelay", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("calibration")
> ### * calibration
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: calibrationTest
> ### Title: Calibration Tests for Poisson or Negative Binomial Predictions
> ### Aliases: calibrationTest calibrationTest.default
> ### Keywords: htest
> 
> ### ** Examples
> 
> mu <- c(0.1, 1, 3, 6, pi, 100)
> size <- 0.1
> set.seed(1)
> y <- rnbinom(length(mu), mu = mu, size = size)
> calibrationTest(y, mu = mu, size = size) # p = 0.99

	Calibration Test for Count Data (based on DSS)

data:  y
z = 0.012353, n = 6, p-value = 0.9901

> calibrationTest(y, mu = mu, size = 1) # p = 4.3e-05

	Calibration Test for Count Data (based on DSS)

data:  y
z = 4.0899, n = 6, p-value = 4.316e-05

> calibrationTest(y, mu = 1, size = size) # p = 0.6959

	Calibration Test for Count Data (based on DSS)

data:  y
z = 0.39093, n = 6, p-value = 0.6959

> calibrationTest(y, mu = 1, size = size, which = "rps") # p = 0.1286

	Calibration Test for Count Data (based on RPS)

data:  y
z = 1.5197, n = 6, p-value = 0.1286

> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("calibration", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("campyDE")
> ### * campyDE
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: campyDE
> ### Title: Campylobacteriosis and Absolute Humidity in Germany 2002-2011
> ### Aliases: campyDE
> ### Keywords: datasets
> 
> ### ** Examples
> 
> # Load the data
> data("campyDE")
> 
> # O104 period is W21-W30 in 2011
> stopifnot(all(campyDE$O104period == (
+   (campyDE$date >= as.Date("2011-05-23")) &
+   (campyDE$date < as.Date("2011-07-31"))
+ )))
> 
> # Make an sts object from the data.frame
> cam.sts <- sts(epoch=campyDE$date, observed=campyDE$case, state=campyDE$state)
> 
> # Plot the result
> plot(cam.sts)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("campyDE", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("categoricalCUSUM")
> ### * categoricalCUSUM
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: categoricalCUSUM
> ### Title: CUSUM detector for time-varying categorical time series
> ### Aliases: categoricalCUSUM catcusum.LLRcompute
> ### Keywords: regression
> 
> ### ** Examples
> 
> ## IGNORE_RDIFF_BEGIN
> have_GAMLSS <- require("gamlss")
Loading required package: gamlss
Loading required package: splines
Loading required package: gamlss.data

Attaching package: ‘gamlss.data’

The following object is masked from ‘package:datasets’:

    sleep

Loading required package: gamlss.dist
Loading required package: nlme
Loading required package: parallel
 **********   GAMLSS Version 5.4-22  ********** 
For more on GAMLSS look at https://www.gamlss.com/
Type gamlssNews() to see new features/changes/bug fixes.

> ## IGNORE_RDIFF_END
> 
> if (have_GAMLSS) {
+   ###########################################################################
+   #Beta-binomial CUSUM for a small example containing the time-varying
+   #number of positive test out of a time-varying number of total
+   #test.
+   #######################################
+ 
+   #Load meat inspection data
+   data("abattoir")
+ 
+   #Use GAMLSS to fit beta-bin regression model
+   phase1 <- 1:(2*52)
+   phase2  <- (max(phase1)+1) : nrow(abattoir)
+ 
+   #Fit beta-binomial model using GAMLSS
+   abattoir.df <- as.data.frame(abattoir)
+ 
+   #Replace the observed and epoch column names to something more convenient
+   dict <- c("observed"="y", "epoch"="t", "population"="n")
+   replace <- dict[colnames(abattoir.df)]
+   colnames(abattoir.df)[!is.na(replace)] <- replace[!is.na(replace)]
+ 
+   m.bbin <- gamlss( cbind(y,n-y) ~ 1 + t +
+                       + sin(2*pi/52*t) + cos(2*pi/52*t) +
+                       + sin(4*pi/52*t) + cos(4*pi/52*t), sigma.formula=~1,
+                    family=BB(sigma.link="log"),
+                    data=abattoir.df[phase1,c("n","y","t")])
+ 
+   #CUSUM parameters
+   R <- 2 #detect a doubling of the odds for a test being positive
+   h <- 4 #threshold of the cusum
+ 
+   #Compute in-control and out of control mean
+   pi0 <- predict(m.bbin,newdata=abattoir.df[phase2,c("n","y","t")],type="response")
+   pi1 <- plogis(qlogis(pi0)+log(R))
+   #Create matrix with in control and out of control proportions.
+   #Categories are D=1 and D=0, where the latter is the reference category
+   pi0m <- rbind(pi0, 1-pi0)
+   pi1m <- rbind(pi1, 1-pi1)
+ 
+ 
+   ######################################################################
+   # Use the multinomial surveillance function. To this end it is necessary
+   # to create a new abattoir object containing counts and proportion for
+   # each of the k=2 categories. For binomial data this appears a bit
+   # redundant, but generalizes easier to k>2 categories.
+   ######################################################################
+ 
+   abattoir2 <- sts(epoch=1:nrow(abattoir), start=c(2006,1), freq=52,
+     observed=cbind(abattoir@observed, abattoir@populationFrac-abattoir@observed),
+     populationFrac=cbind(abattoir@populationFrac,abattoir@populationFrac),
+     state=matrix(0,nrow=nrow(abattoir),ncol=2),
+     multinomialTS=TRUE)
+ 
+   ######################################################################
+   #Function to use as dfun in the categoricalCUSUM
+   #(just a wrapper to the dBB function). Note that from v 3.0-1 the
+   #first argument of dBB changed its name from "y" to "x"!
+   ######################################################################
+   mydBB.cusum <- function(y, mu, sigma, size, log = FALSE) {
+     return(dBB(y[1,], mu = mu[1,], sigma = sigma, bd = size, log = log))
+   }
+ 
+ 
+   #Create control object for multinom cusum and use the categoricalCUSUM
+   #method
+   control <- list(range=phase2,h=h,pi0=pi0m, pi1=pi1m, ret="cases",
+ 		   dfun=mydBB.cusum)
+   surv <- categoricalCUSUM(abattoir2, control=control,
+ 			   sigma=exp(m.bbin$sigma.coef))
+ 
+   #Show results
+   plot(surv[,1],dx.upperbound=0)
+   lines(pi0,col="green")
+   lines(pi1,col="red")
+ 
+   #Index of the alarm
+   which.max(alarms(surv[,1]))
+ }
GAMLSS-RS iteration 1: Global Deviance = 1206.79 
GAMLSS-RS iteration 2: Global Deviance = 1171.326 
GAMLSS-RS iteration 3: Global Deviance = 1138.789 
GAMLSS-RS iteration 4: Global Deviance = 1103.163 
GAMLSS-RS iteration 5: Global Deviance = 1060.744 
GAMLSS-RS iteration 6: Global Deviance = 1005.918 
GAMLSS-RS iteration 7: Global Deviance = 930.1185 
GAMLSS-RS iteration 8: Global Deviance = 830.8562 
GAMLSS-RS iteration 9: Global Deviance = 771.4925 
GAMLSS-RS iteration 10: Global Deviance = 767.2984 
GAMLSS-RS iteration 11: Global Deviance = 767.2767 
GAMLSS-RS iteration 12: Global Deviance = 767.2766 
[1] 41
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("categoricalCUSUM", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()

detaching ‘package:gamlss’, ‘package:parallel’, ‘package:nlme’,
  ‘package:gamlss.dist’, ‘package:gamlss.data’, ‘package:splines’

> nameEx("checkResidualProcess")
> ### * checkResidualProcess
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: checkResidualProcess
> ### Title: Check the residual process of a fitted 'twinSIR' or 'twinstim'
> ### Aliases: checkResidualProcess
> ### Keywords: dplot htest
> 
> ### ** Examples
> 
> data("hagelloch")
> fit <- twinSIR(~ household, data = hagelloch)  # a simplistic model
Initialized 1 log-baseline interval:  0.00000 92.54524
Initial parameter vector:  1 0
iter   10 value 743.984462
final  value 743.982888 
converged
> ## extract the "residual process", i.e., the fitted cumulative intensities
> residuals(fit)
         1          3          4          5          7          8          9 
  4.031158  27.042831  27.638822  30.095005  42.051194  44.154779  46.030802 
        11         14         15         16         18         22         23 
 49.182641  58.266402  58.645863  65.048869  67.504758  72.977398  74.674381 
        24         25         26         27         28         29         30 
 75.336797  75.769966  76.077561  77.227846  77.496387  77.507949  77.544024 
        31         32         33         35         36         37         38 
 78.035440  78.104106  78.573872  78.858727  79.876980  80.846380  80.923944 
        39         40         41         42         43         44         45 
 81.712401  81.733724  82.583505  82.871304  82.958654  84.140272  84.429417 
        46         47         48         49         50         51         52 
 84.690093  85.060039  85.338711  85.981152  86.626602  86.780303  86.965311 
        53         54         55         56         57         58         60 
 87.992945  90.410389  90.416706  90.775526  91.200548  92.955839  94.871037 
        61         62         63         64         65         66         67 
 96.968904  99.670095 100.926117 102.021744 103.287609 104.341868 105.523148 
        69         70         73         74         75         76         77 
107.145096 108.529876 112.289608 113.311245 117.224099 118.375307 121.486300 
        78         79         80         81         82         85         86 
122.856988 124.311569 127.121769 127.364139 129.179696 135.191650 135.453672 
        87         94         95         96         98        101        106 
136.657985 141.606852 143.025873 143.279986 143.726610 144.997675 146.629707 
       108        109        111        112        113        116        118 
147.181193 147.314831 147.891725 147.984778 148.058743 148.721498 148.804293 
       120        121        123        126        127        130        131 
148.949450 149.669590 151.342507 151.973880 152.447386 153.419171 153.488947 
       132        133        134        136        137        138        139 
154.130356 154.170345 154.328129 154.502914 154.599121 154.688216 154.987190 
       141        143        145        146        147        148        150 
155.180006 155.416561 155.550191 155.997096 156.061130 156.319166 157.236373 
       153        158        159        160        161        163        164 
157.299975 157.830867 158.000706 158.238933 158.538252 158.691152 158.992490 
       165        166        167        168        169        171        172 
159.024519 159.161869 159.382423 160.596174 161.388129 162.266883 162.508720 
       173        174        177        179        181        182        184 
162.591937 162.626881 163.483004 164.693898 165.016535 165.108537 165.266781 
       185        186        187        188        190        191        192 
165.318878 165.701988 165.798480 165.824016 166.035657 166.066290 166.097318 
       193        195        196        197        198        199        200 
166.145510 166.518504 166.681095 166.740476 167.263706 168.516478 168.693015 
       201        203        205        207        208        209        211 
168.727198 168.837872 168.990164 169.269174 169.485386 169.863358 170.268372 
       213        214        215        216        217        218        219 
170.536628 170.867126 171.150342 172.247151 172.435640 172.896928 173.040921 
       220        221        222        223        224        225        226 
173.135638 173.139426 173.427026 173.667438 173.752606 174.010942 174.437769 
       228        229        230        231        235        237        238 
175.609010 176.009533 176.079930 176.355717 176.992695 177.536957 177.880080 
       241        242        243        244        265        276        279 
179.041471 179.284750 179.286131 179.500507 182.524994 182.858705 183.012782 
       304        308        333        334        336        342        343 
184.688972 184.800878 185.544008 185.606463 185.666766 185.818292 185.863958 
       345        350        357        358        374 
185.931602 186.098753 186.296775 186.320814 187.000050 
> ## assess goodness of fit based on these residuals
> checkResidualProcess(fit)  # could be better
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("checkResidualProcess", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("coeflist")
> ### * coeflist
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: coeflist
> ### Title: List Coefficients by Model Component
> ### Aliases: coeflist coeflist.default
> ### Keywords: models utilities
> 
> ### ** Examples
> 
> ## the default method just 'split's the coefficient vector
> coefs <- c(a = 1, b = 3, dispersion = 0.5)
> npars <- c(regression = 2, variance = 1)
> coeflist(coefs, npars)
$regression
a b 
1 3 

$variance
dispersion 
       0.5 

> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("coeflist", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("deleval")
> ### * deleval
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: deleval
> ### Title: Surgical Failures Data
> ### Aliases: deleval
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("deleval")
> plot(deleval, xaxis.labelFormat=NULL,ylab="Response",xlab="Patient number")
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("deleval", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("disProg2sts")
> ### * disProg2sts
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: disProg2sts
> ### Title: Convert disProg object to sts and vice versa
> ### Aliases: disProg2sts sts2disProg
> ### Keywords: utilities
> 
> ### ** Examples
> 
>   data(ha)
>   print(disProg2sts(ha))
-- An object of class sts -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 290 12 

Head of observed:
     chwi frkr lich mahe mitt neuk pank rein span zehl scho trko
[1,]    0    0    0    0    0    0    0    0    0    0    0    0
>   class(sts2disProg(disProg2sts(ha)))
[1] "disProg"
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("disProg2sts", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("discpoly")
> ### * discpoly
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: discpoly
> ### Title: Polygonal Approximation of a Disc/Circle
> ### Aliases: discpoly
> ### Keywords: datagen spatial
> 
> ### ** Examples
> 
> ## Construct circles with increasing accuracy and of different spatial classes
> disc1 <- discpoly(c(0,0), 5, npoly=4, class = "owin")
> disc2 <- discpoly(c(0,0), 5, npoly=16, class = "Polygon")
> disc3 <- discpoly(c(0,0), 5, npoly=64, class = "gpc.poly")  # may warn
Warning in discpoly(c(0, 0), 5, npoly = 64, class = "gpc.poly") :
  formal class "gpc.poly" not available
> 
> ## Look at the results
> print(disc1)
window: polygonal boundary
enclosing rectangle: [-5, 5] x [-5, 5] units
> plot(disc1, axes=TRUE, main="", border=2)
> 
> str(disc2)
Formal class 'Polygon' [package "sp"] with 5 slots
  ..@ labpt  : num [1:2] -1.55e-17 -2.82e-16
  ..@ area   : num 76.5
  ..@ hole   : logi FALSE
  ..@ ringDir: int 1
  ..@ coords : num [1:17, 1:2] 5.00 4.62 3.54 1.91 -9.18e-16 ...
> lines(disc2, col=3)
> 
> str(disc3)  # a list or a formal "gpc.poly" (if gpclib is available)
List of 1
 $ :List of 3
  ..$ x   : num [1:64] 5 4.98 4.9 4.78 4.62 ...
  ..$ y   : num [1:64] -1.22e-15 -4.90e-01 -9.75e-01 -1.45 -1.91 ...
  ..$ hole: logi FALSE
> if (is(disc3, "gpc.poly")) {
+   plot(disc3, add=TRUE, poly.args=list(border=4))
+ } else {
+   lines(disc3[[1]], col=4)
+ }
> 
> ## to only _draw_ a circle
> symbols(0, 0, circles=5, inches=FALSE, add=TRUE, fg=5)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("discpoly", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("earsC")
> ### * earsC
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: earsC
> ### Title: Surveillance for a count data time series using the EARS C1, C2
> ###   or C3 method and its extensions
> ### Aliases: earsC
> ### Keywords: classif
> 
> ### ** Examples
> 
> 
> #Sim data and convert to sts object
> disProgObj <- sim.pointSource(p = 0.99, r = 0.5, length = 208, A = 1,
+                               alpha = 1, beta = 0, phi = 0,
+                               frequency = 1, state = NULL, K = 1.7)
> stsObj <- disProg2sts( disProgObj)
> 
> 
> # Call earsC function and show result
> res1 <- earsC(stsObj, control = list(range = 20:208, method="C1"))
> plot(res1, legend.opts=list(horiz=TRUE, x="topright"))
> 
> 
> # Compare C3 upperbounds depending on alpha
> res3 <- earsC(stsObj, control = list(range = 20:208,method="C3",alpha = 0.001))
> plot(upperbound(res3), type='l')
> res3 <- earsC(stsObj, control = list(range = 20:208,method="C3"))
> lines(upperbound(res3), col='red')
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("earsC", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("epidata")
> ### * epidata
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: epidata
> ### Title: Continuous-Time SIR Event History of a Fixed Population
> ### Aliases: as.epidata as.epidata.data.frame as.epidata.default
> ###   print.epidata [.epidata update.epidata epidata
> ### Keywords: spatial classes manip
> 
> ### ** Examples
> 
> data("hagelloch")   # see help("hagelloch") for a description
> head(hagelloch.df)
  PN    NAME FN HN AGE    SEX        PRO        ERU        CL DEAD IFTO SI
1  1 Mueller 41 61   7 female 1861-11-21 1861-11-25 1st class <NA>   45 10
2  2 Mueller 41 61   6 female 1861-11-23 1861-11-27 1st class <NA>   45 12
3  3 Mueller 41 61   4 female 1861-11-28 1861-12-02 preschool <NA>  172  9
4  4 Seibold 61 62  13   male 1861-11-27 1861-11-28 2nd class <NA>  180 10
5  5  Motzer 42 63   8 female 1861-11-22 1861-11-27 1st class <NA>   45 11
6  6  Motzer 42 63  12   male 1861-11-26 1861-11-29 2nd class <NA>  180  9
                 C PR CA NI GE TD   TM x.loc y.loc     tPRO     tERU tDEAD
1  no complicatons  4  4  3  1 NA   NA 142.5 100.0 22.71242 26.22541    NA
2  no complicatons  4  4  3  1  3 40.3 142.5 100.0 24.21169 28.79112    NA
3  no complicatons  4  4  3  2  1 40.5 142.5 100.0 29.59102 33.69121    NA
4  no complicatons  1  1  1  1  3 40.7 165.0 102.5 28.11698 29.02866    NA
5  no complicatons  5  3  2  1 NA   NA 145.0 120.0 23.05953 28.41510    NA
6 bronchopneumonia  3  3  2  1  2 40.7 145.0 120.0 27.95444 30.23918    NA
        tR       tI
1 29.22541 21.71242
2 31.79112 23.21169
3 36.69121 28.59102
4 32.02866 27.11698
5 31.41510 22.05953
6 33.23918 26.95444
> 
> ## convert the original data frame to an "epidata" event history
> myEpi <- as.epidata(hagelloch.df, t0 = 0,
+                     tI.col = "tI", tR.col = "tR", id.col = "PN",
+                     coords.cols = c("x.loc", "y.loc"),
+                     keep.cols = c("SEX", "AGE", "CL"))
> ## Don't show: 
> if (surveillance.options("allExamples")) {
+ ## test consistency with default method
+ evHist <- as.data.frame(myEpi)[,-1]
+ myEpi2 <- as.epidata(
+     evHist, id.col = 1, start.col = "start", stop.col = "stop",
+     atRiskY.col = "atRiskY", event.col = "event", Revent.col = "Revent",
+     coords.cols = c("x.loc", "y.loc")
+ )
+ stopifnot(identical(myEpi, myEpi2))
+ }
> ## End(Don't show)
> 
> str(myEpi)
Classes ‘epidata’ and 'data.frame':	70500 obs. of  12 variables:
 $ BLOCK  : int  1 1 1 1 1 1 1 1 1 1 ...
 $ id     : Factor w/ 188 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8 9 10 ...
 $ start  : num  0 0 0 0 0 0 0 0 0 0 ...
 $ stop   : num  1.14 1.14 1.14 1.14 1.14 ...
 $ atRiskY: num  1 1 1 1 1 1 1 1 1 1 ...
 $ event  : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Revent : num  0 0 0 0 0 0 0 0 0 0 ...
 $ x.loc  : num  142 142 142 165 145 ...
 $ y.loc  : num  100 100 100 102 120 ...
 $ SEX    : Factor w/ 2 levels "male","female": 2 2 2 1 2 1 1 1 1 2 ...
 $ AGE    : num  7 6 4 13 8 12 6 10 13 7 ...
 $ CL     : Factor w/ 3 levels "preschool","1st class",..: 2 2 1 3 2 3 1 2 3 2 ...
 - attr(*, "eventTimes")= num [1:187] 1.14 7.47 7.63 8.25 11.29 ...
 - attr(*, "timeRange")= num [1:2] 0 92.5
 - attr(*, "coords.cols")= int [1:2] 8 9
 - attr(*, "f")= list()
 - attr(*, "w")= list()
> head(as.data.frame(myEpi))  # "epidata" has event history format
  BLOCK id start     stop atRiskY event Revent x.loc y.loc    SEX AGE        CL
1     1  1     0 1.136356       1     0      0 142.5 100.0 female   7 1st class
2     1  2     0 1.136356       1     0      0 142.5 100.0 female   6 1st class
3     1  3     0 1.136356       1     0      0 142.5 100.0 female   4 preschool
4     1  4     0 1.136356       1     0      0 165.0 102.5   male  13 2nd class
5     1  5     0 1.136356       1     0      0 145.0 120.0 female   8 1st class
6     1  6     0 1.136356       1     0      0 145.0 120.0   male  12 2nd class
> summary(myEpi)              # see 'summary.epidata'

AN SIR EPIDEMIC
  Time range: 0 -- 92.5452383686788 
  Number of individuals: 188 
  1 initially infected individuals:
    "184"
  0 never infected individuals
  Size of the epidemic: 187 

$ counters ('data.frame', 376 x 6 ): evolution of the epidemic:
         time type  id nSusceptible nInfectious nRemoved
1    0.000000                   187           1        0
2    1.136356    I 173          186           2        0
3    7.197762    R 173          186           1        1
       [....]                                           
375 85.688298    I 141            0           1      187
376 92.545238    R 141            0           0      188

> plot(myEpi)                 # see 'plot.epidata' and also 'animate.epidata'
> 
> 
> ## add distance- and covariate-based weights for the force of infection
> ## in a twinSIR model, see vignette("twinSIR") for a description
> myEpi <- update(myEpi,
+     f = list(
+         household    = function(u) u == 0,
+         nothousehold = function(u) u > 0
+     ),
+     w = list(
+         c1 = function (CL.i, CL.j) CL.i == "1st class" & CL.j == CL.i,
+         c2 = function (CL.i, CL.j) CL.i == "2nd class" & CL.j == CL.i
+     )
+ )
> ## this is now identical to the prepared hagelloch "epidata"
> stopifnot(all.equal(myEpi, hagelloch))
> 
> ## Don't show: 
> if (surveillance.options("allExamples")) {
+ ## test with precomputed distance matrix D
+ myEpi3 <- suppressWarnings( # from overwriting existing f columns
+     update(hagelloch, f = attr(hagelloch, "f"),
+            D = as.matrix(dist(hagelloch.df[c("x.loc", "y.loc")])))
+ )
+ stopifnot(identical(hagelloch, myEpi3))
+ }
> ## End(Don't show)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("epidata", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("epidataCS")
> ### * epidataCS
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: epidataCS
> ### Title: Continuous Space-Time Marked Point Patterns with Grid-Based
> ###   Covariates
> ### Aliases: epidataCS as.epidataCS print.epidataCS nobs.epidataCS
> ###   head.epidataCS tail.epidataCS [.epidataCS subset.epidataCS
> ###   marks.epidataCS summary.epidataCS print.summary.epidataCS
> ###   as.stepfun.epidataCS getSourceDists
> ###   coerce,epidataCS,SpatialPointsDataFrame-method
> ### Keywords: spatial classes manip
> 
> ### ** Examples
> 
> ## load "imdepi" example data (which is an object of class "epidataCS")
> data("imdepi")
> 
> ## print and summary
> print(imdepi, n=5, digits=2)
Observation period: 0 - 2557 
Observation window (bounding box): [4031, 4672] x [2684, 3550] 
Spatio-temporal grid (not shown): 84 time blocks x 413 tiles 
Types of events: "B" "C"
Overall number of events: 636

   coordinates  time  tile type eps.t eps.s    sex   agegrp BLOCK start
1 (4100, 3200)  0.21 05554    B    30   200   male   [3,19)     1     0
2 (4100, 3100)  0.71 05382    C    30   200   male   [3,19)     1     0
3 (4400, 2900)  5.59 09574    B    30   200 female [19,Inf)     1     0
4 (4200, 2900)  7.12 08212    B    30   200 female   [3,19)     1     0
5 (4100, 3200) 22.06 05554    C    30   200   male   [3,19)     1     0
  popdensity
1        261
2        519
3        209
4       1666
5        261
[....]
> print(s <- summary(imdepi))
Observation period: 0 - 2557 
Observation window (bounding box): [4031.295, 4672.253] x [2684.102, 3549.931] 
Spatio-temporal grid (not shown): 84 time blocks x 413 tiles 
Overall number of events: 636 (2 types)

Summary of event marks and number of potential sources:
      time                tile     type        eps.t        eps.s    
 Min.   :   0.2117   05354  : 34   B:336   Min.   :30   Min.   :200  
 1st Qu.: 539.4753   05370  : 27   C:300   1st Qu.:30   1st Qu.:200  
 Median :1154.9527   11000  : 27           Median :30   Median :200  
 Mean   :1192.6813   05358  : 13           Mean   :30   Mean   :200  
 3rd Qu.:1808.0295   05162  : 12           3rd Qu.:30   3rd Qu.:200  
 Max.   :2542.7800   05382  : 12           Max.   :30   Max.   :200  
                     (Other):511                                     
     sex           agegrp          x              y          |.sources|    
 female:292   [0,3)   :194   Min.   :4039   Min.   :2710   Min.   : 0.000  
 male  :339   [3,19)  :279   1st Qu.:4101   1st Qu.:2967   1st Qu.: 0.000  
 NA's  :  5   [19,Inf):162   Median :4206   Median :3106   Median : 1.000  
              NA's    :  1   Mean   :4244   Mean   :3092   Mean   : 1.634  
                             3rd Qu.:4361   3rd Qu.:3194   3rd Qu.: 2.000  
                             Max.   :4665   Max.   :3525   Max.   :14.000  
                                                                           
> plot(s$counter,  # same as 'as.stepfun(imdepi)'
+      xlab = "Time [days]", ylab="Number of infectious individuals",
+      main=paste("Time course of the number of infectious individuals",
+                 "assuming an infectious period of 30 days", sep="\n"))
> plot(table(s$nSources), xlab="Number of \"close\" infective individuals",
+      ylab="Number of events",
+      main=paste("Distribution of the number of potential sources",
+                 "assuming an interaction range of 200 km and 30 days",
+                 sep="\n"))
> ## the summary object contains further information
> str(s)
List of 14
 $ timeRange  : num [1:2] 0 2557
 $ bbox       : num [1:2, 1:2] 4031 2684 4672 3550
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:2] "x" "y"
  .. ..$ : chr [1:2] "min" "max"
 $ nBlocks    : int 84
 $ nEvents    : int 636
 $ nTypes     : int 2
 $ eventTimes : num [1:636] 0.212 0.712 5.591 7.117 22.06 ...
 $ eventCoords: num [1:636, 1:2] 4112 4123 4412 4203 4128 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:636] "1" "2" "3" "4" ...
  .. ..$ : chr [1:2] "x" "y"
 $ eventTypes : Factor w/ 2 levels "B","C": 1 2 1 1 2 2 2 2 2 2 ...
 $ eventRanges:'data.frame':	636 obs. of  2 variables:
  ..$ eps.t: num [1:636] 30 30 30 30 30 30 30 30 30 30 ...
  ..$ eps.s: num [1:636] 200 200 200 200 200 200 200 200 200 200 ...
 $ eventMarks :'data.frame':	636 obs. of  9 variables:
  ..$ time  : num [1:636] 0.212 0.712 5.591 7.117 22.06 ...
  ..$ tile  : Factor w/ 413 levels "01001","01002",..: 95 91 291 195 95 79 94 327 289 5 ...
  ..$ type  : Factor w/ 2 levels "B","C": 1 2 1 1 2 2 2 2 2 2 ...
  ..$ eps.t : num [1:636] 30 30 30 30 30 30 30 30 30 30 ...
  ..$ eps.s : num [1:636] 200 200 200 200 200 200 200 200 200 200 ...
  ..$ sex   : Factor w/ 2 levels "female","male": 2 2 1 1 2 2 2 1 2 NA ...
  ..$ agegrp: Factor w/ 3 levels "[0,3)","[3,19)",..: 2 2 3 2 2 2 2 2 3 1 ...
  ..$ x     : num [1:636] 4112 4123 4412 4203 4128 ...
  ..$ y     : num [1:636] 3203 3077 2916 2880 3223 ...
 $ tileTable  : Named int [1:413] 2 2 2 2 2 1 0 0 1 0 ...
  ..- attr(*, "names")= chr [1:413] "01001" "01002" "01003" "01004" ...
 $ typeTable  : Named int [1:2] 336 300
  ..- attr(*, "names")= chr [1:2] "B" "C"
 $ counter    :function (v)  
  ..- attr(*, "class")= chr [1:2] "stepfun" "function"
  ..- attr(*, "call")= language stepfun(tps, c(0, nInfectious), right = TRUE)
 $ nSources   : int [1:636] 0 0 0 0 1 2 2 0 0 0 ...
 - attr(*, "class")= chr "summary.epidataCS"
> 
> ## a histogram of the spatial distances to potential source events
> ## (i.e., to events of the previous eps.t=30 days within eps.s=200 km)
> sourceDists_space <- getSourceDists(imdepi, "space")
> hist(sourceDists_space); rug(sourceDists_space)
> 
> ## internal structure of an "epidataCS"-object
> str(imdepi, max.level=4)
List of 4
 $ events :Formal class 'SpatialPointsDataFrame' [package "sp"] with 5 slots
  .. ..@ data       :'data.frame':	636 obs. of  14 variables:
  .. .. ..$ time            : num [1:636] 0.212 0.712 5.591 7.117 22.06 ...
  .. .. ..$ tile            : Factor w/ 413 levels "01001","01002",..: 95 91 291 195 95 79 94 327 289 5 ...
  .. .. ..$ type            : Factor w/ 2 levels "B","C": 1 2 1 1 2 2 2 2 2 2 ...
  .. .. ..$ eps.t           : num [1:636] 30 30 30 30 30 30 30 30 30 30 ...
  .. .. ..$ eps.s           : num [1:636] 200 200 200 200 200 200 200 200 200 200 ...
  .. .. ..$ sex             : Factor w/ 2 levels "female","male": 2 2 1 1 2 2 2 1 2 NA ...
  .. .. ..$ agegrp          : Factor w/ 3 levels "[0,3)","[3,19)",..: 2 2 3 2 2 2 2 2 3 1 ...
  .. .. ..$ BLOCK           : int [1:636] 1 1 1 1 1 1 2 2 2 2 ...
  .. .. ..$ start           : num [1:636] 0 0 0 0 0 0 31 31 31 31 ...
  .. .. ..$ popdensity      : num [1:636] 261 519 209 1666 261 ...
  .. .. ..$ .obsInfLength   : num [1:636] 30 30 30 30 30 30 30 30 30 30 ...
  .. .. ..$ .sources        :List of 636
  .. .. ..$ .bdist          : num [1:636] 13.2 66.6 94.4 12.4 19.2 ...
  .. .. ..$ .influenceRegion:List of 636
  .. .. .. ..- attr(*, "nCircle2Poly")= int 16
  .. .. .. ..- attr(*, "clipper")= chr "polyclip"
  .. ..@ coords.nrs : num(0) 
  .. ..@ coords     : num [1:636, 1:2] 4112 4123 4412 4203 4128 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. ..@ bbox       : num [1:2, 1:2] 4039 2710 4665 3525
  .. .. ..- attr(*, "dimnames")=List of 2
  .. ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slot
 $ stgrid :'data.frame':	34692 obs. of  6 variables:
  ..$ BLOCK     : int [1:34692] 1 1 1 1 1 1 1 1 1 1 ...
  ..$ start     : num [1:34692] 0 0 0 0 0 0 0 0 0 0 ...
  ..$ stop      : num [1:34692] 31 31 31 31 31 31 31 31 31 31 ...
  ..$ tile      : Factor w/ 413 levels "01001","01002",..: 1 2 3 4 5 6 7 8 9 10 ...
  ..$ area      : num [1:34692] 56.4 118.7 214.2 71.6 1428 ...
  ..$ popdensity: num [1:34692] 1557.1 1996.6 987.6 1083.3 95.6 ...
 $ W      :Formal class 'SpatialPolygons' [package "sp"] with 4 slots
  .. ..@ polygons   :List of 1
  .. .. ..$ :Formal class 'Polygons' [package "sp"] with 5 slots
  .. ..@ plotOrder  : int 1
  .. ..@ bbox       : num [1:2, 1:2] 4031 2684 4672 3550
  .. .. ..- attr(*, "dimnames")=List of 2
  .. ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slot
  .. ..$ comment: chr "TRUE"
 $ qmatrix: logi [1:2, 1:2] TRUE FALSE FALSE TRUE
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:2] "B" "C"
  .. ..$ : chr [1:2] "B" "C"
 - attr(*, "class")= chr "epidataCS"
> ## see help("imdepi") for more info on the data set
> 
> ## extraction methods subset the 'events' component
> imdepi[101:200,]
Observation period: 0 - 2557 
Observation window (bounding box): [4031.295, 4672.253] x [2684.102, 3549.931] 
Spatio-temporal grid (not shown): 84 time blocks x 413 tiles 
Types of events: "B" "C"
Overall number of events: 100

             coordinates     time  tile type eps.t eps.s    sex   agegrp BLOCK
101 (4052.863, 3096.593) 353.4000 05354    B    30   200 female [19,Inf)    12
102 (4556.355, 3262.682) 357.6672 11000    B    30   200   male   [3,19)    12
103 (4141.513, 3157.541) 358.5114 05913    C    30   200 female   [3,19)    12
104 (4417.974, 2759.005) 360.0455 09188    C    30   200 female    [0,3)    12
105 (4442.943, 2793.727) 363.5171 09184    C    30   200   male    [0,3)    12
106 (4072.581, 3119.168) 364.1096 05116    C    30   200   male    [0,3)    12
    start popdensity
101   334   567.2927
102   334  3834.0946
103   334  2093.0388
104   334   265.3942
105   334   472.7581
106   334  1525.4796
[....]
> head(imdepi, n=1)           # only first event
Observation period: 0 - 2557 
Observation window (bounding box): [4031.295, 4672.253] x [2684.102, 3549.931] 
Spatio-temporal grid (not shown): 84 time blocks x 413 tiles 
Types of events: "B" "C"
Overall number of events: 1

           coordinates      time  tile type eps.t eps.s  sex agegrp BLOCK start
1 (4112.188, 3202.792) 0.2116949 05554    B    30   200 male [3,19)     1     0
  popdensity
1   260.8612
> tail(imdepi, n=4)           # only last 4 events
Observation period: 0 - 2557 
Observation window (bounding box): [4031.295, 4672.253] x [2684.102, 3549.931] 
Spatio-temporal grid (not shown): 84 time blocks x 413 tiles 
Types of events: "B" "C"
Overall number of events: 4

             coordinates     time  tile type eps.t eps.s    sex   agegrp BLOCK
633 (4560.554, 3269.564) 2536.542 11000    B    30   200 female   [3,19)    84
634 (4561.184, 3429.911) 2539.270 13059    C    30   200   male   [3,19)    84
635 (4054.178, 3077.449) 2540.896 05354    B    30   200 female [19,Inf)    84
636 (4338.578, 2995.313) 2542.780 09662    C    30   200 female   [3,19)    84
    start popdensity
633  2526  3834.0946
634  2526    56.5969
635  2526   567.2927
636  2526  1506.5248
> subset(imdepi, type=="B")   # only events of type B
Note: dropped type(s) "C"
Observation period: 0 - 2557 
Observation window (bounding box): [4031.295, 4672.253] x [2684.102, 3549.931] 
Spatio-temporal grid (not shown): 84 time blocks x 413 tiles 
Types of events: "B"
Overall number of events: 336

            coordinates       time  tile type eps.t eps.s    sex   agegrp BLOCK
1  (4112.188, 3202.792)  0.2116949 05554    B    30   200   male   [3,19)     1
3  (4412.466, 2915.939)  5.5910231 09574    B    30   200 female [19,Inf)     1
4  (4202.635, 2879.698)  7.1169826 08212    B    30   200 female   [3,19)     1
11  (4044.47, 3080.435) 44.5433853 05313    B    30   200   male   [3,19)     2
13 (4134.103, 3038.831) 56.3224294 07137    B    30   200   male [19,Inf)     2
14 (4116.286, 3073.816) 56.4273666 05314    B    30   200 female   [3,19)     2
   start popdensity
1      0   260.8612
3      0   209.4464
4      0  1665.6117
11    31  1610.5826
13    31   260.5648
14    31  2240.5892
[....]
> 
> ## see help("plot.epidataCS") for convenient plot-methods for "epidataCS"
> 
> 
> ###
> ### reconstruct the "imdepi" object
> ###
> 
> ## observation region
> load(system.file("shapes", "districtsD.RData", package="surveillance"),
+      verbose = TRUE)
Loading objects:
  districtsD
  stateD
> 
> ## extract point pattern of events from the "imdepi" data
> ## a) as a data frame with coordinate columns via marks()
> eventsData <- marks(imdepi)
> ## b) as a Spatial object via the coerce-method
> events <- as(imdepi, "SpatialPointsDataFrame")
> 
> ## plot observation region with events (may require package 'sf')
> if (requireNamespace("sf")) {
+   plot(stateD, axes=TRUE); title(xlab="x [km]", ylab="y [km]")
+   points(events, pch=unclass(events$type), cex=0.5, col=unclass(events$type))
+   legend("topright", legend=levels(events$type), title="Type", pch=1:2, col=1:2)
+ 
+   summary(events)
+ }
Loading required namespace: sf
Object of class SpatialPointsDataFrame
Coordinates:
       min      max
x 4038.570 4665.246
y 2710.255 3524.959
Is projected: TRUE 
proj4string :
[+proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80
+units=km +no_defs]
Number of points: 636
Data attributes:
      time                tile     type        eps.t        eps.s    
 Min.   :   0.2117   05354  : 34   B:336   Min.   :30   Min.   :200  
 1st Qu.: 539.4753   05370  : 27   C:300   1st Qu.:30   1st Qu.:200  
 Median :1154.9527   11000  : 27           Median :30   Median :200  
 Mean   :1192.6813   05358  : 13           Mean   :30   Mean   :200  
 3rd Qu.:1808.0295   05162  : 12           3rd Qu.:30   3rd Qu.:200  
 Max.   :2542.7800   05382  : 12           Max.   :30   Max.   :200  
                     (Other):511                                     
     sex           agegrp   
 female:292   [0,3)   :194  
 male  :339   [3,19)  :279  
 NA's  :  5   [19,Inf):162  
              NA's    :  1  
                            
                            
                            
> 
> ## space-time grid with endemic covariates
> head(stgrid <- imdepi$stgrid[,-1])
  start stop  tile    area popdensity
1     0   31 01001   56.38 1557.14792
2     0   31 01002  118.65 1996.64560
3     0   31 01003  214.20  987.58637
4     0   31 01004   71.63 1083.27516
5     0   31 01051 1428.01   95.55325
6     0   31 01053 1262.99  148.13577
> 
> ## reconstruct the "imdepi" object from its components
> myimdepi <- as.epidataCS(events = events, stgrid = stgrid,
+                          W = stateD, qmatrix = diag(2), nCircle2Poly = 16)
> 
> ## This reconstructed object should be equal to 'imdepi' as long as the internal
> ## structures of the embedded classes ("owin", "SpatialPolygons", ...), and
> ## the calculation of the influence regions by "polyclip" have not changed:
> all.equal(imdepi, myimdepi)
[1] TRUE
> ## Don't show: 
> if (surveillance.options("allExamples"))
+ stopifnot(all.equal(imdepi, myimdepi))
> ## End(Don't show)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("epidataCS", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("epidataCS_aggregate")
> ### * epidataCS_aggregate
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: epidataCS_aggregate
> ### Title: Conversion (aggregation) of '"epidataCS"' to '"epidata"' or
> ###   '"sts"'
> ### Aliases: epidataCS2sts as.epidata.epidataCS
> ### Keywords: spatial manip methods
> 
> ### ** Examples
> 
> data("imdepi")
> load(system.file("shapes", "districtsD.RData", package="surveillance"))
> 
> ## convert imdepi point pattern into multivariate time series
> imdsts <- epidataCS2sts(imdepi, freq = 12, start = c(2002, 1),
+                         neighbourhood = NULL, # not needed here
+                         tiles = districtsD)
> 
> ## check the overall number of events by district
> stopifnot(all.equal(colSums(observed(imdsts)),
+                     c(table(imdepi$events$tile))))
> 
> ## compare plots of monthly number of cases
> opar <- par(mfrow = c(2, 1))
> plot(imdepi, "time")
> plot(imdsts, type = observed ~ time)
> par(opar)
> 
> ## plot number of cases by district
> plot(imdsts, type = observed ~ unit)
> 
> ## also test conversion to an SIS event history ("epidata") of the "tiles"
> if (requireNamespace("intervals")) {
+     imdepi_short <- subset(imdepi, time < 50)  # to reduce the runtime
+     imdepi_short$stgrid <- subset(imdepi_short$stgrid, start < 50)
+     imdepidata <- as.epidata(imdepi_short,
+                              tileCentroids = coordinates(districtsD))
+     summary(imdepidata)
+ }
Loading required namespace: intervals
Inserting extra stop times in 'stgrid' (this might take a while) ... Done.
Generating final "epidata" object for use with twinSIR ... Done.

AN SIS EPIDEMIC
  Time range: 0 -- 59 
  Number of individuals: 413 
  0 initially infected individuals
  402 never infected individuals:
    "01001" "01002" "01003" "01004" "01053" "01054" "01055" "01056" "01057" "01058"
    "01059" "01060" "01061" "01062" "02000" "03101" "03102" "03103" "03151"
    "03152" "03153" "03154" "03155" "03156" "03157" "03158" "03241" "03251"
    "03252" "03254" "03255" "03256" "03257" "03351" "03352" "03353" "03354"
    "03355" "03356" "03357" "03358" "03359" "03360" "03361" "03401" "03402"
    "03403" "03404" "03405" "03451" "03452" "03453" "03454" "03455" "03456"
    "03457" "03458" "03459" "03460" "03461" "03462" "04011" "04012" "05111"
    "05112" "05113" "05114" "05116" "05117" "05119" "05120" "05122" "05124"
    "05154" "05158" "05162" "05166" "05314" "05315" "05316" "05354" "05358"
    "05362" "05366" "05370" "05374" "05378" "05512" "05513" "05558" "05562"
    "05566" "05570" "05754" "05758" "05762" "05766" "05770" "05774" "05911"
  Size of the epidemic: 11 
  Number of infections: 11 

$ counters ('data.frame', 22 x 6 ): evolution of the epidemic:
         time type    id nSusceptible nInfectious nRemoved
1   0.0000000                     413           0        0
2   0.2116949    I 05554          412           1        0
3   0.7124225    I 05382          411           2        0
       [....]                                             
21 54.9544435    R 05170          406           6        1
22 54.9544435    S 05170          407           6        0

> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("epidataCS_aggregate", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("epidataCS_animate")
> ### * epidataCS_animate
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: epidataCS_animate
> ### Title: Spatio-Temporal Animation of a Continuous-Time Continuous-Space
> ###   Epidemic
> ### Aliases: animate.epidataCS
> ### Keywords: hplot dynamic spatial
> 
> ### ** Examples
> 
> data("imdepi")
> imdepiB <- subset(imdepi, type == "B")
Note: dropped type(s) "C"
> 
> ## Not run: 
> ##D # Animate the first year of type B with a step size of 7 days
> ##D animate(imdepiB, interval=c(0,365), time.spacing=7, nmax=Inf, sleep=0.1)
> ##D 
> ##D # Sequential animation of type B events during the first year
> ##D animate(imdepiB, interval=c(0,365), time.spacing=NULL, sleep=0.1)
> ##D 
> ##D # Animate the whole time range but with nmax=20 snapshots only
> ##D animate(imdepiB, time.spacing=NA, nmax=20, sleep=0.1)
> ## End(Not run)
> 
> # Such an animation can be saved in various ways using the tools of
> # the animation package, e.g., saveHTML()
> if (interactive() && require("animation")) {
+   oldwd <- setwd(tempdir())  # to not clutter up the current working dir
+   saveHTML(animate(imdepiB, interval = c(0,365), time.spacing = 7),
+            nmax = Inf, interval = 0.2, loop = FALSE,
+            title = "Animation of the first year of type B events")
+   setwd(oldwd)
+ }
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("epidataCS_animate", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("epidataCS_permute")
> ### * epidataCS_permute
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: epidataCS_permute
> ### Title: Randomly Permute Time Points or Locations of '"epidataCS"'
> ### Aliases: permute.epidataCS
> ### Keywords: manip
> 
> ### ** Examples
> 
> data("imdepi")
> 
> set.seed(3)
> permepi <- permute.epidataCS(imdepi, what = "time", keep = time <= 30)
> 
> print(imdepi, n = 8)
Observation period: 0 - 2557 
Observation window (bounding box): [4031.295, 4672.253] x [2684.102, 3549.931] 
Spatio-temporal grid (not shown): 84 time blocks x 413 tiles 
Types of events: "B" "C"
Overall number of events: 636

           coordinates       time  tile type eps.t eps.s    sex   agegrp BLOCK
1 (4112.188, 3202.792)  0.2116949 05554    B    30   200   male   [3,19)     1
2  (4122.508, 3076.97)  0.7124225 05382    C    30   200   male   [3,19)     1
3 (4412.466, 2915.939)  5.5910231 09574    B    30   200 female [19,Inf)     1
4 (4202.635, 2879.698)  7.1169826 08212    B    30   200 female   [3,19)     1
5 (4128.335, 3223.314) 22.0595327 05554    C    30   200   male   [3,19)     1
6 (4089.915, 3178.005) 24.9544435 05170    C    30   200   male   [3,19)     1
7 (4151.791, 3211.446) 31.4718945 05515    C    30   200   male   [3,19)     2
8  (4539.07, 3273.842) 35.1075810 11000    C    30   200 female   [3,19)     2
  start popdensity
1     0   260.8612
2     0   519.3570
3     0   209.4464
4     0  1665.6117
5     0   260.8612
6     0   454.7456
7    31   901.0663
8    31  3834.0946
[....]
> print(permepi, n = 8)
Observation period: 0 - 2557 
Observation window (bounding box): [4031.295, 4672.253] x [2684.102, 3549.931] 
Spatio-temporal grid (not shown): 84 time blocks x 413 tiles 
Types of events: "B" "C"
Overall number of events: 636

             coordinates       time  tile type eps.t eps.s    sex   agegrp
1   (4112.188, 3202.792)  0.2116949 05554    B    30   200   male   [3,19)
2    (4122.508, 3076.97)  0.7124225 05382    C    30   200   male   [3,19)
3   (4412.466, 2915.939)  5.5910231 09574    B    30   200 female [19,Inf)
4   (4202.635, 2879.698)  7.1169826 08212    B    30   200 female   [3,19)
5   (4128.335, 3223.314) 22.0595327 05554    C    30   200   male   [3,19)
6   (4089.915, 3178.005) 24.9544435 05170    C    30   200   male   [3,19)
271 (4047.116, 3112.675) 31.4718945 05370    B    30   200 female   [3,19)
242 (4107.549, 3092.563) 35.1075810 05315    B    30   200   male [19,Inf)
    BLOCK start popdensity
1       1     0   260.8612
2       1     0   519.3570
3       1     0   209.4464
4       1     0  1665.6117
5       1     0   260.8612
6       1     0   454.7456
271     2    31   408.9903
242     2    31  2456.7998
[....]
> ## the first 6 events are kept (as are all row.names),
> ## the time labels of the remaining events are shuffled
> ## (and events then again sorted by time),
> ## the marginal temporal distribution is unchanged
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("epidataCS_permute", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("epidataCS_plot")
> ### * epidataCS_plot
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: epidataCS_plot
> ### Title: Plotting the Events of an Epidemic over Time and Space
> ### Aliases: plot.epidataCS epidataCSplot_time epidataCSplot_space
> ### Keywords: hplot methods spatial
> 
> ### ** Examples
> 
> data("imdepi")
> 
> ## show the occurrence of events along time
> plot(imdepi, "time", main = "Histogram of event time points")
> plot(imdepi, "time", by = NULL, main = "Aggregated over both event types")
> 
> ## show the distribution in space
> plot(imdepi, "space", lwd = 2, col = "lavender")
> 
> ## with the district-specific population density in the background,
> ## a scale bar, and customized point style
> load(system.file("shapes", "districtsD.RData", package = "surveillance"))
> districtsD$log10popdens <- log10(districtsD$POPULATION/districtsD$AREA)
> keylabels <- (c(1,2,5) * rep(10^(1:3), each=3))[-1]
> plot(imdepi, "space", tiles = districtsD, pop = "log10popdens",
+      ## modify point style for better visibility on gray background
+      points.args = list(pch=c(1,3), col=c("orangered","blue"), lwd=2),
+      ## metric scale bar, see proj4string(imdepi$W)
+      sp.layout = layout.scalebar(imdepi$W, scale=100, labels=c("0","100 km")),
+      ## gray scale for the population density and white borders
+      col.regions = gray.colors(100, start=0.9, end=0.1), col = "white",
+      ## color key is equidistant on log10(popdens) scale
+      at = seq(1.3, 3.7, by=0.05),
+      colorkey = list(labels=list(at=log10(keylabels), labels=keylabels),
+                      title=expression("Population density per " * km^2)))
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("epidataCS_plot", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("epidataCS_update")
> ### * epidataCS_update
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: epidataCS_update
> ### Title: Update method for '"epidataCS"'
> ### Aliases: update.epidataCS
> ### Keywords: manip utilities methods
> 
> ### ** Examples
> 
> data("imdepi")
> 
> ## assume different interaction ranges and simplify polygons
> imdepi2 <- update(imdepi, eps.t = 20, eps.s = Inf, nCircle2Poly = 16)
>     
> (s <- summary(imdepi))
Observation period: 0 - 2557 
Observation window (bounding box): [4031.295, 4672.253] x [2684.102, 3549.931] 
Spatio-temporal grid (not shown): 84 time blocks x 413 tiles 
Overall number of events: 636 (2 types)

Summary of event marks and number of potential sources:
      time                tile     type        eps.t        eps.s    
 Min.   :   0.2117   05354  : 34   B:336   Min.   :30   Min.   :200  
 1st Qu.: 539.4753   05370  : 27   C:300   1st Qu.:30   1st Qu.:200  
 Median :1154.9527   11000  : 27           Median :30   Median :200  
 Mean   :1192.6813   05358  : 13           Mean   :30   Mean   :200  
 3rd Qu.:1808.0295   05162  : 12           3rd Qu.:30   3rd Qu.:200  
 Max.   :2542.7800   05382  : 12           Max.   :30   Max.   :200  
                     (Other):511                                     
     sex           agegrp          x              y          |.sources|    
 female:292   [0,3)   :194   Min.   :4039   Min.   :2710   Min.   : 0.000  
 male  :339   [3,19)  :279   1st Qu.:4101   1st Qu.:2967   1st Qu.: 0.000  
 NA's  :  5   [19,Inf):162   Median :4206   Median :3106   Median : 1.000  
              NA's    :  1   Mean   :4244   Mean   :3092   Mean   : 1.634  
                             3rd Qu.:4361   3rd Qu.:3194   3rd Qu.: 2.000  
                             Max.   :4665   Max.   :3525   Max.   :14.000  
                                                                           
> (s2 <- summary(imdepi2))
Observation period: 0 - 2557 
Observation window (bounding box): [4031.295, 4672.253] x [2684.102, 3549.931] 
Spatio-temporal grid (not shown): 84 time blocks x 413 tiles 
Overall number of events: 636 (2 types)

Summary of event marks and number of potential sources:
      time                tile     type        eps.t        eps.s    
 Min.   :   0.2117   05354  : 34   B:336   Min.   :20   Min.   :Inf  
 1st Qu.: 539.4753   05370  : 27   C:300   1st Qu.:20   1st Qu.:Inf  
 Median :1154.9527   11000  : 27           Median :20   Median :Inf  
 Mean   :1192.6813   05358  : 13           Mean   :20   Mean   :Inf  
 3rd Qu.:1808.0295   05162  : 12           3rd Qu.:20   3rd Qu.:Inf  
 Max.   :2542.7800   05382  : 12           Max.   :20   Max.   :Inf  
                     (Other):511                                     
     sex           agegrp          x              y          |.sources|    
 female:292   [0,3)   :194   Min.   :4039   Min.   :2710   Min.   : 0.000  
 male  :339   [3,19)  :279   1st Qu.:4101   1st Qu.:2967   1st Qu.: 1.000  
 NA's  :  5   [19,Inf):162   Median :4206   Median :3106   Median : 2.000  
              NA's    :  1   Mean   :4244   Mean   :3092   Mean   : 2.854  
                             3rd Qu.:4361   3rd Qu.:3194   3rd Qu.: 4.000  
                             Max.   :4665   Max.   :3525   Max.   :14.000  
                                                                           
> ## The update reduced the number of infectives (along time)
> ## because the length of the infectious periods is reduced. It also 
> ## changed the set of potential sources of transmission for each
> ## event, since the interaction is shorter in time but wider in space
> ## (eps.s=Inf means interaction over the whole observation region).
> 
> ## use a time-constant grid
> imdepi3 <- update(imdepi, stgrid = subset(imdepi$stgrid, BLOCK == 1, -stop))
> (s3 <- summary(imdepi3)) # "1 time block"
Observation period: 0 - 2557 
Observation window (bounding box): [4031.295, 4672.253] x [2684.102, 3549.931] 
Spatio-temporal grid (not shown): 1 time block, x 413 tiles 
Overall number of events: 636 (2 types)

Summary of event marks and number of potential sources:
      time                tile     type        eps.t        eps.s    
 Min.   :   0.2117   05354  : 34   B:336   Min.   :30   Min.   :200  
 1st Qu.: 539.4753   05370  : 27   C:300   1st Qu.:30   1st Qu.:200  
 Median :1154.9527   11000  : 27           Median :30   Median :200  
 Mean   :1192.6813   05358  : 13           Mean   :30   Mean   :200  
 3rd Qu.:1808.0295   05162  : 12           3rd Qu.:30   3rd Qu.:200  
 Max.   :2542.7800   05382  : 12           Max.   :30   Max.   :200  
                     (Other):511                                     
     sex           agegrp          x              y          |.sources|    
 female:292   [0,3)   :194   Min.   :4039   Min.   :2710   Min.   : 0.000  
 male  :339   [3,19)  :279   1st Qu.:4101   1st Qu.:2967   1st Qu.: 0.000  
 NA's  :  5   [19,Inf):162   Median :4206   Median :3106   Median : 1.000  
              NA's    :  1   Mean   :4244   Mean   :3092   Mean   : 1.634  
                             3rd Qu.:4361   3rd Qu.:3194   3rd Qu.: 2.000  
                             Max.   :4665   Max.   :3525   Max.   :14.000  
                                                                           
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("epidataCS_update", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("epidata_animate")
> ### * epidata_animate
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: epidata_animate
> ### Title: Spatio-Temporal Animation of an Epidemic
> ### Aliases: animate.epidata animate.summary.epidata
> ### Keywords: hplot dynamic spatial
> 
> ### ** Examples
> 
> data("hagelloch")
> (s <- summary(hagelloch))

AN SIR EPIDEMIC
  Time range: 0 -- 92.5452383686788 
  Number of individuals: 188 
  1 initially infected individuals:
    "184"
  0 never infected individuals
  Size of the epidemic: 187 

$ counters ('data.frame', 376 x 6 ): evolution of the epidemic:
         time type  id nSusceptible nInfectious nRemoved
1    0.000000                   187           1        0
2    1.136356    I 173          186           2        0
3    7.197762    R 173          186           1        1
       [....]                                           
375 85.688298    I 141            0           1      187
376 92.545238    R 141            0           0      188

> 
> # plot the ordering of the events only
> animate(s)   # or: animate(hagelloch)
> 
> # with timer (animate only up to t=10)
> animate(s, time.spacing=0.1, end=10, sleep=0.01,
+         legend.opts=list(x="topleft"))
> 
> # Such an animation can be saved in various ways using tools of
> # the animation package, e.g., saveHTML()
> if (interactive() && require("animation")) {
+   oldwd <- setwd(tempdir())  # to not clutter up the current working dir
+   saveHTML({
+     par(bg="white")  # default "transparent" is grey in some browsers
+     animate(s, time.spacing=1, sleep=0, legend.opts=list(x="topleft"),
+             generate.snapshots="epiani")
+   }, use.dev=FALSE, img.name="epiani", ani.width=600, interval=0.5)
+   setwd(oldwd)
+ }
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("epidata_animate", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("epidata_intersperse")
> ### * epidata_intersperse
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: epidata_intersperse
> ### Title: Impute Blocks for Extra Stops in '"epidata"' Objects
> ### Aliases: intersperse
> ### Keywords: spatial manip
> 
> ### ** Examples
> 
> data("hagelloch")
> subset(hagelloch, start < 25 & stop > 25 & id %in% 9:13, select = 1:7)
Note: converted class "epidata" to simple "data.frame"
      BLOCK id    start     stop atRiskY event Revent
12417    67  9 24.89708 25.04317       1     0      0
12418    67 10 24.89708 25.04317       0     0      0
12419    67 11 24.89708 25.04317       1     1      0
12420    67 12 24.89708 25.04317       0     0      0
12421    67 13 24.89708 25.04317       1     0      0
> # there is no "stop" time at 25, but we can add this extra stop
> nrow(hagelloch)
[1] 70500
> moreStopsEpi <- intersperse(hagelloch, stoptimes = 25)
> nrow(moreStopsEpi)
[1] 70688
> subset(moreStopsEpi, (stop == 25 | start == 25) & id %in% 9:13, select = 1:7)
Note: converted class "epidata" to simple "data.frame"
      BLOCK id    start     stop atRiskY event Revent
12417    67  9 24.89708 25.00000       1     0      0
12418    67 10 24.89708 25.00000       0     0      0
12419    67 11 24.89708 25.00000       1     0      0
12420    67 12 24.89708 25.00000       0     0      0
12421    67 13 24.89708 25.00000       1     0      0
12605    68  9 25.00000 25.04317       1     0      0
12606    68 10 25.00000 25.04317       0     0      0
12607    68 11 25.00000 25.04317       1     1      0
12608    68 12 25.00000 25.04317       0     0      0
12609    68 13 25.00000 25.04317       1     0      0
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("epidata_intersperse", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("epidata_plot")
> ### * epidata_plot
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: epidata_plot
> ### Title: Plotting the Evolution of an Epidemic
> ### Aliases: plot.epidata plot.summary.epidata stateplot
> ### Keywords: hplot methods spatial
> 
> ### ** Examples
> 
> data("hagelloch")
> (s <- summary(hagelloch))

AN SIR EPIDEMIC
  Time range: 0 -- 92.5452383686788 
  Number of individuals: 188 
  1 initially infected individuals:
    "184"
  0 never infected individuals
  Size of the epidemic: 187 

$ counters ('data.frame', 376 x 6 ): evolution of the epidemic:
         time type  id nSusceptible nInfectious nRemoved
1    0.000000                   187           1        0
2    1.136356    I 173          186           2        0
3    7.197762    R 173          186           1        1
       [....]                                           
375 85.688298    I 141            0           1      187
376 92.545238    R 141            0           0      188

> 
> # rudimentary stateplot
> stateplot(s, id = "187")
> 
> # evolution of the epidemic
> plot(s)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("epidata_plot", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("epidata_summary")
> ### * epidata_summary
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: epidata_summary
> ### Title: Summarizing an Epidemic
> ### Aliases: summary.epidata print.summary.epidata
> ### Keywords: methods
> 
> ### ** Examples
> 
> data("hagelloch")
> s <- summary(hagelloch)
> s          # uses the print method for summary.epidata

AN SIR EPIDEMIC
  Time range: 0 -- 92.5452383686788 
  Number of individuals: 188 
  1 initially infected individuals:
    "184"
  0 never infected individuals
  Size of the epidemic: 187 

$ counters ('data.frame', 376 x 6 ): evolution of the epidemic:
         time type  id nSusceptible nInfectious nRemoved
1    0.000000                   187           1        0
2    1.136356    I 173          186           2        0
3    7.197762    R 173          186           1        1
       [....]                                           
375 85.688298    I 141            0           1      187
376 92.545238    R 141            0           0      188

> names(s)   # components of the list 's'
[1] "type"              "size"              "initiallyInfected"
[4] "neverInfected"     "coordinates"       "byID"             
[7] "counters"         
> 
> # positions of the individuals
> plot(s$coordinates)
> 
> # events by id
> head(s$byID)
  id   time.I   time.R
1  1 21.71242 29.22541
2  2 23.21169 31.79112
3  3 28.59102 36.69121
4  4 27.11698 32.02866
5  5 22.05953 31.41510
6  6 26.95444 33.23918
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("epidata_summary", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("fanplot")
> ### * fanplot
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: fanplot
> ### Title: Fan Plot of Forecast Distributions
> ### Aliases: fanplot
> ### Keywords: hplot distribution
> 
> ### ** Examples
> 
> ## artificial data example to illustrate the graphical options
> if (requireNamespace("fanplot")) {
+     means <- c(18, 19, 20, 25, 26, 35, 34, 25, 19)
+     y <- rlnorm(length(means), log(means), 0.5)
+     quantiles <- sapply(1:99/100, qlnorm, log(means), seq(.5,.8,length.out=length(means)))
+     
+     ## default style with point predictions, color key and log-scale
+     fanplot(quantiles = quantiles, probs = 1:99/100, means = means,
+             observed = y, key.args = list(start = 1, space = .3), log = "y")
+     
+     ## with contour lines instead of a key, and different colors
+     pal <- colorRampPalette(c("darkgreen", "gray93"))
+     fanplot(quantiles = quantiles, probs = 1:99/100, observed = y,
+             fan.args = list(fan.col = pal, ln = c(5,10,25,50,75,90,95)/100),
+             observed.args = list(type = "b", pch = 19))
+ }
Loading required namespace: fanplot
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("fanplot", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("farringtonFlexible")
> ### * farringtonFlexible
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: farringtonFlexible
> ### Title: Surveillance for Univariate Count Time Series Using an Improved
> ###   Farrington Method
> ### Aliases: farringtonFlexible
> ### Keywords: classif classif
> 
> ### ** Examples
> 
> data("salmonella.agona")
> # Create the corresponding sts object from the old disProg object
> salm <- disProg2sts(salmonella.agona)
> 
> ### RUN THE ALGORITHMS WITH TWO DIFFERENT SETS OF OPTIONS
> control1 <-  list(range=282:312,
+                   noPeriods=1,
+                   b=4, w=3, weightsThreshold=1,
+                   pastWeeksNotIncluded=3,
+                   pThresholdTrend=0.05,
+                   alpha=0.1)
> control2 <- list(range=282:312,
+                  noPeriods=10,
+                  b=4, w=3, weightsThreshold=2.58,
+                  pastWeeksNotIncluded=26,
+                  pThresholdTrend=1,
+                  alpha=0.1)
> salm1 <- farringtonFlexible(salm,control=control1)
> salm2 <- farringtonFlexible(salm,control=control2)
> 
> ### PLOT THE RESULTS
> y.max <- max(upperbound(salm1),observed(salm1),upperbound(salm2),na.rm=TRUE)
> plot(salm1, ylim=c(0,y.max), main='S. Newport in Germany', legend.opts=NULL)
> lines(1:(nrow(salm1)+1)-0.5,
+       c(upperbound(salm1),upperbound(salm1)[nrow(salm1)]),
+       type="s",col='tomato4',lwd=2)
> lines(1:(nrow(salm2)+1)-0.5,
+       c(upperbound(salm2),upperbound(salm2)[nrow(salm2)]),
+       type="s",col="blueviolet",lwd=2)
> legend("topleft",
+        legend=c('Alarm','Upperbound with old options',
+                 'Upperbound with new options'),
+        pch=c(24,NA,NA),lty=c(NA,1,1),
+        bg="white",lwd=c(2,2,2),col=c('red','tomato4',"blueviolet"))
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("farringtonFlexible", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("find.kh")
> ### * find.kh
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: find.kh
> ### Title: Determine the k and h values in a standard normal setting
> ### Aliases: find.kh
> ### Keywords: models
> 
> ### ** Examples
> 
> if (requireNamespace("spc")) {
+     find.kh(ARLa=500,ARLr=7,sided="one")
+     find.kh(ARLa=500,ARLr=3,sided="one")
+ }
Loading required namespace: spc
$k
[1] 1.014217

$h
       h 
2.289819 

> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("find.kh", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("fluBYBW")
> ### * fluBYBW
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: fluBYBW
> ### Title: Influenza in Southern Germany
> ### Aliases: fluBYBW
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("fluBYBW")
> 
> # Count time series plot
> plot(fluBYBW, type = observed ~ time)
> 
> # Map of disease incidence (per 100000 inhabitants) for the year 2001
> plot(fluBYBW, type = observed ~ unit, tps = 1:52, total.args = list(),
+      population = fluBYBW@map$X31_12_01 / 100000)
> # the overall rate for 2001 shown in the bottom right corner is
> sum(observed(fluBYBW[1:52,])) / sum(fluBYBW@map$X31_12_01) * 100000
[1] 2.66892
> 
> ## Not run: 
> ##D # Generating an animation takes a while.
> ##D # Here we take the first 20 weeks of 2001 (runtime: ~3 minutes).
> ##D # The full animation is available in Supplement A of Meyer and Held (2014)
> ##D if (require("animation")) {
> ##D     oldwd <- setwd(tempdir())  # to not clutter up the current working dir
> ##D     saveHTML(animate(fluBYBW, tps = 1:20),
> ##D              title="Evolution of influenza in Bayern and Baden-Wuerttemberg",
> ##D              ani.width=500, ani.height=600)
> ##D     setwd(oldwd)
> ##D }
> ## End(Not run)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("fluBYBW", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("formatDate")
> ### * formatDate
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: formatDate
> ### Title: Convert Dates to Character (Including Quarter Strings)
> ### Aliases: formatDate
> ### Keywords: chron
> 
> ### ** Examples
> 
> formatDate(as.Date("2021-10-13"), "%G/%OQ/%q")
[1] "2021/IV/13"
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("formatDate", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("formatPval")
> ### * formatPval
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: formatPval
> ### Title: Pretty p-Value Formatting
> ### Aliases: formatPval
> ### Keywords: print
> 
> ### ** Examples
> 
> formatPval(c(0.9, 0.13567, 0.0432, 0.000546, 1e-8))
[1] "0.90"    "0.14"    "0.043"   "0.0005"  "<0.0001"
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("formatPval", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("glm_epidataCS")
> ### * glm_epidataCS
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: glm_epidataCS
> ### Title: Fit an Endemic-Only 'twinstim' as a Poisson-'glm'
> ### Aliases: glm_epidataCS
> ### Keywords: models
> 
> ### ** Examples
> 
> data("imdepi", "imdepifit")
> 
> ## Fit an endemic-only twinstim() and an equivalent model wrapped in glm()
> fit_twinstim <- update(imdepifit, epidemic = ~0, siaf = NULL, subset = NULL,
+                        optim.args=list(control=list(trace=0)), verbose=FALSE)
> fit_glm <- glm_epidataCS(formula(fit_twinstim)$endemic, data = imdepi)
> 
> ## Compare the coefficients
> cbind(twinstim = coef(fit_twinstim), glm = coef(fit_glm))
                              twinstim          glm
h.(Intercept)             -20.36616482 -20.36616654
h.I(start/365 - 3.5)       -0.04307801  -0.04307701
h.sin(2 * pi * start/365)   0.27037886   0.27038515
h.cos(2 * pi * start/365)   0.35193560   0.35194203
> ## Don't show: 
> stopifnot(all.equal(coef(fit_glm), coef(fit_twinstim),
+                     tolerance = 1e-6, check.attributes = FALSE))
> if (surveillance.options("allExamples")) {
+     ## also check type-specific model:
+     stopifnot(all.equal(
+         coef(glm_epidataCS(~0+type, imdepi)),
+         coef(update(fit_twinstim, endemic=~(1|type))),
+     tolerance = 1e-6, check.attributes = FALSE))
+ }
> ## End(Don't show)
> 
> ### also compare to an equivalent endemic-only hhh4() fit
> 
> ## first need to aggregate imdepi into an "sts" object
> load(system.file("shapes", "districtsD.RData", package="surveillance"))
> imdsts <- epidataCS2sts(imdepi, freq = 12, start = c(2002, 1),
+                         neighbourhood = NULL, tiles = districtsD,
+                         popcol.stgrid = "popdensity")
> 
> ## determine the correct offset to get an equivalent model
> offset <- 2 * rep(with(subset(imdepi$stgrid, !duplicated(BLOCK)),
+                   stop - start), ncol(imdsts)) *
+           sum(districtsD$POPULATION) * population(imdsts)
> 
> ## fit the model using hhh4()
> fit_hhh4 <- hhh4(imdsts, control = list(
+     end = list(
+         f = addSeason2formula(~I(start/365-3.5), period=365, timevar="start"),
+         offset = offset
+     ), family = "Poisson", subset = 1:nrow(imdsts),
+     data = list(start=with(subset(imdepi$stgrid, !duplicated(BLOCK)), start))))
> 
> summary(fit_hhh4)

Call: 
hhh4(stsObj = imdsts, control = list(end = list(f = addSeason2formula(~I(start/365 - 
    3.5), period = 365, timevar = "start"), offset = offset), 
    family = "Poisson", subset = 1:nrow(imdsts), data = list(start = with(subset(imdepi$stgrid, 
        !duplicated(BLOCK)), start))))

Coefficients:
                             Estimate   Std. Error
end.1                        -20.36617    0.04192 
end.I(start/365 - 3.5)        -0.04308    0.01976 
end.sin(2 * pi * start/365)    0.27039    0.05773 
end.cos(2 * pi * start/365)    0.35194    0.05775 

Log-likelihood:   -2963.27 
AIC:              5934.54 
BIC:              5968.35 

Number of units:        413 
Number of time points:  84 

> stopifnot(all.equal(coef(fit_hhh4), coef(fit_glm), check.attributes=FALSE))
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("glm_epidataCS", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("ha")
> ### * ha
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: ha
> ### Title: Hepatitis A in Berlin
> ### Aliases: ha ha.sts
> ### Keywords: datasets
> 
> ### ** Examples
> 
> ## deprecated "disProg" object
> data("ha")
> ha
-- An object of class disProg -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 290 12 

Head of observed:
     chwi frkr lich mahe mitt neuk pank rein span zehl scho trko
[1,]    0    0    0    0    0    0    0    0    0    0    0    0
> plot(aggregate(ha))
> 
> ## new-style "sts" object
> data("ha.sts")
> ha.sts
-- An object of class sts -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 290 12 

Head of observed:
     chwi frkr lich mahe mitt neuk pank rein span zehl scho trko
[1,]    0    0    0    0    0    0    0    0    0    0    0    0

map: 12 Polygons, 3 variables
Head of map@data:
     Id                     BEZIRK SNAME
chwi  0 Charlottenburg-Wilmersdorf  chwi
> plot(ha.sts, type = observed ~ time)  # = plot(aggregate(ha.sts, by = "unit"))
> plot(ha.sts, type = observed ~ unit, labels = TRUE)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("ha", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("hagelloch")
> ### * hagelloch
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: hagelloch
> ### Title: 1861 Measles Epidemic in the City of Hagelloch, Germany
> ### Aliases: hagelloch hagelloch.df
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("hagelloch")
> head(hagelloch.df)   # original data documented in Oesterle (1992)
  PN    NAME FN HN AGE    SEX        PRO        ERU        CL DEAD IFTO SI
1  1 Mueller 41 61   7 female 1861-11-21 1861-11-25 1st class <NA>   45 10
2  2 Mueller 41 61   6 female 1861-11-23 1861-11-27 1st class <NA>   45 12
3  3 Mueller 41 61   4 female 1861-11-28 1861-12-02 preschool <NA>  172  9
4  4 Seibold 61 62  13   male 1861-11-27 1861-11-28 2nd class <NA>  180 10
5  5  Motzer 42 63   8 female 1861-11-22 1861-11-27 1st class <NA>   45 11
6  6  Motzer 42 63  12   male 1861-11-26 1861-11-29 2nd class <NA>  180  9
                 C PR CA NI GE TD   TM x.loc y.loc     tPRO     tERU tDEAD
1  no complicatons  4  4  3  1 NA   NA 142.5 100.0 22.71242 26.22541    NA
2  no complicatons  4  4  3  1  3 40.3 142.5 100.0 24.21169 28.79112    NA
3  no complicatons  4  4  3  2  1 40.5 142.5 100.0 29.59102 33.69121    NA
4  no complicatons  1  1  1  1  3 40.7 165.0 102.5 28.11698 29.02866    NA
5  no complicatons  5  3  2  1 NA   NA 145.0 120.0 23.05953 28.41510    NA
6 bronchopneumonia  3  3  2  1  2 40.7 145.0 120.0 27.95444 30.23918    NA
        tR       tI
1 29.22541 21.71242
2 31.79112 23.21169
3 36.69121 28.59102
4 32.02866 27.11698
5 31.41510 22.05953
6 33.23918 26.95444
> head(as.data.frame(hagelloch))   # "epidata" event history format
  BLOCK id start     stop atRiskY event Revent x.loc y.loc    SEX AGE        CL
1     1  1     0 1.136356       1     0      0 142.5 100.0 female   7 1st class
2     1  2     0 1.136356       1     0      0 142.5 100.0 female   6 1st class
3     1  3     0 1.136356       1     0      0 142.5 100.0 female   4 preschool
4     1  4     0 1.136356       1     0      0 165.0 102.5   male  13 2nd class
5     1  5     0 1.136356       1     0      0 145.0 120.0 female   8 1st class
6     1  6     0 1.136356       1     0      0 145.0 120.0   male  12 2nd class
  household nothousehold c1 c2
1         0            1  0  0
2         0            1  0  0
3         0            1  0  0
4         0            1  0  1
5         0            1  0  0
6         0            1  0  1
> 
> ## How the "epidata" 'hagelloch' was created from 'hagelloch.df'
> stopifnot(all.equal(hagelloch,
+   as.epidata(
+     hagelloch.df, t0 = 0, tI.col = "tI", tR.col = "tR",
+     id.col = "PN", coords.cols = c("x.loc", "y.loc"),
+     f = list(
+         household    = function(u) u == 0,
+         nothousehold = function(u) u > 0
+     ),
+     w = list(
+         c1 = function (CL.i, CL.j) CL.i == "1st class" & CL.j == CL.i,
+         c2 = function (CL.i, CL.j) CL.i == "2nd class" & CL.j == CL.i
+     ),
+     keep.cols = c("SEX", "AGE", "CL"))
+ ))
> 
> 
> ### Basic plots produced from hagelloch.df
> 
> # Show case locations as in Neal & Roberts (different scaling) using
> # the data.frame (promoted to a SpatialPointsDataFrame)
> coordinates(hagelloch.df) <- c("x.loc","y.loc")
> plot(hagelloch.df, xlab="x [m]", ylab="x [m]", pch=15, axes=TRUE,
+      cex=sqrt(multiplicity(hagelloch.df)))
> 
> # Epicurve
> hist(as.numeric(hagelloch.df$tI), xlab="Time (days)", ylab="Cases", main="")
> 
> 
> ### "epidata" summary and plot methods
> 
> (s <- summary(hagelloch))

AN SIR EPIDEMIC
  Time range: 0 -- 92.5452383686788 
  Number of individuals: 188 
  1 initially infected individuals:
    "184"
  0 never infected individuals
  Size of the epidemic: 187 

$ counters ('data.frame', 376 x 6 ): evolution of the epidemic:
         time type  id nSusceptible nInfectious nRemoved
1    0.000000                   187           1        0
2    1.136356    I 173          186           2        0
3    7.197762    R 173          186           1        1
       [....]                                           
375 85.688298    I 141            0           1      187
376 92.545238    R 141            0           0      188

> head(s$byID)
  id   time.I   time.R
1  1 21.71242 29.22541
2  2 23.21169 31.79112
3  3 28.59102 36.69121
4  4 27.11698 32.02866
5  5 22.05953 31.41510
6  6 26.95444 33.23918
> plot(s)
> 
> ## Not run: 
> ##D   # Show a dynamic illustration of the spread of the infection
> ##D   animate(hagelloch, time.spacing=0.1, sleep=1/100,
> ##D           legend.opts=list(x="topleft"))
> ## End(Not run)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("hagelloch", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("hcl.colors")
> ### * hcl.colors
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: hcl.colors
> ### Title: HCL-based Heat Colors from the 'colorspace' Package
> ### Aliases: .hcl.colors
> ### Keywords: color dplot internal
> 
> ### ** Examples
> 
> barplot(rep(1,10), col = surveillance:::.hcl.colors(10), axes = FALSE)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("hcl.colors", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("hepatitisA")
> ### * hepatitisA
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: hepatitisA
> ### Title: Hepatitis A in Germany
> ### Aliases: hepatitisA
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(hepatitisA)
> plot(hepatitisA)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("hepatitisA", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("hhh4")
> ### * hhh4
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: hhh4
> ### Title: Fitting HHH Models with Random Effects and Neighbourhood
> ###   Structure
> ### Aliases: hhh4
> ### Keywords: ts regression
> 
> ### ** Examples
> 
> ######################
> ## Univariate examples
> ######################
> 
> ### weekly counts of salmonella agona cases, UK, 1990-1995
> 
> data("salmonella.agona")
> ## convert old "disProg" to new "sts" data class
> salmonella <- disProg2sts(salmonella.agona)
> salmonella
-- An object of class sts -- 
freq:		 52 
start:		 1990 1 
dim(observed):	 312 1 

Head of observed:
     observed1
[1,]         1
> plot(salmonella)
> 
> ## generate formula for an (endemic) time trend and seasonality
> f.end <- addSeason2formula(f = ~1 + t, S = 1, period = 52)
> f.end
~1 + t + sin(2 * pi * t/52) + cos(2 * pi * t/52)
> ## specify a simple autoregressive negative binomial model
> model1 <- list(ar = list(f = ~1), end = list(f = f.end), family = "NegBin1")
> ## fit this model to the data
> res <- hhh4(salmonella, model1)
> ## summarize the model fit
> summary(res, idx2Exp=1, amplitudeShift=TRUE, maxEV=TRUE)

Call: 
hhh4(stsObj = salmonella, control = model1)

Coefficients:
                      Estimate    Std. Error
exp(ar.1)              0.2678139   0.0596124
end.1                  0.7697737   0.1240722
end.t                 -0.0007282   0.0006345
end.A(2 * pi * t/52)   0.5841434   0.0810975
end.s(2 * pi * t/52)  -2.6961872   0.0303381
overdisp               0.1905914   0.0467357

Epidemic dominant eigenvalue:  0.27 

Log-likelihood:   -620.23 
AIC:              1252.46 
BIC:              1274.9 

Number of units:        1 
Number of time points:  311 

> plot(res)
> plot(res, type = "season", components = "end")
> 
> 
> ### weekly counts of meningococcal infections, Germany, 2001-2006
> 
> data("influMen")
> fluMen <- disProg2sts(influMen)
> meningo <- fluMen[, "meningococcus"]
> meningo
-- An object of class sts -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 312 1 

Head of observed:
     meningococcus
[1,]             4
> plot(meningo)
> 
> ## again a simple autoregressive NegBin model with endemic seasonality
> meningoFit <- hhh4(stsObj = meningo, control = list(
+     ar = list(f = ~1),
+     end = list(f = addSeason2formula(f = ~1, S = 1, period = 52)),
+     family = "NegBin1"
+ ))
> 
> summary(meningoFit, idx2Exp=TRUE, amplitudeShift=TRUE, maxEV=TRUE)

Call: 
hhh4(stsObj = meningo, control = list(ar = list(f = ~1), end = list(f = addSeason2formula(f = ~1, 
    S = 1, period = 52)), family = "NegBin1"))

Coefficients:
                      Estimate  Std. Error
exp(ar.1)             0.16471   0.05513   
exp(end.1)            8.05551   0.55271   
end.A(2 * pi * t/52)  0.43158   0.03793   
end.s(2 * pi * t/52)  0.65109   0.04841   
overdisp              0.04917   0.01168   

Epidemic dominant eigenvalue:  0.16 

Log-likelihood:   -845.61 
AIC:              1701.23 
BIC:              1719.93 

Number of units:        1 
Number of time points:  311 

> plot(meningoFit)
> plot(meningoFit, type = "season", components = "end")
> 
> 
> ########################
> ## Multivariate examples
> ########################
> 
> ### bivariate analysis of influenza and meningococcal infections
> ### (see Paul et al, 2008)
> 
> plot(fluMen, same.scale = FALSE)
>      
> ## Fit a negative binomial model with
> ## - autoregressive component: disease-specific intercepts
> ## - neighbour-driven component: only transmission from flu to men
> ## - endemic component: S=3 and S=1 sine/cosine pairs for flu and men, respectively
> ## - disease-specific overdispersion
> 
> WfluMen <- neighbourhood(fluMen)
> WfluMen["meningococcus","influenza"] <- 0
> WfluMen
              influenza meningococcus
influenza             0             1
meningococcus         0             0
> f.end_fluMen <- addSeason2formula(f = ~ -1 + fe(1, which = c(TRUE, TRUE)),
+                                   S = c(3, 1), period = 52)
> f.end_fluMen
~-1 + fe(1, which = c(TRUE, TRUE)) + fe(sin(2 * pi * t/52), which = c(TRUE, 
    TRUE)) + fe(cos(2 * pi * t/52), which = c(TRUE, TRUE)) + 
    fe(sin(4 * pi * t/52), which = c(TRUE, FALSE)) + fe(cos(4 * 
    pi * t/52), which = c(TRUE, FALSE)) + fe(sin(6 * pi * t/52), 
    which = c(TRUE, FALSE)) + fe(cos(6 * pi * t/52), which = c(TRUE, 
    FALSE))
> fluMenFit <- hhh4(fluMen, control = list(
+     ar = list(f = ~ -1 + fe(1, unitSpecific = TRUE)),
+     ne = list(f = ~ 1, weights = WfluMen),
+     end = list(f = f.end_fluMen),
+     family = "NegBinM"))
> summary(fluMenFit, idx2Exp=1:3)

Call: 
hhh4(stsObj = fluMen, control = list(ar = list(f = ~-1 + fe(1, 
    unitSpecific = TRUE)), ne = list(f = ~1, weights = WfluMen), 
    end = list(f = f.end_fluMen), family = "NegBinM"))

Coefficients:
                                      Estimate   Std. Error
exp(ar.1.influenza)                    0.737592   0.050030 
exp(ar.1.meningococcus)                0.095146   0.056894 
exp(ne.1)                              0.005425   0.001413 
end.1.influenza                        1.088286   0.165319 
end.1.meningococcus                    2.118598   0.066831 
end.sin(2 * pi * t/52).influenza       1.186185   0.235984 
end.sin(2 * pi * t/52).meningococcus   0.266606   0.039680 
end.cos(2 * pi * t/52).influenza       1.509778   0.146707 
end.cos(2 * pi * t/52).meningococcus   0.229044   0.035323 
end.sin(4 * pi * t/52).influenza       0.919169   0.171502 
end.cos(4 * pi * t/52).influenza      -0.161599   0.179850 
end.sin(6 * pi * t/52).influenza       0.369235   0.149980 
end.cos(6 * pi * t/52).influenza      -0.534546   0.161901 
overdisp.influenza                     0.294554   0.035769 
overdisp.meningococcus                 0.039497   0.010893 

Log-likelihood:   -1880.97 
AIC:              3791.94 
BIC:              3858.43 

Number of units:        2 
Number of time points:  311 

> plot(fluMenFit, type = "season", components = "end", unit = 1)
> plot(fluMenFit, type = "season", components = "end", unit = 2)
> ## Don't show: 
>     ## regression test for amplitude/shift transformation of sine-cosine pairs
>     ## coefficients were wrongly matched in surveillance < 1.18.0
>     stopifnot(coef(fluMenFit, amplitudeShift = TRUE)["end.A(2 * pi * t/52).meningococcus"] == sqrt(sum(coef(fluMenFit)[paste0("end.", c("sin","cos"), "(2 * pi * t/52).meningococcus")]^2)))
> ## End(Don't show)
> 
> 
> ### weekly counts of measles, Weser-Ems region of Lower Saxony, Germany
> 
> data("measlesWeserEms")
> measlesWeserEms
-- An object of class sts -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 104 17 

Head of observed:
     03401 03402 03403 03404 03405 03451 03452 03453 03454 03455 03456 03457
[1,]     0     0     0     0     0     0     0     0     0     0     0     0
     03458 03459 03460 03461 03462
[1,]     0     0     0     0     0

map: 17 Polygons, 6 variables
Head of map@data:
                 GEN     AREA POPULATION vaccdoc.2004 vacc1.2004 vacc2.2004
03401 SK Delmenhorst 72177996      75986    0.9297573  0.9519231  0.7870879

Head of neighbourhood:
      03401 03402 03403 03404 03405 03451 03452 03453 03454 03455 03456 03457
03401     0     4     2     4     3     2     4     2     3     2     4     3
      03458 03459 03460 03461 03462
03401     1     3     2     1     3
> plot(measlesWeserEms)  # note the two districts with zero cases
> 
> ## we could fit the same simple model as for the salmonella cases above
> model1 <- list(
+     ar = list(f = ~1),
+     end = list(f = addSeason2formula(~1 + t, period = 52)),
+     family = "NegBin1"
+ )
> measlesFit <- hhh4(measlesWeserEms, model1)
> summary(measlesFit, idx2Exp=TRUE, amplitudeShift=TRUE, maxEV=TRUE)

Call: 
hhh4(stsObj = measlesWeserEms, control = model1)

Coefficients:
                      Estimate   Std. Error
exp(ar.1)              0.727033   0.088425 
exp(end.1)             0.094096   0.018276 
exp(end.t)             1.000573   0.003311 
end.A(2 * pi * t/52)   1.030334   0.145167 
end.s(2 * pi * t/52)  -0.527350   0.111359 
overdisp               2.350618   0.328655 

Epidemic dominant eigenvalue:  0.73 

Log-likelihood:   -996.2 
AIC:              2004.41 
BIC:              2037.22 

Number of units:        17 
Number of time points:  103 

> 
> ## but we should probably at least use a population offset in the endemic
> ## component to reflect heterogeneous incidence levels of the districts,
> ## and account for spatial dependence (here just using first-order adjacency)
> measlesFit2 <- update(measlesFit,
+     end = list(offset = population(measlesWeserEms)),
+     ne = list(f = ~1, weights = neighbourhood(measlesWeserEms) == 1))
> summary(measlesFit2, idx2Exp=TRUE, amplitudeShift=TRUE, maxEV=TRUE)

Call: 
hhh4(stsObj = object$stsObj, control = control)

Coefficients:
                      Estimate   Std. Error
exp(ar.1)              0.645403   0.079270 
exp(ne.1)              0.015805   0.004200 
exp(end.1)             1.080248   0.278839 
exp(end.t)             1.001185   0.004264 
end.A(2 * pi * t/52)   1.164231   0.192124 
end.s(2 * pi * t/52)  -0.634360   0.133500 
overdisp               2.013839   0.285441 

Epidemic dominant eigenvalue:  0.72 

Log-likelihood:   -971.72 
AIC:              1957.44 
BIC:              1995.72 

Number of units:        17 
Number of time points:  103 

> plot(measlesFit2, units = NULL, hide0s = TRUE)
> 
> ## 'measlesFit2' corresponds to the 'measlesFit_basic' model in
> ## vignette("hhh4_spacetime"). See there for further analyses,
> ## including vaccination coverage as a covariate,
> ## spatial power-law weights, and random intercepts.
> 
> 
> ## Not run: 
> ##D ### last but not least, a more sophisticated (and time-consuming)
> ##D ### analysis of weekly counts of influenza from 140 districts in
> ##D ### Southern Germany (originally analysed by Paul and Held, 2011,
> ##D ### and revisited by Held and Paul, 2012, and Meyer and Held, 2014)
> ##D 
> ##D data("fluBYBW")
> ##D plot(fluBYBW, type = observed ~ time)
> ##D plot(fluBYBW, type = observed ~ unit,
> ##D      ## mean yearly incidence per 100.000 inhabitants (8 years)
> ##D      population = fluBYBW@map$X31_12_01 / 100000 * 8)
> ##D 
> ##D ## For the full set of models for data("fluBYBW") as analysed by
> ##D ## Paul and Held (2011), including predictive model assessement
> ##D ## using proper scoring rules, see the (computer-intensive)
> ##D ## demo("fluBYBW") script:
> ##D demoscript <- system.file("demo", "fluBYBW.R", package = "surveillance")
> ##D demoscript
> ##D #file.show(demoscript)
> ##D 
> ##D ## Here we fit the improved power-law model of Meyer and Held (2014)
> ##D ## - autoregressive component: random intercepts + S = 1 sine/cosine pair
> ##D ## - neighbour-driven component: random intercepts + S = 1 sine/cosine pair
> ##D ##   + population gravity with normalized power-law weights
> ##D ## - endemic component: random intercepts + trend + S = 3 sine/cosine pairs
> ##D ## - random intercepts are iid but correlated between components
> ##D f.S1 <- addSeason2formula(
> ##D     ~-1 + ri(type="iid", corr="all"),
> ##D     S = 1, period = 52)
> ##D f.end.S3 <- addSeason2formula(
> ##D     ~-1 + ri(type="iid", corr="all") + I((t-208)/100),
> ##D     S = 3, period = 52)
> ##D 
> ##D ## for power-law weights, we need adjaceny orders, which can be
> ##D ## computed from the binary adjacency indicator matrix
> ##D nbOrder1 <- neighbourhood(fluBYBW)
> ##D neighbourhood(fluBYBW) <- nbOrder(nbOrder1)
> ##D 
> ##D ## full model specification
> ##D fluModel <- list(
> ##D     ar = list(f = f.S1),
> ##D     ne = list(f = update.formula(f.S1, ~ . + log(pop)),
> ##D               weights = W_powerlaw(maxlag=max(neighbourhood(fluBYBW)),
> ##D                                    normalize = TRUE, log = TRUE)),
> ##D     end = list(f = f.end.S3, offset = population(fluBYBW)),
> ##D     family = "NegBin1", data = list(pop = population(fluBYBW)),
> ##D     optimizer = list(variance = list(method = "Nelder-Mead")),
> ##D     verbose = TRUE)
> ##D 
> ##D ## CAVE: random effects considerably increase the runtime of model estimation
> ##D ## (It is usually advantageous to first fit a model with simple intercepts
> ##D ## to obtain reasonable start values for the other parameters.)
> ##D set.seed(1)  # because random intercepts are initialized randomly
> ##D fluFit <- hhh4(fluBYBW, fluModel)
> ##D 
> ##D summary(fluFit, idx2Exp = TRUE, amplitudeShift = TRUE)
> ##D 
> ##D plot(fluFit, type = "fitted", total = TRUE)
> ##D 
> ##D plot(fluFit, type = "season")
> ##D range(plot(fluFit, type = "maxEV"))
> ##D 
> ##D plot(fluFit, type = "maps", prop = TRUE)
> ##D 
> ##D gridExtra::grid.arrange(
> ##D     grobs = lapply(c("ar", "ne", "end"), function (comp)
> ##D         plot(fluFit, type = "ri", component = comp, main = comp,
> ##D              exp = TRUE, sub = "multiplicative effect")),
> ##D     nrow = 1, ncol = 3)
> ##D 
> ##D plot(fluFit, type = "neweights", xlab = "adjacency order")
> ## End(Not run)
> 
> 
> ########################################################################
> ## An endemic-only "hhh4" model can also be estimated using MASS::glm.nb
> ########################################################################
> 
> ## weekly counts of measles, Weser-Ems region of Lower Saxony, Germany
> data("measlesWeserEms")
> 
> ## fit an endemic-only "hhh4" model
> ## with time covariates and a district-specific offset
> hhh4fit <- hhh4(measlesWeserEms, control = list(
+     end = list(f = addSeason2formula(~1 + t, period = measlesWeserEms@freq),
+                offset = population(measlesWeserEms)),
+     ar = list(f = ~-1), ne = list(f = ~-1), family = "NegBin1",
+     subset = 1:nrow(measlesWeserEms)
+ ))
> summary(hhh4fit)

Call: 
hhh4(stsObj = measlesWeserEms, control = list(end = list(f = addSeason2formula(~1 + 
    t, period = measlesWeserEms@freq), offset = population(measlesWeserEms)), 
    ar = list(f = ~-1), ne = list(f = ~-1), family = "NegBin1", 
    subset = 1:nrow(measlesWeserEms)))

Coefficients:
                        Estimate   Std. Error
end.1                    2.946672   0.274235 
end.t                   -0.013929   0.005049 
end.sin(2 * pi * t/52)   1.556754   0.185513 
end.cos(2 * pi * t/52)  -0.217468   0.133003 
overdisp                15.381777   1.267034 

Log-likelihood:   -1222.63 
AIC:              2455.26 
BIC:              2482.65 

Number of units:        17 
Number of time points:  104 

> 
> ## fit the same model using MASS::glm.nb
> measlesWeserEmsData <- as.data.frame(measlesWeserEms, tidy = TRUE)
> measlesWeserEmsData$t <- c(hhh4fit$control$data$t)
> glmnbfit <- MASS::glm.nb(
+     update(formula(hhh4fit)$end, observed ~ . + offset(log(population))),
+     data = measlesWeserEmsData
+ )
> summary(glmnbfit)

Call:
MASS::glm.nb(formula = update(formula(hhh4fit)$end, observed ~ 
    . + offset(log(population))), data = measlesWeserEmsData, 
    init.theta = 0.06501198678, link = log)

Coefficients:
                    Estimate Std. Error z value Pr(>|z|)    
(Intercept)         2.946674   0.214456  13.740  < 2e-16 ***
t                  -0.013929   0.003772  -3.693 0.000222 ***
sin(2 * pi * t/52)  1.556755   0.160986   9.670  < 2e-16 ***
cos(2 * pi * t/52) -0.217467   0.144862  -1.501 0.133303    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

(Dispersion parameter for Negative Binomial(0.065) family taken to be 1)

    Null deviance: 667.73  on 1767  degrees of freedom
Residual deviance: 571.36  on 1764  degrees of freedom
AIC: 2455.3

Number of Fisher Scoring iterations: 1


              Theta:  0.06501 
          Std. Err.:  0.00533 

 2 x log-likelihood:  -2445.26400 
> 
> ## Note that the overdispersion parameter is parametrized inversely.
> ## The likelihood and point estimates are all the same.
> ## However, the variance estimates are different: in glm.nb, the parameters
> ## are estimated conditional on the overdispersion theta.
> 
> ## Don't show: 
> stopifnot(
+     all.equal(logLik(hhh4fit), logLik(glmnbfit)),
+     all.equal(1/coef(hhh4fit)[["overdisp"]], glmnbfit$theta, tolerance = 1e-6),
+     all.equal(coef(hhh4fit)[1:4], coef(glmnbfit),
+               tolerance = 1e-6, check.attributes = FALSE),
+     all.equal(c(residuals(hhh4fit)), residuals(glmnbfit),
+               tolerance = 1e-6, check.attributes = FALSE)
+ )
> ## End(Don't show)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("hhh4", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("hhh4_W")
> ### * hhh4_W
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: hhh4_W
> ### Title: Power-Law and Nonparametric Neighbourhood Weights for
> ###   'hhh4'-Models
> ### Aliases: W_powerlaw W_np
> ### Keywords: spatial models utilities
> 
> ### ** Examples
> 
> data("measlesWeserEms")
> 
> ## data contains adjaceny orders as required for parametric weights
> plot(measlesWeserEms, type = observed ~ unit, labels = TRUE)
> neighbourhood(measlesWeserEms)[1:6,1:6]
      03401 03402 03403 03404 03405 03451
03401     0     4     2     4     3     2
03402     4     0     3     4     3     2
03403     2     3     0     4     3     1
03404     4     4     4     0     5     3
03405     3     3     3     5     0     2
03451     2     2     1     3     2     0
> max(neighbourhood(measlesWeserEms))  # max order is 5
[1] 5
> 
> ## fit a power-law decay of spatial interaction
> ## in a hhh4 model with seasonality and random intercepts in the endemic part
> measlesModel <- list(
+     ar = list(f = ~ 1),
+     ne = list(f = ~ 1, weights = W_powerlaw(maxlag=5)),
+     end = list(f = addSeason2formula(~-1 + ri(), S=1, period=52)),
+     family = "NegBin1")
> 
> ## fit the model
> set.seed(1)  # random intercepts are initialized randomly
> measlesFit <- hhh4(measlesWeserEms, measlesModel)
> summary(measlesFit)  # "neweights.d" is the decay parameter d

Call: 
hhh4(stsObj = measlesWeserEms, control = measlesModel)

Random effects:
            Var   Corr
end.ri(iid) 1.876     

Fixed effects:
                        Estimate  Std. Error
ar.1                    -0.5067    0.1182   
ne.1                    -3.1333    0.4117   
end.sin(2 * pi * t/52)   0.9853    0.1571   
end.cos(2 * pi * t/52)  -0.7411    0.1664   
end.ri(iid)             -3.0210    0.3735   
neweights.d              5.6189    4.0822   
overdisp                 1.4316    0.2047   

Penalized log-likelihood:  -910.22 
Marginal log-likelihood:   -33.61 

Number of units:        17 
Number of time points:  103 

> coefW(measlesFit)
      d 
5.61886 
> 
> ## plot the spatio-temporal weights o_ji^-d / sum_k o_jk^-d
> ## as a function of adjacency order
> plot(measlesFit, type = "neweights", xlab = "adjacency order")
> ## normalization => same distance does not necessarily mean same weight.
> ## to extract the whole weight matrix W: getNEweights(measlesFit)
> 
> ## visualize contributions of the three model components
> ## to the overall number of infections (aggregated over all districts)
> plot(measlesFit, total = TRUE)
> ## little contribution from neighbouring districts
> 
> 
> if (surveillance.options("allExamples")) {
+ 
+ ## simpler model with autoregressive effects captured by the ne component
+ measlesModel2 <- list(
+     ne = list(f = ~ 1, weights = W_powerlaw(maxlag=5, from0=TRUE)),
+     end = list(f = addSeason2formula(~-1 + ri(), S=1, period=52)),
+     family = "NegBin1")
+ measlesFit2 <- hhh4(measlesWeserEms, measlesModel2)
+ ## omitting the separate AR component simplifies model extensions/selection
+ ## and interpretation of covariate effects (only two predictors left)
+ 
+ plot(measlesFit2, type = "neweights", exclude = NULL, xlab = "adjacency order")
+ ## strong decay, again mostly within-district transmission
+ ## (one could also try a purely autoregressive model)
+ plot(measlesFit2, total = TRUE,
+      legend.args = list(legend = c("epidemic", "endemic")))
+ ## almost the same RMSE as with separate AR and NE effects
+ c(rmse1 = sqrt(mean(residuals(measlesFit, "response")^2)),
+   rmse2 = sqrt(mean(residuals(measlesFit2, "response")^2)))
+ 
+ }
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("hhh4_W", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("hhh4_plot")
> ### * hhh4_plot
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: hhh4_plot
> ### Title: Plots for Fitted 'hhh4'-models
> ### Aliases: plot.hhh4 plotHHH4_fitted plotHHH4_fitted1 plotHHH4_season
> ###   getMaxEV_season plotHHH4_maxEV getMaxEV plotHHH4_maps plotHHH4_ri
> ###   plotHHH4_neweights
> ### Keywords: hplot
> 
> ### ** Examples
> 
> data("measlesWeserEms")
> 
> ## fit a simple hhh4 model
> measlesModel <- list(
+     ar = list(f = ~ 1),
+     end = list(f = addSeason2formula(~0 + ri(type="iid"), S=1, period=52),
+                offset = population(measlesWeserEms)),
+     family = "NegBin1"
+     )
> measlesFit <- hhh4(measlesWeserEms, measlesModel)
> 
> ## fitted values for a single unit
> plot(measlesFit, units=2)
> 
> ## sum fitted components over all units
> plot(measlesFit, total=TRUE)
> 
> ## 'xaxis' option for a nicely formatted time axis
> ## default tick locations and labels:
> plot(measlesFit, total=TRUE, xaxis=list(epochsAsDate=TRUE, line=1))
> ## an alternative with monthly ticks:
> oopts <- surveillance.options(stsTickFactors = c("%m"=0.75, "%Y" = 1.5))
> plot(measlesFit, total=TRUE, xaxis=list(epochsAsDate=TRUE,
+     xaxis.tickFreq=list("%m"=atChange, "%Y"=atChange),
+     xaxis.labelFreq=list("%Y"=atMedian), xaxis.labelFormat="%Y"))
> surveillance.options(oopts)
> 
> ## plot the multiplicative effect of seasonality
> plot(measlesFit, type="season")
> 
> ## alternative fit with biennial pattern, plotted jointly with original fit
> measlesFit2 <- update(measlesFit,
+     end = list(f = addSeason2formula(~0 + ri(type="iid"), S=2, period=104)))
> plotHHH4_season(measlesFit, measlesFit2, components="end", period=104)
> 
> ## dominant eigenvalue of the Lambda matrix (cf. Held and Paul, 2012)
> getMaxEV(measlesFit)  # here simply constant and equal to exp(ar.1)
  [1] 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443
  [8] 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443
 [15] 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443
 [22] 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443
 [29] 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443
 [36] 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443
 [43] 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443
 [50] 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443
 [57] 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443
 [64] 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443
 [71] 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443
 [78] 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443
 [85] 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443
 [92] 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443
 [99] 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443 0.6041443
> plot(measlesFit, type="maxEV")  # not very exciting
> 
> ## fitted mean components/proportions by district, averaged over time
> if (requireNamespace("gridExtra")) {
+     plot(measlesFit, type="maps", labels=list(cex=0.6),
+          which=c("endemic", "epi.own"), prop=TRUE, zmax=NA,
+          main=c("endemic proportion", "autoregressive proportion"))
+ }
Loading required namespace: gridExtra
> 
> ## estimated random intercepts of the endemic component
> round(nu0    <- fixef(measlesFit)["end.ri(iid)"],   4) # global intercept
end.ri(iid) 
     0.1574 
> round(ranefs <- ranef(measlesFit, tomatrix = TRUE), 4) # zero-mean deviations
      end.ri(iid)
03401     -1.6268
03402      2.5184
03403      0.1465
03404     -1.0824
03405     -1.6931
03451     -0.3663
03452      1.2506
03453      0.5271
03454      0.4285
03455     -0.9609
03456     -1.1792
03457      1.9180
03458     -0.1307
03459     -0.0966
03460     -0.5476
03461      0.8749
03462      0.0196
> stopifnot(all.equal(
+     nu0 + ranefs,
+     ranef(measlesFit, intercept = TRUE) # local intercepts (log-scale)
+ ))
> plot(measlesFit, type="ri", component="end",
+      main="deviations around the endemic intercept (log-scale)")
> exp(ranef(measlesFit))  # multiplicative effects, plotted below
end.ri(iid).03401 end.ri(iid).03402 end.ri(iid).03403 end.ri(iid).03404 
        0.1965635        12.4083002         1.1577485         0.3387909 
end.ri(iid).03405 end.ri(iid).03451 end.ri(iid).03452 end.ri(iid).03453 
        0.1839540         0.6932666         3.4924754         1.6939719 
end.ri(iid).03454 end.ri(iid).03455 end.ri(iid).03456 end.ri(iid).03457 
        1.5349648         0.3825384         0.3075257         6.8074490 
end.ri(iid).03458 end.ri(iid).03459 end.ri(iid).03460 end.ri(iid).03461 
        0.8775099         0.9079036         0.5783473         2.3987108 
end.ri(iid).03462 
        1.0197462 
> plot(measlesFit, type="ri", component="end", exp=TRUE,
+      main="multiplicative effects",
+      labels=list(font=3, labels="GEN"))
> 
> ## neighbourhood weights as a function of neighbourhood order
> plot(measlesFit, type="neweights")  # boring, model has no "ne" component
> 
> ## fitted values for the 6 regions with most cases and some customization
> bigunits <- tail(names(sort(colSums(observed(measlesWeserEms)))), 6)
> plot(measlesFit, units=bigunits,
+      names=measlesWeserEms@map@data[bigunits,"GEN"],
+      legend=5, legend.args=list(x="top"), xlab="Time (weekly)",
+      hide0s=TRUE, ylim=c(0,max(observed(measlesWeserEms)[,bigunits])),
+      start=c(2002,1), end=c(2002,26), par.settings=list(xaxs="i"))
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("hhh4_plot", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("hhh4_predict")
> ### * hhh4_predict
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: hhh4_predict
> ### Title: Predictions from a 'hhh4' Model
> ### Aliases: predict.hhh4
> ### Keywords: methods models
> 
> ### ** Examples
> 
> ## simulate simple seasonal noise with reduced baseline for t >= 60
> t <- 0:100
> y <- rpois(length(t), exp(3 + sin(2*pi*t/52) - 2*(t >= 60)))
> obj <- sts(y)
> plot(obj)
> 
> ## fit true model
> fit <- hhh4(obj, list(end = list(f = addSeason2formula(~lock)),
+                       data = list(lock = as.integer(t >= 60)),
+                       family = "Poisson"))
> coef(fit, amplitudeShift = TRUE, se = TRUE)
                        Estimate Std. Error
end.1                 2.98937318 0.03274760
end.lock             -2.04436410 0.09101313
end.A(2 * pi * t/52)  1.03892400 0.04365286
end.s(2 * pi * t/52)  0.00871127 0.03475900
> 
> ## compute predictions for a subset of the time points
> stopifnot(identical(predict(fit), fitted(fit)))
> plot(obj)
> lines(40:80, predict(fit, newSubset = 40:80), lwd = 2)
> 
> 
> ## advanced: compute predictions for "newdata" (here, a modified covariate)
> mod <- fit
> mod$terms <- NULL  # to be sure
> mod$control$data$lock[t >= 60] <- 0.5
> pred <- meanHHH(mod$coefficients, terms(mod))$mean
> plot(fit, xaxis = NA)
> lines(mod$control$subset, pred, lty = 2)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("hhh4_predict", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("hhh4_simulate")
> ### * hhh4_simulate
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: hhh4_simulate
> ### Title: Simulate '"hhh4"' Count Time Series
> ### Aliases: simulate.hhh4
> ### Keywords: datagen
> 
> ### ** Examples
> 
> data(influMen)
> # convert to sts class and extract meningococcal disease time series
> meningo <- disProg2sts(influMen)[,2]
> 
> # fit model
> fit <- hhh4(meningo, control = list(
+               ar = list(f = ~ 1),
+               end = list(f = addSeason2formula(~1, period = 52)),
+               family = "NegBin1"))
> plot(fit)
> 
> # simulate from model (generates an "sts" object)
> simData <- simulate(fit, seed=1234)
> 
> # plot simulated data
> plot(simData, main = "simulated data", xaxis.labelFormat=NULL)
> 
> # use simplify=TRUE to return an array of simulated counts
> simCounts <- simulate(fit, seed=1234, simplify=TRUE)
> dim(simCounts)  # nTime x nUnit x nsim
[1] 312   1   1
> ## Don't show: 
> stopifnot(observed(simData) == c(simCounts))
> ## End(Don't show)
> # plot the first year of simulated counts (+ initial + observed)
> plot(simCounts[1:52,,], type = "time", xaxis.labelFormat = NULL)
> # see help(plot.hhh4sims) for other plots, mainly useful for nsim > 1
> 
> # simulate from a Poisson instead of a NegBin model
> # keeping all other parameters fixed at their original estimates
> coefs <- replace(coef(fit), "overdisp", 0)
> simData2 <- simulate(fit, seed=123, coefs = coefs)
> plot(simData2, main = "simulated data: Poisson model", xaxis.labelFormat = NULL)
> 
> # simulate from a model with higher autoregressive parameter
> coefs <- replace(coef(fit), "ar.1", log(0.9))
> simData3 <- simulate(fit, seed=321, coefs = coefs)
> plot(simData3, main = "simulated data: lambda = 0.5", xaxis.labelFormat = NULL)
> 
> 
> ## more sophisticated: simulate beyond initially observed time range
> 
> # extend data range by one year (non-observed domain), filling with NA values
> nextend <- 52
> timeslots <- c("observed", "state", "alarm", "upperbound", "populationFrac")
> addrows <- function (mat, n) mat[c(seq_len(nrow(mat)), rep(NA, n)),,drop=FALSE]
> extended <- Map(function (x) addrows(slot(meningo, x), n = nextend), x = timeslots)
> # create new sts object with extended matrices
> meningo2 <- do.call("sts", c(list(start = meningo@start, frequency = meningo@freq,
+                                   map = meningo@map), extended))
> 
> # fit to the observed time range only, via the 'subset' argument
> fit2 <- hhh4(meningo2, control = list(
+               ar = list(f = ~ 1),
+               end = list(f = addSeason2formula(~1, period = 52)),
+               family = "NegBin1",
+               subset = 2:(nrow(meningo2) - nextend)))
> # the result is the same as before
> stopifnot(all.equal(fit, fit2, ignore = c("stsObj", "control")))
> ## Don't show: 
> # one-week-ahead prediction only "works" for the first non-observed time point
> # because the autoregressive component relies on non-missing past counts
> oneStepAhead(fit2, tp = rep(nrow(meningo2)-nextend, 2), type = "final", verbose = FALSE)
$pred
    meningococcus
313      11.45203

$observed
    meningococcus
313            NA

$psi
    -log(overdisp)
312       3.012411

$allConverged
[1] TRUE

attr(,"class")
[1] "oneStepAhead"
> # however, methods won't work as observed is NA
> ## End(Don't show)
> # long-term probabilistic forecast via simulation for non-observed time points
> meningoSim <- simulate(fit2, nsim = 100, seed = 1,
+                        subset = seq(nrow(meningo)+1, nrow(meningo2)),
+                        y.start = tail(observed(meningo), 1))
> apply(meningoSim, 1:2, function (ysim) quantile(ysim, c(0.1, 0.5, 0.9)))
, , meningococcus

    313  314  315 316  317  318 319  320 321  322  323  324 325  326  327 328
10%   6  7.0  7.9   9  8.0  9.0   9  8.0   9  7.9  9.0  8.9   7  6.0  7.0   8
50%  11 11.5 13.0  14 14.0 13.5  14 14.5  14 14.0 14.0 14.0  12 13.5 13.0  12
90%  17 18.1 21.0  20 21.1 21.0  21 20.1  20 23.0 21.1 19.0  18 21.0 18.2  18
    329  330  331  332 333  334  335  336 337  338 339  340  341 342 343 344
10%   8  5.9  6.0  5.9   6  5.0  4.9  5.0   4  3.0   3  3.9  3.9   3   3   3
50%  12 11.0 11.5 10.0  10  8.0  8.0  9.0   8  7.0   7  7.0  6.5   7   6   6
90%  18 18.0 17.0 16.1  17 14.1 13.0 14.1  13 12.1  12 12.1 11.0  10  11  10
     345 346  347 348 349 350 351  352 353 354 355 356 357  358 359  360 361
10%  3.0   3  3.0   3   3   3   3  3.0   3   3   4   4   4  4.9   5  6.0   6
50%  6.0   6  6.0   6   6   6   7  7.0   7   6   7   7   7  8.0   9  9.0  10
90% 10.1  11 11.1  10  10  10  10 10.1  11  11  12  12  12 14.0  14 14.1  16
    362  363 364
10%   6  6.9   7
50%  11 11.0  12
90%  16 17.0  18

> # three plot types are available for "hhh4sims", see also ?plot.hhh4sims
> plot(meningoSim, type = "time", average = median)
> plot(meningoSim, type = "size", observed = FALSE)
> if (requireNamespace("fanplot"))
+     plot(meningoSim, type = "fan", means.args = list(),
+          fan.args = list(ln = c(.1,.9), ln.col = 8))
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("hhh4_simulate", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("hhh4_simulate_plot")
> ### * hhh4_simulate_plot
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: hhh4_simulate_plot
> ### Title: Plot Simulations from '"hhh4"' Models
> ### Aliases: plot.hhh4sims aggregate.hhh4sims as.hhh4simslist
> ###   plot.hhh4simslist aggregate.hhh4simslist plotHHH4sims_size
> ###   plotHHH4sims_time plotHHH4sims_fan
> ### Keywords: hplot
> 
> ### ** Examples
> 
> ### univariate example
> data("salmAllOnset")
> 
> ## fit a hhh4 model to the first 13 years
> salmModel <- list(end = list(f = addSeason2formula(~1 + t)),
+                   ar = list(f = ~1), family = "NegBin1", subset = 2:678)
> salmFit <- hhh4(salmAllOnset, salmModel)
> 
> ## simulate the next 20 weeks ahead
> salmSims <- simulate(salmFit, nsim = 300, seed = 3, subset = 678 + seq_len(20),
+                      y.start = observed(salmAllOnset)[678,])
> 
> ## compare final size distribution to observed value
> summary(aggregate(salmSims, time = TRUE))  # summary of simulated values
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   2092    3467    4070    4264    4869    8379 
> plot(salmSims, type = "size")
> 
> ## individual and average simulated time series with a confidence interval
> plot(salmSims, type = "time", main = "20-weeks-ahead simulation")
> 
> ## fan chart based on the quantiles of the simulated counts at each time point
> ## point forecasts are represented by a white line within the fan
> if (requireNamespace("fanplot")) {
+     plot(salmSims, type = "fan", main = "20-weeks-ahead simulation",
+          fan.args = list(ln = 1:9/10), means.args = list())
+ }
> 
> 
> ### multivariate example
> data("measlesWeserEms")
> 
> ## fit a hhh4 model to the first year
> measlesModel <- list(
+     end = list(f = addSeason2formula(~1), offset = population(measlesWeserEms)),
+     ar = list(f = ~1),
+     ne = list(f = ~1 + log(pop),
+         weights = W_powerlaw(maxlag = 5, normalize = TRUE)),
+     family = "NegBin1", subset = 2:52,
+     data = list(pop = population(measlesWeserEms)))
> measlesFit1 <- hhh4(measlesWeserEms, control = measlesModel)
> 
> ## use a Poisson distribution instead (just for comparison)
> measlesFit2 <- update(measlesFit1, family = "Poisson")
> 
> ## simulate realizations from these models during the second year
> measlesSims <- lapply(X = list(NegBin = measlesFit1, Poisson = measlesFit2),
+                       FUN = simulate, nsim = 50, seed = 1, subset = 53:104,
+                       y.start = observed(measlesWeserEms)[52,])
> 
> ## final size of the first model
> plot(measlesSims[[1]])
> 
> ## stratified by groups of districts
> mygroups <- factor(substr(colnames(measlesWeserEms), 4, 4))
> apply(aggregate(measlesSims[[1]], time = TRUE, units = mygroups), 1, summary)
             0       5      6
Min.     11.00   40.00   4.00
1st Qu.  30.00  116.25  20.25
Median   41.00  170.50  38.50
Mean     60.06  246.26  70.42
3rd Qu.  79.75  298.50  84.50
Max.    181.00 1690.00 596.00
> plot(measlesSims[[1]], groups = mygroups)
> 
> ## a class and plot-method for a list of simulations from different models
> measlesSims <- as.hhh4simslist(measlesSims)
> plot(measlesSims)
> 
> ## simulated time series
> plot(measlesSims, type = "time", individual = TRUE, ylim = c(0, 80))
> 
> ## fan charts
> if (requireNamespace("fanplot")) {
+     opar <- par(mfrow = c(2,1))
+     plot(measlesSims, type = "fan", which = 1, ylim = c(0, 80), main = "NegBin",
+          key.args = list())
+     plot(measlesSims, type = "fan", which = 2, ylim = c(0, 80), main = "Poisson")
+     par(opar)
+ }
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("hhh4_simulate_plot", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("hhh4_simulate_scores")
> ### * hhh4_simulate_scores
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: hhh4_simulate_scores
> ### Title: Proper Scoring Rules for Simulations from 'hhh4' Models
> ### Aliases: scores.hhh4sims scores.hhh4simslist
> ### Keywords: univar
> 
> ### ** Examples
> 
> data("salmAllOnset")
> 
> ## fit a hhh4 model to the first 13 years
> salmModel <- list(end = list(f = addSeason2formula(~1 + t)),
+                   ar = list(f = ~1), family = "NegBin1", subset = 2:678)
> salmFit <- hhh4(salmAllOnset, salmModel)
> 
> ## simulate the next 20 weeks ahead (with very small 'nsim' for speed)
> salmSims <- simulate(salmFit, nsim = 500, seed = 3, subset = 678 + seq_len(20),
+                      y.start = observed(salmAllOnset)[678,])
> if (requireNamespace("fanplot"))
+     plot(salmSims, "fan")
> 
> 
> ### calculate scores at each time point
> 
> ## using empirical distribution of simulated counts as forecast distribution
> scores(salmSims, which = c("rps", "logs", "dss"))
            rps     logs       dss
 [1,] 44.652300 6.214608 12.360009
 [2,] 41.615368 4.605170 10.151219
 [3,]  9.001204 4.605170  7.341208
 [4,] 24.887444 6.214608  8.327968
 [5,] 14.269080 5.115996  7.937095
 [6,] 31.087064 4.422849  8.773099
 [7,] 56.776224      Inf 10.060180
 [8,] 18.132608 6.214608  8.453401
 [9,] 16.652632 5.521461  8.458259
[10,] 18.897472      Inf  8.643125
[11,] 56.820728      Inf  9.840239
[12,] 23.824868 4.828314  8.918505
[13,] 20.494280 4.605170  9.086949
[14,] 18.469088 5.115996  8.911161
[15,] 19.905304 4.605170  9.024052
[16,] 21.880828 5.521461  9.135292
[17,] 34.970124 5.115996  9.317830
[18,] 29.534468 6.214608  9.226855
[19,] 32.378336      Inf  9.301393
[20,] 23.988568 5.115996  9.564189
> ## observed count sometimes not covered by simulations -> infinite log-score
> ## => for a more detailed forecast, either considerably increase 'nsim', or:
> 
> ## 1. use continuous density() of simulated counts as forecast distribution
> fi <- apply(salmSims, 1, function (x) approxfun(density(x)))
> logs_kde <- mapply(function (f, y) -log(f(y)),
+                    f = fi, y = observed(attr(salmSims,"stsObserved")))
> cbind("empirical" = scores(salmSims, "logs"), "density" = logs_kde)
    empirical  density
679  6.214608 6.659979
680  4.605170 5.822914
681  4.605170 4.603229
682  6.214608 5.211775
683  5.115996 4.991573
684  4.422849 5.484528
685       Inf 6.064300
686  6.214608 5.240908
687  5.521461 5.269806
688       Inf 5.313447
689       Inf 6.084266
690  4.828314 5.472717
691  4.605170 5.190417
692  5.115996 5.268753
693  4.605170 5.375747
694  5.521461 5.438898
695  5.115996 5.796517
696  6.214608 5.680099
697       Inf 5.843015
698  5.115996 5.251521
> ## a similar KDE approach is implemented in scoringRules::logs_sample()
> 
> ## 2. average conditional predictive NegBin's of simulated trajectories,
> ##    currently only implemented in HIDDA.forecasting::dhhh4sims()
> 
> 
> ### produce a PIT histogram
> 
> ## using empirical distribution of simulated counts as forecast distribition
> pit(x = observed(attr(salmSims, "stsObserved")),
+     pdistr = apply(salmSims, 1:2, ecdf))
Warning in pit.default(x = observed(attr(salmSims, "stsObserved")), pdistr = apply(salmSims,  :
  predictive distribution has 0 probability for observed 'x'
> ## long-term forecast is badly calibrated (lower tail is unused, see fan above)
> ## we also get a warning for the same reason as infinite log-scores
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("hhh4_simulate_scores", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("hhh4_update")
> ### * hhh4_update
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: hhh4_update
> ### Title: 'update' a fitted '"hhh4"' model
> ### Aliases: update.hhh4
> ### Keywords: models methods
> 
> ### ** Examples
> 
> data("salmonella.agona")
> ## convert to sts class
> salmonella <- disProg2sts(salmonella.agona)
> 
> ## fit a basic model
> fit0 <- hhh4(salmonella,
+             list(ar = list(f = ~1), end = list(f = addSeason2formula(~t))))
> 
> ## update: Poisson -> NegBin1, component seasonality
> fit1 <- update(fit0, family = "NegBin1", S = list(end=2, ar=2))
> 
> ## compare fits
> AIC(fit0, fit1)
     df      AIC
fit0  5 1285.577
fit1 12 1251.151
> opar <- par(mfrow=c(2,2))
> plot(fit0, type="fitted", names="fit0", par.settings=NULL)
> plot(fit1, type="fitted", names="fit1", par.settings=NULL)
> plot(fit0, fit1, type="season", components=c("end", "ar"), par.settings=NULL)
> par(opar)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("hhh4_update", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("hhh4_validation")
> ### * hhh4_validation
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: hhh4_validation
> ### Title: Predictive Model Assessment for 'hhh4' Models
> ### Aliases: oneStepAhead quantile.oneStepAhead confint.oneStepAhead
> ###   plot.oneStepAhead scores.oneStepAhead scores.hhh4
> ###   calibrationTest.oneStepAhead calibrationTest.hhh4 pit.oneStepAhead
> ###   pit.hhh4
> ### Keywords: univar htest dplot ts
> 
> ### ** Examples
> 
> ### univariate salmonella agona count time series
> 
> data("salmonella.agona")
> ## convert from old "disProg" to new "sts" class
> salmonella <- disProg2sts(salmonella.agona)
> 
> ## generate formula for temporal and seasonal trends
> f.end <- addSeason2formula(~1 + t, S=1, period=52)
> model <- list(ar = list(f = ~1), end = list(f = f.end), family = "NegBin1")
> ## fit the model
> result <- hhh4(salmonella, model)
> 
> ## do sequential one-step-ahead predictions for the last 5 weeks
> pred <- oneStepAhead(result, nrow(salmonella)-5, type="rolling",
+                      which.start="final", verbose=FALSE)
> pred
$pred
    observed1
308  2.393189
309  2.554725
310  2.149935
311  2.037949
312  1.355550

$observed
    observed1
308         3
309         2
310         2
311         0
312         4

$psi
    -log(overdisp)
307       1.654039
308       1.664373
309       1.672556
310       1.681389
311       1.667292

$allConverged
[1] TRUE

attr(,"class")
[1] "oneStepAhead"
> quantile(pred)
    2.5 % 10.0 % 50.0 % 90.0 % 97.5 %
308     0      0      2      5      7
309     0      0      2      5      7
310     0      0      2      4      6
311     0      0      2      4      6
312     0      0      1      3      4
> confint(pred)
    2.5 % 97.5 %
308     0      7
309     0      7
310     0      6
311     0      6
312     0      4
> 
> ## simple plot of the 80% one-week-ahead prediction interval
> ## and point forecasts
> if (requireNamespace("fanplot"))
+     plot(pred, probs = c(.1,.9), means.args = list())
> 
> ## Don't show: 
> ## test equivalence of parallelized version
> if (.Platform$OS.type == "unix" && isTRUE(parallel::detectCores() > 1))
+     stopifnot(identical(pred,
+         oneStepAhead(result, nrow(salmonella)-5, type="rolling",
+                      which.start="final", verbose=FALSE, cores=2)))
> ## End(Don't show)
> 
> ## note: oneStepAhead(..., type="final") just means fitted values
> stopifnot(identical(
+     unname(oneStepAhead(result, nrow(salmonella)-5, type="final")$pred),
+     unname(tail(fitted(result), 5))))
> 
> 
> ## compute scores of the one-step-ahead predictions
> (sc <- scores(pred))
        logs       rps      dss        ses
308 1.776080 0.5848567 1.355074 0.36821935
309 1.516732 0.4287197 1.413625 0.30771949
310 1.474374 0.3762164 1.111988 0.02248049
311 1.727808 1.1377692 2.511047 4.15323789
312 3.137643 2.0323380 4.639845 6.99311433
> 
> ## the above uses the scores-method for "oneStepAhead" predictions,
> ## which is a simple wrapper around the default method:
> scores(x = pred$observed, mu = pred$pred, size = exp(pred$psi))
, , logs

    observed1
308  1.776080
309  1.516732
310  1.474374
311  1.727808
312  3.137643

, , rps

    observed1
308 0.5848567
309 0.4287197
310 0.3762164
311 1.1377692
312 2.0323380

, , dss

    observed1
308  1.355074
309  1.413625
310  1.111988
311  2.511047
312  4.639845

, , ses

     observed1
308 0.36821935
309 0.30771949
310 0.02248049
311 4.15323789
312 6.99311433

> 
> ## scores with respect to the fitted values are similar
> (scFitted <- scores(result, subset = nrow(salmonella)-(4:0)))
        logs       rps      dss        ses
308 1.769394 0.5747661 1.359750 0.32560060
309 1.519504 0.4316637 1.425517 0.32209501
310 1.478047 0.3785423 1.136176 0.03182741
311 1.742344 1.1552244 2.540516 4.27045216
312 3.027744 1.9500842 4.233001 6.60969759
> 
> ## Don't show: 
> ## test that scFitted is equivalent to scores(oneStepAhead(..., type = "final"))
> stopifnot(all.equal(
+     scFitted,
+     scores(oneStepAhead(result, nrow(salmonella)-5, type="final")),
+     check.attributes = FALSE))
> ## End(Don't show)
> 
> 
> ## test if the one-step-ahead predictions are calibrated
> calibrationTest(pred)  # p = 0.8746

	Calibration Test for Count Data (based on DSS)

data:  pred
z = 0.15781, n = 5, p-value = 0.8746

> 
> ## the above uses the calibrationTest-method for "oneStepAhead" predictions,
> ## which is a simple wrapper around the default method:
> calibrationTest(x = pred$observed, mu = pred$pred, size = exp(pred$psi))

	Calibration Test for Count Data (based on DSS)

data:  pred$observed
z = 0.15781, n = 5, p-value = 0.8746

> 
> ## we can also test calibration of the fitted values
> ## using the calibrationTest-method for "hhh4" fits
> calibrationTest(result, subset = nrow(salmonella)-(4:0))

	Calibration Test for Count Data (based on DSS)

data:  result
z = 0.049572, n = 5, p-value = 0.9605

> 
> 
> ## plot a (non-randomized) PIT histogram for the predictions
> pit(pred)
> 
> ## the above uses the pit-method for "oneStepAhead" predictions,
> ## which is a simple wrapper around the default method:
> pit(x = pred$observed, pdistr = "pnbinom", mu = pred$pred, size = exp(pred$psi))
> 
> 
> ### multivariate measles count time series
> ## (omitting oneStepAhead forecasts here to keep runtime low)
> 
> data("measlesWeserEms")
> 
> ## simple hhh4 model with random effects in the endemic component
> measlesModel <- list(
+     end = list(f = addSeason2formula(~0 + ri(type="iid"))),
+     ar = list(f = ~1),
+     family = "NegBin1")
> measlesFit <- hhh4(measlesWeserEms, control = measlesModel)
> 
> ## assess overall (in-sample) calibration of the model, i.e.,
> ## if the observed counts are from the fitted NegBin distribution
> calibrationTest(measlesFit) # default is DSS (not suitable for low counts)

	Calibration Test for Count Data (based on DSS)

data:  measlesFit
z = 3.118, n = 1751, p-value = 0.001821

> calibrationTest(measlesFit, which = "logs") # p = 0.7238

	Calibration Test for Count Data (based on LOGS)

data:  measlesFit
z = -0.35334, n = 1751, p-value = 0.7238

> 
> ## to assess calibration in the second year for a specific district
> calibrationTest(measlesFit, subset = 53:104, units = "03452", which = "rps")

	Calibration Test for Count Data (based on RPS)

data:  measlesFit
z = 0.27416, n = 52, p-value = 0.784

> pit(measlesFit, subset = 53:104, units = "03452")
> 
> 
> ### For a more sophisticated multivariate analysis of
> ### areal time series of influenza counts - data("fluBYBW") -
> ### see the (computer-intensive) demo("fluBYBW") script:
> demoscript <- system.file("demo", "fluBYBW.R", package = "surveillance")
> #file.show(demoscript)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("hhh4_validation", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("imdepi")
> ### * imdepi
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: imdepi
> ### Title: Occurrence of Invasive Meningococcal Disease in Germany
> ### Aliases: imdepi
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("imdepi")
> 
> # Basic information
> print(imdepi, n=5, digits=2)
Observation period: 0 - 2557 
Observation window (bounding box): [4031, 4672] x [2684, 3550] 
Spatio-temporal grid (not shown): 84 time blocks x 413 tiles 
Types of events: "B" "C"
Overall number of events: 636

   coordinates  time  tile type eps.t eps.s    sex   agegrp BLOCK start
1 (4100, 3200)  0.21 05554    B    30   200   male   [3,19)     1     0
2 (4100, 3100)  0.71 05382    C    30   200   male   [3,19)     1     0
3 (4400, 2900)  5.59 09574    B    30   200 female [19,Inf)     1     0
4 (4200, 2900)  7.12 08212    B    30   200 female   [3,19)     1     0
5 (4100, 3200) 22.06 05554    C    30   200   male   [3,19)     1     0
  popdensity
1        261
2        519
3        209
4       1666
5        261
[....]
> 
> # What is an epidataCS-object?
> str(imdepi, max.level=4)
List of 4
 $ events :Formal class 'SpatialPointsDataFrame' [package "sp"] with 5 slots
  .. ..@ data       :'data.frame':	636 obs. of  14 variables:
  .. .. ..$ time            : num [1:636] 0.212 0.712 5.591 7.117 22.06 ...
  .. .. ..$ tile            : Factor w/ 413 levels "01001","01002",..: 95 91 291 195 95 79 94 327 289 5 ...
  .. .. ..$ type            : Factor w/ 2 levels "B","C": 1 2 1 1 2 2 2 2 2 2 ...
  .. .. ..$ eps.t           : num [1:636] 30 30 30 30 30 30 30 30 30 30 ...
  .. .. ..$ eps.s           : num [1:636] 200 200 200 200 200 200 200 200 200 200 ...
  .. .. ..$ sex             : Factor w/ 2 levels "female","male": 2 2 1 1 2 2 2 1 2 NA ...
  .. .. ..$ agegrp          : Factor w/ 3 levels "[0,3)","[3,19)",..: 2 2 3 2 2 2 2 2 3 1 ...
  .. .. ..$ BLOCK           : int [1:636] 1 1 1 1 1 1 2 2 2 2 ...
  .. .. ..$ start           : num [1:636] 0 0 0 0 0 0 31 31 31 31 ...
  .. .. ..$ popdensity      : num [1:636] 261 519 209 1666 261 ...
  .. .. ..$ .obsInfLength   : num [1:636] 30 30 30 30 30 30 30 30 30 30 ...
  .. .. ..$ .sources        :List of 636
  .. .. ..$ .bdist          : num [1:636] 13.2 66.6 94.4 12.4 19.2 ...
  .. .. ..$ .influenceRegion:List of 636
  .. .. .. ..- attr(*, "nCircle2Poly")= int 16
  .. .. .. ..- attr(*, "clipper")= chr "polyclip"
  .. ..@ coords.nrs : num(0) 
  .. ..@ coords     : num [1:636, 1:2] 4112 4123 4412 4203 4128 ...
  .. .. ..- attr(*, "dimnames")=List of 2
  .. ..@ bbox       : num [1:2, 1:2] 4039 2710 4665 3525
  .. .. ..- attr(*, "dimnames")=List of 2
  .. ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slot
 $ stgrid :'data.frame':	34692 obs. of  6 variables:
  ..$ BLOCK     : int [1:34692] 1 1 1 1 1 1 1 1 1 1 ...
  ..$ start     : num [1:34692] 0 0 0 0 0 0 0 0 0 0 ...
  ..$ stop      : num [1:34692] 31 31 31 31 31 31 31 31 31 31 ...
  ..$ tile      : Factor w/ 413 levels "01001","01002",..: 1 2 3 4 5 6 7 8 9 10 ...
  ..$ area      : num [1:34692] 56.4 118.7 214.2 71.6 1428 ...
  ..$ popdensity: num [1:34692] 1557.1 1996.6 987.6 1083.3 95.6 ...
 $ W      :Formal class 'SpatialPolygons' [package "sp"] with 4 slots
  .. ..@ polygons   :List of 1
  .. .. ..$ :Formal class 'Polygons' [package "sp"] with 5 slots
  .. ..@ plotOrder  : int 1
  .. ..@ bbox       : num [1:2, 1:2] 4031 2684 4672 3550
  .. .. ..- attr(*, "dimnames")=List of 2
  .. ..@ proj4string:Formal class 'CRS' [package "sp"] with 1 slot
  .. ..$ comment: chr "TRUE"
 $ qmatrix: logi [1:2, 1:2] TRUE FALSE FALSE TRUE
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:2] "B" "C"
  .. ..$ : chr [1:2] "B" "C"
 - attr(*, "class")= chr "epidataCS"
> names(imdepi$events@data)
 [1] "time"             "tile"             "type"             "eps.t"           
 [5] "eps.s"            "sex"              "agegrp"           "BLOCK"           
 [9] "start"            "popdensity"       ".obsInfLength"    ".sources"        
[13] ".bdist"           ".influenceRegion"
> # => events data.frame has hidden columns
> sapply(imdepi$events@data, class)
            time             tile             type            eps.t 
       "numeric"         "factor"         "factor"        "numeric" 
           eps.s              sex           agegrp            BLOCK 
       "numeric"         "factor"         "factor"        "integer" 
           start       popdensity    .obsInfLength         .sources 
       "numeric"        "numeric"        "numeric"           "list" 
          .bdist .influenceRegion 
       "numeric"           "list" 
> # marks and print methods ignore these auxiliary columns
> 
> # look at the B type only
> imdepiB <- subset(imdepi, type == "B")
Note: dropped type(s) "C"
> #<- subsetting applies to the 'events' component
> imdepiB
Observation period: 0 - 2557 
Observation window (bounding box): [4031.295, 4672.253] x [2684.102, 3549.931] 
Spatio-temporal grid (not shown): 84 time blocks x 413 tiles 
Types of events: "B"
Overall number of events: 336

            coordinates       time  tile type eps.t eps.s    sex   agegrp BLOCK
1  (4112.188, 3202.792)  0.2116949 05554    B    30   200   male   [3,19)     1
3  (4412.466, 2915.939)  5.5910231 09574    B    30   200 female [19,Inf)     1
4  (4202.635, 2879.698)  7.1169826 08212    B    30   200 female   [3,19)     1
11  (4044.47, 3080.435) 44.5433853 05313    B    30   200   male   [3,19)     2
13 (4134.103, 3038.831) 56.3224294 07137    B    30   200   male [19,Inf)     2
14 (4116.286, 3073.816) 56.4273666 05314    B    30   200 female   [3,19)     2
   start popdensity
1      0   260.8612
3      0   209.4464
4      0  1665.6117
11    31  1610.5826
13    31   260.5648
14    31  2240.5892
[....]
> 
> # select only the last 10 events
> tail(imdepi, n=10)   # there is also a corresponding 'head' method
Observation period: 0 - 2557 
Observation window (bounding box): [4031.295, 4672.253] x [2684.102, 3549.931] 
Spatio-temporal grid (not shown): 84 time blocks x 413 tiles 
Types of events: "B" "C"
Overall number of events: 10

             coordinates     time  tile type eps.t eps.s    sex   agegrp BLOCK
627   (4436.837, 3152.6) 2507.726 15087    B    30   200 female [19,Inf)    83
628 (4373.538, 2764.207) 2514.150 09777    C    30   200   male   [3,19)    83
629  (4301.32, 3387.208) 2515.638 01056    B    30   200 female     <NA>    83
630   (4202.49, 2901.67) 2521.696 07334    B    30   200   male [19,Inf)    83
631 (4472.408, 2878.951) 2526.241 09362    C    30   200 female   [3,19)    84
632 (4051.938, 3091.086) 2528.155 05354    B    30   200 female   [3,19)    84
    start popdensity
627  2496  109.21497
628  2496   96.39475
629  2496  453.61073
630  2496  271.59540
631  2526 1642.22856
632  2526  567.29266
[....]
> 
> # Access event marks
> str(marks(imdepi))
'data.frame':	636 obs. of  9 variables:
 $ time  : num  0.212 0.712 5.591 7.117 22.06 ...
 $ tile  : Factor w/ 413 levels "01001","01002",..: 95 91 291 195 95 79 94 327 289 5 ...
 $ type  : Factor w/ 2 levels "B","C": 1 2 1 1 2 2 2 2 2 2 ...
 $ eps.t : num  30 30 30 30 30 30 30 30 30 30 ...
 $ eps.s : num  200 200 200 200 200 200 200 200 200 200 ...
 $ sex   : Factor w/ 2 levels "female","male": 2 2 1 1 2 2 2 1 2 NA ...
 $ agegrp: Factor w/ 3 levels "[0,3)","[3,19)",..: 2 2 3 2 2 2 2 2 3 1 ...
 $ x     : num  4112 4123 4412 4203 4128 ...
 $ y     : num  3203 3077 2916 2880 3223 ...
> 
> # there is an update-method which assures that the object remains valid
> # when changing parameters like eps.s, eps.t or qmatrix
> update(imdepi, eps.t = 20)
Observation period: 0 - 2557 
Observation window (bounding box): [4031.295, 4672.253] x [2684.102, 3549.931] 
Spatio-temporal grid (not shown): 84 time blocks x 413 tiles 
Types of events: "B" "C"
Overall number of events: 636

           coordinates       time  tile type eps.t eps.s    sex   agegrp BLOCK
1 (4112.188, 3202.792)  0.2116949 05554    B    20   200   male   [3,19)     1
2  (4122.508, 3076.97)  0.7124225 05382    C    20   200   male   [3,19)     1
3 (4412.466, 2915.939)  5.5910231 09574    B    20   200 female [19,Inf)     1
4 (4202.635, 2879.698)  7.1169826 08212    B    20   200 female   [3,19)     1
5 (4128.335, 3223.314) 22.0595327 05554    C    20   200   male   [3,19)     1
6 (4089.915, 3178.005) 24.9544435 05170    C    20   200   male   [3,19)     1
  start popdensity
1     0   260.8612
2     0   519.3570
3     0   209.4464
4     0  1665.6117
5     0   260.8612
6     0   454.7456
[....]
> 
> # Summary
> s <- summary(imdepi)
> s
Observation period: 0 - 2557 
Observation window (bounding box): [4031.295, 4672.253] x [2684.102, 3549.931] 
Spatio-temporal grid (not shown): 84 time blocks x 413 tiles 
Overall number of events: 636 (2 types)

Summary of event marks and number of potential sources:
      time                tile     type        eps.t        eps.s    
 Min.   :   0.2117   05354  : 34   B:336   Min.   :30   Min.   :200  
 1st Qu.: 539.4753   05370  : 27   C:300   1st Qu.:30   1st Qu.:200  
 Median :1154.9527   11000  : 27           Median :30   Median :200  
 Mean   :1192.6813   05358  : 13           Mean   :30   Mean   :200  
 3rd Qu.:1808.0295   05162  : 12           3rd Qu.:30   3rd Qu.:200  
 Max.   :2542.7800   05382  : 12           Max.   :30   Max.   :200  
                     (Other):511                                     
     sex           agegrp          x              y          |.sources|    
 female:292   [0,3)   :194   Min.   :4039   Min.   :2710   Min.   : 0.000  
 male  :339   [3,19)  :279   1st Qu.:4101   1st Qu.:2967   1st Qu.: 0.000  
 NA's  :  5   [19,Inf):162   Median :4206   Median :3106   Median : 1.000  
              NA's    :  1   Mean   :4244   Mean   :3092   Mean   : 1.634  
                             3rd Qu.:4361   3rd Qu.:3194   3rd Qu.: 2.000  
                             Max.   :4665   Max.   :3525   Max.   :14.000  
                                                                           
> str(s)
List of 14
 $ timeRange  : num [1:2] 0 2557
 $ bbox       : num [1:2, 1:2] 4031 2684 4672 3550
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:2] "x" "y"
  .. ..$ : chr [1:2] "min" "max"
 $ nBlocks    : int 84
 $ nEvents    : int 636
 $ nTypes     : int 2
 $ eventTimes : num [1:636] 0.212 0.712 5.591 7.117 22.06 ...
 $ eventCoords: num [1:636, 1:2] 4112 4123 4412 4203 4128 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : chr [1:636] "1" "2" "3" "4" ...
  .. ..$ : chr [1:2] "x" "y"
 $ eventTypes : Factor w/ 2 levels "B","C": 1 2 1 1 2 2 2 2 2 2 ...
 $ eventRanges:'data.frame':	636 obs. of  2 variables:
  ..$ eps.t: num [1:636] 30 30 30 30 30 30 30 30 30 30 ...
  ..$ eps.s: num [1:636] 200 200 200 200 200 200 200 200 200 200 ...
 $ eventMarks :'data.frame':	636 obs. of  9 variables:
  ..$ time  : num [1:636] 0.212 0.712 5.591 7.117 22.06 ...
  ..$ tile  : Factor w/ 413 levels "01001","01002",..: 95 91 291 195 95 79 94 327 289 5 ...
  ..$ type  : Factor w/ 2 levels "B","C": 1 2 1 1 2 2 2 2 2 2 ...
  ..$ eps.t : num [1:636] 30 30 30 30 30 30 30 30 30 30 ...
  ..$ eps.s : num [1:636] 200 200 200 200 200 200 200 200 200 200 ...
  ..$ sex   : Factor w/ 2 levels "female","male": 2 2 1 1 2 2 2 1 2 NA ...
  ..$ agegrp: Factor w/ 3 levels "[0,3)","[3,19)",..: 2 2 3 2 2 2 2 2 3 1 ...
  ..$ x     : num [1:636] 4112 4123 4412 4203 4128 ...
  ..$ y     : num [1:636] 3203 3077 2916 2880 3223 ...
 $ tileTable  : Named int [1:413] 2 2 2 2 2 1 0 0 1 0 ...
  ..- attr(*, "names")= chr [1:413] "01001" "01002" "01003" "01004" ...
 $ typeTable  : Named int [1:2] 336 300
  ..- attr(*, "names")= chr [1:2] "B" "C"
 $ counter    :function (v)  
  ..- attr(*, "class")= chr [1:2] "stepfun" "function"
  ..- attr(*, "call")= language stepfun(tps, c(0, nInfectious), right = TRUE)
 $ nSources   : int [1:636] 0 0 0 0 1 2 2 0 0 0 ...
 - attr(*, "class")= chr "summary.epidataCS"
> 
> # Step function of number of infectives
> plot(s$counter, xlab = "Time [days]",
+      ylab = "Number of infectious individuals",
+      main = "Time series of IMD assuming 30 days infectious period")
> 
> # distribution of number of potential sources of infection
> opar <- par(mfrow=c(1,2), las=1)
> for (type in c("B","C")) {
+   plot(100*prop.table(table(s$nSources[s$eventTypes==type])),
+   xlim=range(s$nSources), xlab = "Number of potential epidemic sources",
+   ylab = "Proportion of events [%]")
+ }
> par(opar)
> 
> # a histogram of the number of events along time (using the
> # plot-method for the epidataCS-class, see ?plot.epidataCS)
> opar <- par(mfrow = c(2,1))
> plot(imdepi, "time", subset = type == "B", main = "Finetype B")
> plot(imdepi, "time", subset = type == "C", main = "Finetype C")
> par(opar)
> 
> # Plot the spatial distribution of the events in W
> plot(imdepi, "space", points.args = list(col=c("indianred", "darkblue")))
> 
> # or manually (no legends, no account for tied locations)
> plot(imdepi$W, lwd=2, asp=1) 
> plot(imdepi$events, pch=c(3,4)[imdepi$events$type], cex=0.8,
+      col=c("indianred", "darkblue")[imdepi$events$type], add=TRUE)
> 
> ## Not run: 
> ##D   # Show a dynamic illustration of the spatio-temporal dynamics of the 
> ##D   # spread during the first year of type B with a step size of 7 days
> ##D   animate(imdepiB, interval=c(0,365), time.spacing=7, sleep=0.1)
> ## End(Not run)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("imdepi", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("imdepifit")
> ### * imdepifit
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: imdepifit
> ### Title: Example 'twinstim' Fit for the 'imdepi' Data
> ### Aliases: imdepifit
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("imdepi", "imdepifit")
> 
> ## how this fit was obtained
> imdepifit$call
twinstim(endemic = addSeason2formula(~offset(log(popdensity)) + 
    I(start/365 - 3.5), S = 1, period = 365, timevar = "start"), 
    epidemic = ~type + agegrp, siaf = siaf.gaussian(), data = imdepi, 
    subset = !is.na(agegrp), optim.args = list(control = list(reltol = sqrt(.Machine$double.eps))), 
    model = FALSE, cumCIF = FALSE)
> ## Don't show: 
> if (surveillance.options("allExamples"))
+ ## reproduce "imdepifit"
+ stopifnot(all.equal(imdepifit, eval(imdepifit$call)))
> ## End(Don't show)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("imdepifit", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("influMen")
> ### * influMen
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: influMen
> ### Title: Influenza and meningococcal infections in Germany, 2001-2006
> ### Aliases: influMen
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(influMen)
> plot(influMen, as.one=FALSE, same.scale=FALSE) 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("influMen", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("intersectPolyCircle")
> ### * intersectPolyCircle
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: intersectPolyCircle
> ### Title: Intersection of a Polygonal and a Circular Domain
> ### Aliases: intersectPolyCircle intersectPolyCircle.owin
> ### Keywords: spatial manip
> 
> ### ** Examples
> 
> letterR <- surveillance:::LETTERR  # an "owin" (internally used for checks)
> plot(letterR, axes = TRUE)
> plot(intersectPolyCircle(letterR, center = c(-1, 2), radius = 2),
+      add = TRUE, col = 4, lwd = 3)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("intersectPolyCircle", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("isoWeekYear")
> ### * isoWeekYear
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: isoWeekYear
> ### Title: Find ISO Week and Year of Date Objects
> ### Aliases: isoWeekYear
> ### Keywords: chron
> 
> ### ** Examples
> 
> dates <- as.Date(c("2002-12-31","2003-01-01","2003-01-06"))
> isoWeekYear(dates)
$ISOYear
[1] 2003 2003 2003

$ISOWeek
[1] 1 1 2

> 
> ## the same using numeric inputs:
> isoWeekYear(Y = c(2002, 2003, 2003), M = c(12, 1, 1), D = c(31, 1, 6))
$ISOYear
[1] 2003 2003 2003

$ISOWeek
[1] 1 1 2

> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("isoWeekYear", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("knox")
> ### * knox
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: knox
> ### Title: Knox Test for Space-Time Interaction
> ### Aliases: knox plot.knox toLatex.knox
> ### Keywords: htest
> 
> ### ** Examples
> 
> data("imdepi")
> imdepiB <- subset(imdepi, type == "B")
Note: dropped type(s) "C"
> 
> ## Perform the Knox test using the Poisson approximation
> knoxtest <- knox(
+     dt = dist(imdepiB$events$time), eps.t = 30,
+     ds = dist(coordinates(imdepiB$events)), eps.s = 50,
+     simulate.p.value = FALSE
+ )
> knoxtest

	Knox test with Poisson approximation

data:  dt = dist(imdepiB$events$time) and ds = dist(coordinates(imdepiB$events))
number of close pairs = 204, lambda = 181.57, p-value = 0.04649
alternative hypothesis: true number is greater than 181.5686

contingency table:
       ds
dt      <= 50  > 50
  <= 30   204  1295
   > 30  6613 48168

> ## The Poisson approximation works well for these data since
> ## the proportion of close pairs is rather small (204/56280).
> ## Don't show: 
> .opt <- options(xtable.comment = FALSE)
> ## End(Don't show)
> ## contingency table in LaTeX
> toLatex(knoxtest)
\begin{table}[ht]
\centering
\begin{tabular}{r|rr|r}
  \hline
 & \multicolumn{2}{|c|}{ds} & \\
dt & $\le$ 50 &  $>$ 50 & $\sum$ \\ 
  \hline
$\le$ 30 & 204 & 1295 & 1499 \\ 
   $>$ 30 & 6613 & 48168 & 54781 \\ 
   \hline
$\sum$ & 6817 & 49463 & 56280 \\ 
   \hline
\end{tabular}
\end{table}
> ## Don't show: 
> options(.opt)
> ## End(Don't show)
> 
> ## Obtain the p-value via a Monte Carlo permutation test,
> ## where the permutations can be computed in parallel
> ## (using forking on Unix-alikes and a cluster on Windows, see ?plapply)
> knoxtestMC <- knox(
+     dt = dist(imdepiB$events$time), eps.t = 30,
+     ds = dist(coordinates(imdepiB$events)), eps.s = 50,
+     simulate.p.value = TRUE, B = 99,  # limited here for speed
+     .parallel = 2, .seed = 1, .verbose = FALSE
+ )
> knoxtestMC

	Knox test with simulated p-value

data:  dt = dist(imdepiB$events$time) and ds = dist(coordinates(imdepiB$events))
number of close pairs = 204, B = 99, p-value = 0.03
alternative hypothesis: true number is greater than 181.5686

contingency table:
       ds
dt      <= 50  > 50
  <= 30   204  1295
   > 30  6613 48168

> plot(knoxtestMC)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("knox", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("ks.plot.unif")
> ### * ks.plot.unif
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: ks.plot.unif
> ### Title: Plot the ECDF of a uniform sample with Kolmogorov-Smirnov bounds
> ### Aliases: ks.plot.unif
> ### Keywords: hplot htest
> 
> ### ** Examples
> 
> samp <- runif(99)
> ks.plot.unif(samp, conf.level=c(0.95, 0.99), exact=TRUE)
> ks.plot.unif(samp, conf.level=c(0.95, 0.99), exact=FALSE)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("ks.plot.unif", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("layout.labels")
> ### * layout.labels
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: layout.labels
> ### Title: Layout Items for 'spplot'
> ### Aliases: layout.labels layout.scalebar
> ### Keywords: aplot dplot
> 
> ### ** Examples
> if (requireNamespace("sf")) { # required by recent 'sp'
+ 
+ ## districts in the Regierungsbezirk Weser-Ems (longlat coordinates)
+ data("measlesWeserEms")
+ mapWE <- measlesWeserEms@map
+ li1 <- layout.labels(mapWE, labels = list(font=2, labels="GEN"))
+ li2 <- layout.scalebar(mapWE, corner = c(0.05, 0.05), scale = 20,
+                        labels = c("0", "20 km"))
+ spplot(mapWE, zcol = "AREA", sp.layout = c(list(li1), li2),
+        col.regions = rev(heat.colors(100)), scales = list(draw = TRUE))
+ 
+ ## districts in Bavaria (projected coordinates)
+ load(system.file("shapes", "districtsD.RData", package = "surveillance"))
+ bavaria <- districtsD[substr(row.names(districtsD), 1, 2) == "09", ]
+ sb <- layout.scalebar(bavaria, corner = c(0.75,0.9), scale = 50,
+                       labels = c("0", "50 km"), cex = 0.8)
+ spplot(bavaria, zcol = "POPULATION", sp.layout = sb,
+        xlab = "x [km]", ylab = "y [km]", scales = list(draw = TRUE),
+        col.regions = rev(heat.colors(100)))
+ 
+ ## these layout functions also work in the traditional graphics system
+ par(mar = c(0,0,0,0))
+ plot(bavaria, col = "lavender")
+ layout.scalebar(bavaria, corner = c(0.75, 0.9), scale = 50,
+                 labels = c("0", "50 km"), plot = TRUE)
+ layout.labels(bavaria, labels = list(cex = 0.8,
+               labels = substr(bavaria$GEN, 1, 3)), plot = TRUE)
+ 
+ }
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("layout.labels", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("linelist2sts")
> ### * linelist2sts
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: linelist2sts
> ### Title: Convert Dates of Individual Case Reports into a Time Series of
> ###   Counts
> ### Aliases: linelist2sts
> ### Keywords: models optimize
> 
> ### ** Examples
> 
> #Load O104 outbreak data
> data("husO104Hosp")
> 
> #Convert line list to an sts object
> sts <- linelist2sts(husO104Hosp, dateCol="dHosp", aggregate.by="1 day")
> 
> #Check that the number of cases is correct
> all.equal(sum(observed(sts)),nrow(husO104Hosp))
[1] TRUE
> 
> #Plot the result
> plot(sts,xaxis.tickFreq=list("%d"=atChange,"%m"=atChange),
+            xaxis.labelFreq=list("%d"=at2ndChange),
+            xaxis.labelFormat="%d %b",
+            xlab="",las=2,cex.axis=0.8)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("linelist2sts", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("m1")
> ### * m1
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: m1
> ### Title: RKI SurvStat Data
> ### Aliases: m1 h1_nrwrp k1 m2 m3 m4 m5 n1 n2 q1_nrwh q2 s1 s2 s3
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(k1)
> survResObj <- algo.rki1(k1, control=list(range=27:192))
> plot(survResObj, "RKI 1", "k1")
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("m1", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("makeControl")
> ### * makeControl
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: makeControl
> ### Title: Generate 'control' Settings for an 'hhh4' Model
> ### Aliases: makeControl
> 
> ### ** Examples
> 
> makeControl()
$ar
$ar$f
~1
<environment: 0x5eddfd9a35d0>

$ar$offset
[1] 1


$ne
$ne$f
~1
<environment: 0x5eddfd9a35d0>

$ne$offset
[1] 1


$end
$end$f
~1 + sin(2 * pi * t/52) + cos(2 * pi * t/52)

$end$offset
[1] 1


$family
[1] "NegBin1"

> 
> ## a simplistic model for the fluBYBW data
> ## (first-order transmission only, no district-specific intercepts)
> data("fluBYBW")
> mycontrol <- makeControl(
+     f = list(~1, ~1, ~t), S = c(1, 1, 3),
+     offset = list(population(fluBYBW)),  # recycled -> in all components
+     ne = list(normalize = TRUE),
+     verbose = TRUE)
> str(mycontrol)
List of 5
 $ ar     :List of 2
  ..$ f     :Class 'formula'  language ~1 + sin(2 * pi * t/52) + cos(2 * pi * t/52)
  .. .. ..- attr(*, ".Environment")=<environment: R_GlobalEnv> 
  ..$ offset: num [1:416, 1:140] 0.00956 0.00956 0.00956 0.00956 0.00956 ...
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : NULL
  .. .. ..$ : chr [1:140] "8336" "8337" "8315" "8311" ...
 $ ne     :List of 3
  ..$ f        :Class 'formula'  language ~1 + sin(2 * pi * t/52) + cos(2 * pi * t/52)
  .. .. ..- attr(*, ".Environment")=<environment: R_GlobalEnv> 
  ..$ offset   : num [1:416, 1:140] 0.00956 0.00956 0.00956 0.00956 0.00956 ...
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : NULL
  .. .. ..$ : chr [1:140] "8336" "8337" "8315" "8311" ...
  ..$ normalize: logi TRUE
 $ end    :List of 2
  ..$ f     :Class 'formula'  language ~t + sin(2 * pi * t/52) + cos(2 * pi * t/52) + sin(4 * pi * t/52) + cos(4 *      pi * t/52) + sin(6 * pi * t/52) | __truncated__
  .. .. ..- attr(*, ".Environment")=<environment: R_GlobalEnv> 
  ..$ offset: num [1:416, 1:140] 0.00956 0.00956 0.00956 0.00956 0.00956 ...
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : NULL
  .. .. ..$ : chr [1:140] "8336" "8337" "8315" "8311" ...
 $ family : chr "NegBin1"
 $ verbose: logi TRUE
> 
> if (surveillance.options("allExamples"))
+ ## fit this model
+ fit <- hhh4(fluBYBW, mycontrol)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("makeControl", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("measles.weser")
> ### * measles.weser
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: measles.weser
> ### Title: Measles in the Weser-Ems region of Lower Saxony, Germany,
> ###   2001-2002
> ### Aliases: measles.weser measlesWeserEms
> ### Keywords: datasets
> 
> ### ** Examples
> 
> ## old "disProg" object
> data("measles.weser")
> measles.weser
-- An object of class disProg -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 104 15 

Head of observed:
     3402 3403 3404 3451 3452 3453 3454 3455 3456 3457 3458 3459 3460 3461 3462
[1,]    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0
> plot(measles.weser, as.one=FALSE)
> 
> ## new "sts" object (with corrections)
> data("measlesWeserEms")
> measlesWeserEms
-- An object of class sts -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 104 17 

Head of observed:
     03401 03402 03403 03404 03405 03451 03452 03453 03454 03455 03456 03457
[1,]     0     0     0     0     0     0     0     0     0     0     0     0
     03458 03459 03460 03461 03462
[1,]     0     0     0     0     0

map: 17 Polygons, 6 variables
Head of map@data:
                 GEN     AREA POPULATION vaccdoc.2004 vacc1.2004 vacc2.2004
03401 SK Delmenhorst 72177996      75986    0.9297573  0.9519231  0.7870879

Head of neighbourhood:
      03401 03402 03403 03404 03405 03451 03452 03453 03454 03455 03456 03457
03401     0     4     2     4     3     2     4     2     3     2     4     3
      03458 03459 03460 03461 03462
03401     1     3     2     1     3
> plot(measlesWeserEms)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("measles.weser", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("measlesDE")
> ### * measlesDE
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: measlesDE
> ### Title: Measles in the 16 states of Germany
> ### Aliases: measlesDE
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(measlesDE)
> plot(measlesDE)
> 
> ## aggregate to bi-weekly intervals
> measles2w <- aggregate(measlesDE, nfreq = 26)
> plot(measles2w, type = observed ~ time)
> 
> ## use a date index for nicer x-axis plotting
> epoch(measles2w) <- seq(as.Date("2005-01-03"), by = "2 weeks",
+                         length.out = nrow(measles2w))
> plot(measles2w, type = observed ~ time)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("measlesDE", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("meningo.age")
> ### * meningo.age
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: meningo.age
> ### Title: Meningococcal infections in France 1985-1997
> ### Aliases: meningo.age
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(meningo.age)
> plot(meningo.age, title="Meningococcal infections in France 1985-97")
> plot(meningo.age, as.one=FALSE)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("meningo.age", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("momo")
> ### * momo
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: momo
> ### Title: Danish 1994-2008 all-cause mortality data for eight age groups
> ### Aliases: momo
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data("momo")
> momo
-- An object of class sts -- 
freq:		 52 with strptime format string %V
start:		 1994-01-03 
dim(observed):	 782 8 

Head of observed:
     [0,1) [1,5) [5,15) [15,45) [45,65) [65,75) [75,85) [85,Inf)
[1,]    11     4      2      53     212     279     528      408
> 
> ## show the period 2000-2008 with customized x-axis annotation
> ## (this is Figure 1 in Hoehle and Mazick, 2010)
> oopts <- surveillance.options("stsTickFactors" = c("%G" = 1.5, "%Q"=.75))
> plot(momo[year(momo) >= 2000,], ylab = "", xlab = "Time (weeks)",
+      par.list = list(las = 1), col = c(gray(0.5), NA, NA),
+      xaxis.tickFreq = list("%G"=atChange, "%Q"=atChange),
+      xaxis.labelFreq = list("%G"=atChange), xaxis.labelFormat = "%G")
> surveillance.options(oopts)
> 
> 
> if (surveillance.options("allExamples")) {
+ 
+ ## stratified monitoring from 2007-W40 using the Farrington algorithm
+ phase2 <- which(epoch(momo) >= "2007-10-01")
+ momo2 <- farrington(momo, control = list(range=phase2, alpha=0.01, b=5, w=4))
+ print(colSums(alarms(momo2)))
+ plot(momo2, col = c(8, NA, 4), same.scale = FALSE)
+ 
+ ## stripchart of alarms (Figure 5 in Hoehle and Mazick, 2010)
+ plot(momo2, type = alarm ~ time, xlab = "Time (weeks)", main = "",
+      alarm.symbol = list(pch=3, col=1, cex=1.5))
+ 
+ }
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("momo", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("multiplicity.Spatial")
> ### * multiplicity.Spatial
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: multiplicity.Spatial
> ### Title: Count Number of Instances of Points
> ### Aliases: multiplicity.Spatial
> ### Keywords: utilities spatial
> 
> ### ** Examples
> 
> foo <- SpatialPoints(matrix(c(1,2,
+                               2,3,
+                               1,2,
+                               4,5), 4, 2, byrow=TRUE))
> multiplicity(foo)
1 2 3 4 
2 1 2 1 
> 
> # the following function determines the multiplicities in a matrix
> # or data frame and returns unique rows with appended multiplicity
> countunique <- function(x) unique(cbind(x, count=multiplicity(x)))
> countunique(coordinates(foo))
  coords.x1 coords.x2 count
1         1         2     2
2         2         3     1
4         4         5     1
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("multiplicity.Spatial", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("nbOrder")
> ### * nbOrder
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: nbOrder
> ### Title: Determine Neighbourhood Order Matrix from Binary Adjacency
> ###   Matrix
> ### Aliases: nbOrder
> ### Keywords: spatial utilities
> 
> ### ** Examples
> 
> ## generate adjacency matrix
> set.seed(1)
> n <- 6
> adjmat <- matrix(0, n, n)
> adjmat[lower.tri(adjmat)] <- sample(0:1, n*(n-1)/2, replace=TRUE)
> adjmat <- adjmat + t(adjmat)
> adjmat
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    0    0    1    0    0    1
[2,]    0    0    0    0    0    1
[3,]    1    0    0    1    0    0
[4,]    0    0    1    0    0    0
[5,]    0    0    0    0    0    0
[6,]    1    1    0    0    0    0
> 
> ## determine neighbourhood order matrix
> nblags <- nbOrder(adjmat)
> nblags
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    0    2    1    2    0    1
[2,]    2    0    3    4    0    1
[3,]    1    3    0    1    0    2
[4,]    2    4    1    0    0    3
[5,]    0    0    0    0    0    0
[6,]    1    1    2    3    0    0
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("nbOrder", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("nowcast")
> ### * nowcast
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: nowcast
> ### Title: Adjust a univariate time series of counts for observed
> ###   but-not-yet-reported events
> ### Aliases: nowcast
> ### Keywords: models
> 
> ### ** Examples
> 
> data("husO104Hosp")
> 
> #Extract the reporting triangle at a specific day
> t.repTriangle <- as.Date("2011-07-04")
> 
> #Use 'void' nowcasting procedure (we just want the reporting triangle)
> nc <- nowcast(now=t.repTriangle,when=t.repTriangle,
+               dEventCol="dHosp",dReportCol="dReport",data=husO104Hosp,
+               D=15,method="unif")
Removed 0 records due to NA dates.
Building reporting triangle...
No. cases:  626 
No. cases within moving window:  626 
> 
> #Show reporting triangle
> reportingTriangle(nc)
           [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]
2011-05-07    0    0    0    0    0    0    0    0    0     0     0     1     0
2011-05-08    0    0    0    0    0    0    0    0    0     0     0     0     0
2011-05-09    0    0    0    0    0    0    0    0    0     0     0     0     0
2011-05-10    0    0    0    0    0    0    0    0    0     0     0     0     0
2011-05-11    0    0    0    0    0    0    0    0    0     0     0     0     0
2011-05-12    0    0    0    0    0    0    0    0    0     0     0     0     0
2011-05-13    0    0    0    0    0    0    0    0    0     0     0     2     2
2011-05-14    0    0    0    0    0    0    0    0    0     0     0     0     1
2011-05-15    0    0    0    0    0    0    0    0    0     1     2     4     1
2011-05-16    0    0    0    0    0    0    0    0    0     2     3     2     0
2011-05-17    0    0    0    0    0    0    0    5    2     6     3     0     1
2011-05-18    0    0    0    0    0    0    2    1    9     2     0     0     2
2011-05-19    0    0    0    0    1    5    5    9    3     0     0     0     1
2011-05-20    0    0    0    0    4    5    4    6    0     2     5     1     2
2011-05-21    0    0    0    3    6   17   15    0    0     7     4     1     0
2011-05-22    0    0    2    1   11    8    0    2    4     8     2     0     3
2011-05-23    0    0    1    9    6    0    3    3    2     1     0     5     2
2011-05-24    0    1    8    9    0    1    9    2    4     0     5     1     0
2011-05-25    1    0   10    0    1    5    7    4    0     4     2     1     4
2011-05-26    0    6    0    1    6    6    3    0    3     2     0     1     0
2011-05-27    0    0    0    8    6    1    0    3    6     0     1     1     2
2011-05-28    0    0    2    2    4    0    4    2    0     0     3     0     3
2011-05-29    0    3    4    2    0    3    0    0    1     2     1     1     0
2011-05-30    1    2    2    0    6    1    0    1    5     3     1     0     1
2011-05-31    0    2    0    2    3    0    0    5    3     0     0     0     0
2011-06-01    0    0    2    3    0    0    1    2    4     3     1     0     0
2011-06-02    0    0    0    0    1    3    1    1    0     0     0     0     0
2011-06-03    1    0    0    4    2    1    2    0    0     0     0     0     0
2011-06-04    0    0    1    1    0    2    0    0    0     0     0     0     0
2011-06-05    0    0    1    1    1    1    0    0    0     1     0     0     0
2011-06-06    0    1    2    0    3    0    0    0    1     1     0     0     0
2011-06-07    1    0    1    0    1    0    0    0    0     0     1     0     0
2011-06-08    0    1    0    0    0    0    0    0    0     0     0     0     0
2011-06-09    0    0    0    0    0    0    0    0    1     0     0     1     0
2011-06-10    0    0    0    0    1    0    0    1    0     0     0     0     0
2011-06-11    0    0    0    0    0    0    1    0    0     1     0     0     0
2011-06-12    0    0    0    0    0    1    0    0    0     0     0     0     1
2011-06-13    0    0    0    0    0    0    0    0    1     0     0     0     0
2011-06-14    0    0    0    0    0    0    1    0    1     0     0     0     0
2011-06-15    0    0    0    0    0    0    0    0    2     0     0     0     0
2011-06-16    0    0    0    0    0    0    0    1    2     0     0     0     0
2011-06-17    0    0    0    0    1    3    0    0    0     0     0     0     0
2011-06-18    0    0    0    1    0    0    0    0    0     0     0     0     0
2011-06-19    0    0    1    0    1    0    0    0    0     0     0     0     0
2011-06-20    0    0    0    0    0    0    0    0    0     0     0     0     0
2011-06-21    0    0    1    1    0    0    0    1    0     0     0     0     0
2011-06-22    0    1    0    0    0    1    0    0    0     1     0     0     0
2011-06-23    0    0    0    0    0    0    1    0    0     0     0     0    NA
2011-06-24    0    0    0    0    0    0    0    0    0     0     0    NA    NA
2011-06-25    0    0    0    0    1    0    0    0    0     0    NA    NA    NA
2011-06-26    0    0    0    0    0    0    0    0    0    NA    NA    NA    NA
2011-06-27    0    0    0    1    0    0    0    0   NA    NA    NA    NA    NA
2011-06-28    0    0    0    2    0    0    0   NA   NA    NA    NA    NA    NA
2011-06-29    0    0    0    0    0    0   NA   NA   NA    NA    NA    NA    NA
2011-06-30    0    0    0    0    0   NA   NA   NA   NA    NA    NA    NA    NA
2011-07-01    0    0    0    0   NA   NA   NA   NA   NA    NA    NA    NA    NA
2011-07-02    0    0    0   NA   NA   NA   NA   NA   NA    NA    NA    NA    NA
2011-07-03    0    0   NA   NA   NA   NA   NA   NA   NA    NA    NA    NA    NA
2011-07-04    0   NA   NA   NA   NA   NA   NA   NA   NA    NA    NA    NA    NA
           [,14] [,15] [,16]
2011-05-07     0     0     0
2011-05-08     0     0     0
2011-05-09     0     0     0
2011-05-10     0     0     0
2011-05-11     0     0     0
2011-05-12     1     0     1
2011-05-13     0     0     2
2011-05-14     0     0     0
2011-05-15     0     0     1
2011-05-16     0     1     4
2011-05-17     0     0     0
2011-05-18     0     0     3
2011-05-19     1     0     4
2011-05-20     0     2     4
2011-05-21     1     2    10
2011-05-22     0     0     1
2011-05-23     0     3     9
2011-05-24     0     2     9
2011-05-25     2     1     7
2011-05-26     1     2     3
2011-05-27     2     1     3
2011-05-28     0     0     2
2011-05-29     0     0     2
2011-05-30     0     0     3
2011-05-31     1     0     1
2011-06-01     0     0     0
2011-06-02     0     0     0
2011-06-03     1     0     0
2011-06-04     0     0     0
2011-06-05     0     0     1
2011-06-06     0     0     1
2011-06-07     0     0     0
2011-06-08     0     0     0
2011-06-09     0     0     0
2011-06-10     0     0     0
2011-06-11     0     0     0
2011-06-12     0     0     0
2011-06-13     0     0     0
2011-06-14     0     0     0
2011-06-15     0     0     0
2011-06-16     0     0     0
2011-06-17     0     0     0
2011-06-18     0     0     0
2011-06-19     0     0     0
2011-06-20     0     0    NA
2011-06-21     0    NA    NA
2011-06-22    NA    NA    NA
2011-06-23    NA    NA    NA
2011-06-24    NA    NA    NA
2011-06-25    NA    NA    NA
2011-06-26    NA    NA    NA
2011-06-27    NA    NA    NA
2011-06-28    NA    NA    NA
2011-06-29    NA    NA    NA
2011-06-30    NA    NA    NA
2011-07-01    NA    NA    NA
2011-07-02    NA    NA    NA
2011-07-03    NA    NA    NA
2011-07-04    NA    NA    NA
attr(,"n.x")
 [1]  4 17 38 51 66 64 59 49 54 47 34 22 26 10 14 71
attr(,"N.x")
 [1]   4  21  59 110 176 240 299 346 399 446 479 501 526 533 544 615
attr(,"N.tT")
 [1]  1  0  0  0  0  2  6  1  9 12 17 19 29 35 66 42 44 51 49 34 34 22 19 26 17
[26] 16  6 11  4  6  9  4  1  2  2  2  2  1  2  2  3  4  1  2  0  3  3  1  0  1
[51]  0  1  2  0  0  0  0  0  0
attr(,"N.tInf")

2011-05-07 2011-05-08 2011-05-09 2011-05-10 2011-05-11 2011-05-12 2011-05-13 
         1          0          0          0          0          2          6 
2011-05-14 2011-05-15 2011-05-16 2011-05-17 2011-05-18 2011-05-19 2011-05-20 
         1          9         12         17         19         29         35 
2011-05-21 2011-05-22 2011-05-23 2011-05-24 2011-05-25 2011-05-26 2011-05-27 
        66         42         44         51         49         34         34 
2011-05-28 2011-05-29 2011-05-30 2011-05-31 2011-06-01 2011-06-02 2011-06-03 
        22         19         26         17         16          6         11 
2011-06-04 2011-06-05 2011-06-06 2011-06-07 2011-06-08 2011-06-09 2011-06-10 
         4          6          9          4          1          2          2 
2011-06-11 2011-06-12 2011-06-13 2011-06-14 2011-06-15 2011-06-16 2011-06-17 
         2          2          1          2          2          3          4 
2011-06-18 2011-06-19 2011-06-20 2011-06-21 2011-06-22 2011-06-23 2011-06-24 
         1          2          0          3          3          1          0 
2011-06-25 2011-06-26 2011-06-27 2011-06-28 2011-06-29 2011-06-30 2011-07-01 
         1          0          1          3          1          0          0 
2011-07-02 2011-07-03 2011-07-04 
         0          1          1 
attr(,"T")
[1] 58
attr(,"D")
[1] 15
attr(,"t02s")
 [1] "2011-05-07" "2011-05-08" "2011-05-09" "2011-05-10" "2011-05-11"
 [6] "2011-05-12" "2011-05-13" "2011-05-14" "2011-05-15" "2011-05-16"
[11] "2011-05-17" "2011-05-18" "2011-05-19" "2011-05-20" "2011-05-21"
[16] "2011-05-22" "2011-05-23" "2011-05-24" "2011-05-25" "2011-05-26"
[21] "2011-05-27" "2011-05-28" "2011-05-29" "2011-05-30" "2011-05-31"
[26] "2011-06-01" "2011-06-02" "2011-06-03" "2011-06-04" "2011-06-05"
[31] "2011-06-06" "2011-06-07" "2011-06-08" "2011-06-09" "2011-06-10"
[36] "2011-06-11" "2011-06-12" "2011-06-13" "2011-06-14" "2011-06-15"
[41] "2011-06-16" "2011-06-17" "2011-06-18" "2011-06-19" "2011-06-20"
[46] "2011-06-21" "2011-06-22" "2011-06-23" "2011-06-24" "2011-06-25"
[51] "2011-06-26" "2011-06-27" "2011-06-28" "2011-06-29" "2011-06-30"
[56] "2011-07-01" "2011-07-02" "2011-07-03" "2011-07-04"
> 
> #Perform Bayesian nowcasting assuming the delay distribution is stable over time
> nc.control <- list(N.tInf.prior=structure("poisgamma",
+                                 mean.lambda=50,var.lambda=3000),
+                                 nSamples=1e2)
> 
> t.repTriangle <- as.Date("2011-06-10")
> when <- seq(t.repTriangle-3,length.out=10,by="-1 day")
> nc <- nowcast(now=t.repTriangle,when=when,
+               dEventCol="dHosp",dReportCol="dReport",data=husO104Hosp,
+               D=15,method="bayes.trunc",control=nc.control)
Removed 0 records due to NA dates.
Building reporting triangle...
No. cases:  570 
No. cases within moving window:  570 
bayes prep...
(E,V) of prior for lambda = ( 50,3000.07824271886 )
bayes.trunc...
> 
> #Show time series and posterior median forecast/nowcast
> plot(nc,xaxis.tickFreq=list("%d"=atChange,"%m"=atChange),
+      xaxis.labelFreq=list("%d"=at2ndChange),xaxis.labelFormat="%d-%b",
+      xlab="Time (days)",lty=c(1,1,1,1),lwd=c(1,1,2))
> 
> ## Not run: 
> ##D ### Using runjags to do a Bayesian model with changepoint(s)
> ##D ### -- this might take a while
> ##D nc.control.ddcp <- modifyList(nc.control,
> ##D                     list(gd.prior.kappa=0.1,
> ##D                          ddcp=list(ddChangepoint=as.Date(c("2011-05-23")),
> ##D                              logLambda="tps",
> ##D                              tau.gamma=1,
> ##D                              mcmc=c(burnin=1000,sample=1000,thin=1,
> ##D                                     adapt=1000,store.samples=FALSE))))
> ##D 
> ##D nc.ddcp <- nowcast(now=t.repTriangle,when=when,
> ##D                dEventCol="dHosp",dReportCol="dReport",
> ##D                data=husO104Hosp, aggregate.by="1 day",
> ##D                method="bayes.trunc.ddcp", D=15,
> ##D                    control=nc.control.ddcp)
> ##D 
> ##D plot(nc.ddcp,legend.opts=NULL,
> ##D      xaxis.tickFreq=list("%d"=atChange,"%m"=atChange),
> ##D      xaxis.labelFreq=list("%d"=at2ndChange),xaxis.labelFormat="%d-%b",
> ##D      xlab="Time (days)",lty=c(1,1,1,1),lwd=c(1,1,2))
> ##D 
> ##D lambda <- attr(delayCDF(nc.ddcp)[["bayes.trunc.ddcp"]],"model")$lambda
> ##D showIdx <- seq(which( max(when) == epoch(nc.ddcp))) #seq(ncol(lambda))
> ##D matlines( showIdx,t(lambda)[showIdx,],col="gray",lwd=c(1,2,1),lty=c(2,1,2))
> ##D legend(x="topright",c(expression(lambda(t)),"95% CI"),col="gray",lwd=c(2,1),lty=c(1,2))
> ## End(Not run)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("nowcast", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("pairedbinCUSUM")
> ### * pairedbinCUSUM
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: pairedbinCUSUM
> ### Title: Paired binary CUSUM and its run-length computation
> ### Aliases: pairedbinCUSUM pairedbinCUSUM.runlength
> ###   pairedbinCUSUM.LLRcompute
> ### Keywords: regression
> 
> ### ** Examples
> 
> #Set in-control and out-of-control parameters as in paper
> theta0 <- c(-2.3,-4.5,2.5)
> theta1 <- c(-1.7,-2.9,2.5)
> 
> #Small helper function to compute the paired-binary likelihood
> #of the length two vector yz when the true parameters are theta
> dPBin <- function(yz,theta) {
+     exp(dbinom(yz[1],size=1,prob=plogis(theta[1]),log=TRUE) +
+     dbinom(yz[2],size=1,prob=plogis(theta[2]+theta[3]*yz[1]),log=TRUE))
+ }
> 
> #Likelihood ratio for all four possible configurations
> p <- c(dPBin(c(0,0), theta=theta0), dPBin(c(0,1), theta=theta0),
+        dPBin(c(1,0), theta=theta0), dPBin(c(1,1), theta=theta0))
> if (surveillance.options("allExamples"))
+ #Compute ARL using slow, non-sparse matrix operations
+ pairedbinCUSUM.runlength(p,w1=c(-1,37,-9,29),w2=c(-1,7),h1=70,h2=32,
+                          h11=38,h22=17)
> 
> #Sparse computations can be considerably (!) faster
> pairedbinCUSUM.runlength(p,w1=c(-1,37,-9,29),w2=c(-1,7),h1=70,h2=32,
+                          h11=38,h22=17,sparse=TRUE)
g = 1763 
[1] 284.3664
> 
> #Use paired binary CUSUM on the De Leval et al. (1994) arterial switch
> #operation data on 104 newborn babies
> data("deleval")
> 
> #Switch between death and near misses
> observed(deleval) <- observed(deleval)[,c(2,1)]
> 
> #Run paired-binary CUSUM without generating alarms.
> pb.surv <- pairedbinCUSUM(deleval,control=list(theta0=theta0,
+              theta1=theta1,h1=Inf,h2=Inf,h11=Inf,h22=Inf))
> 
> plot(pb.surv, xaxis.labelFormat=NULL, ylab="CUSUM Statistic")
> 
> 
> 
> ######################################################################
> #Scale the plots so they become comparable to the plots in Steiner et
> #al. (1999). To this end a small helper function is defined.
> ######################################################################
> 
> ######################################################################
> #Log LR for conditional specification of the paired model
> ######################################################################
> LLR.pairedbin <- function(yz,theta0, theta1) {
+     #In control
+     alphay0 <- theta0[1] ; alphaz0 <- theta0[2] ; beta0 <- theta0[3]
+     #Out of control
+     alphay1 <- theta1[1] ; alphaz1 <- theta1[2] ; beta1 <- theta1[3]
+     #Likelihood ratios
+     llry <- (alphay1-alphay0)*yz[1]+log(1+exp(alphay0))-log(1+exp(alphay1))
+     llrz <- (alphaz1-alphaz0)*yz[2]+log(1+exp(alphaz0+beta0*yz[1]))-
+                                     log(1+exp(alphaz1+beta1*yz[1]))
+     return(c(llry=llry,llrz=llrz))
+ }
> 
> 
> val <- expand.grid(0:1,0:1)
> table <- t(apply(val,1, LLR.pairedbin, theta0=theta0, theta1=theta1))
> w1 <- min(abs(table[,1]))
> w2 <- min(abs(table[,2]))
> S <- upperbound(pb.surv) / cbind(rep(w1,nrow(observed(pb.surv))),w2)
> 
> #Show results
> opar <- par(mfcol=c(2,1))
> plot(1:nrow(deleval),S[,1],type="l",main="Near Miss",xlab="Patient No.",
+      ylab="CUSUM Statistic")
> lines(c(0,1e99), c(32,32),lty=2,col=2)
> lines(c(0,1e99), c(17,17),lty=2,col=3)
> 
> plot(1:nrow(deleval),S[,2],type="l",main="Death",xlab="Patient No.",
+      ylab="CUSUM Statistic")
>     lines(c(0,1e99), c(70,70),lty=2,col=2)
>     lines(c(0,1e99), c(38,38),lty=2,col=3)
> par(opar)
> 
> ######################################################################
> # Run the CUSUM with thresholds as in Steiner et al. (1999).
> # After each alarm the CUSUM statistic is set to zero and
> # monitoring continues from this point. Triangles indicate alarm
> # in the respective CUSUM (nearmiss or death). If in both
> # simultaneously then an alarm is caused by the secondary limits.
> ######################################################################
> pb.surv2 <- pairedbinCUSUM(deleval,control=list(theta0=theta0,
+              theta1=theta1,h1=70*w1,h2=32*w2,h11=38*w1,h22=17*w2))
> 
> plot(pb.surv2, xaxis.labelFormat=NULL)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("pairedbinCUSUM", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("permutationTest")
> ### * permutationTest
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: permutationTest
> ### Title: Monte Carlo Permutation Test for Paired Individual Scores
> ### Aliases: permutationTest
> ### Keywords: htest
> 
> ### ** Examples
> 
> permutationTest(rnorm(50, 1.5), rnorm(50, 1), plot = TRUE)
$diffObs
[1] 0.4831218

$pVal.permut
[1] 0.0118

$pVal.t
[1] 0.01150569

> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("permutationTest", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("pit")
> ### * pit
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: pit
> ### Title: Non-Randomized Version of the PIT Histogram (for Count Data)
> ### Aliases: pit pit.default
> ### Keywords: dplot
> 
> ### ** Examples
> 
> ## Simulation example of Czado et al. (2009, Section 2.4)
> set.seed(100)
> x <- rnbinom(200, mu = 5, size = 2)
> pdistrs <- list("NB(5,0)"   = function (x) ppois(x, lambda=5),
+                 "NB(5,1/2)" = function (x) pnbinom(x, mu=5, size=2),
+                 "NB(5,1)"   = function (x) pnbinom(x, mu=5, size=1))
> ## Reproduce Figure 1
> op <- par(mfrow = c(1,3))
> for (i in seq_along(pdistrs)) {
+     pit(x, pdistr = pdistrs[[i]], J = 10,
+         plot = list(ylim = c(0,2.75), main = names(pdistrs)[i]))
+     box()
+ }
> par(op)
> 
> ## Alternative call using ... arguments for pdistr (less efficient)
> stopifnot(identical(pit(x, "pnbinom", mu = 5, size = 2, plot = FALSE),
+                     pit(x, pdistrs[[2]], plot = FALSE)))
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("pit", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("plapply")
> ### * plapply
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: plapply
> ### Title: Verbose and Parallel 'lapply'
> ### Aliases: plapply
> ### Keywords: iteration list
> 
> ### ** Examples
> 
> ## example inspired by help("lapply")
> x <- list(a = 1:10, beta = exp(-3:3), logic = c(TRUE,FALSE,FALSE,TRUE))
> 
> ## if neither parallel nor verbose then this simply equals lapply()
> plapply(x, quantile, probs = 1:3/4, .verbose = FALSE)
$a
 25%  50%  75% 
3.25 5.50 7.75 

$beta
      25%       50%       75% 
0.2516074 1.0000000 5.0536690 

$logic
25% 50% 75% 
0.0 0.5 1.0 

> 
> ## verbose lapply() -- not really useful for such fast computations
> res <- plapply(x, quantile, probs = 1:3/4, .verbose = TRUE)
...
> res <- plapply(x, quantile, probs = 1:3/4, .verbose = "|")
|||
> res <- plapply(x, quantile, probs = 1:3/4,
+                .verbose = quote(cat("length(x) =", length(x), "\n")))
length(x) = 10 
length(x) = 7 
length(x) = 4 
> 
> ## setting the seed for reproducibility of results involving the RNG
> samp <- plapply(as.list(1:3), runif, .seed = 1)
...
> 
> ## parallel lapply()
> res <- plapply(x, quantile, probs = 1:3/4, .parallel = 2, .verbose = FALSE)
> 
> ## using a predefined cluster
> library("parallel")
> cl <- makeCluster(getOption("cl.cores", 2))
> res <- plapply(x, quantile, probs = 1:3/4, .parallel = cl)
> stopCluster(cl)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("plapply", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()

detaching ‘package:parallel’

> nameEx("plot.disProg")
> ### * plot.disProg
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: plot.disProg
> ### Title: Plot Observed Counts and Defined Outbreak States of a
> ###   (Multivariate) Time Series
> ### Aliases: plot.disProg
> ### Keywords: hplot internal
> 
> ### ** Examples
> 
> # Plotting of simulated data
> disProgObj <- sim.pointSource(p = 0.99, r = 0.5, length = 208,
+                               A = 1, alpha = 1, beta = 0, phi = 0,
+                               frequency = 1, state = NULL, K = 5)
> plot(disProgObj)
> title <- "Infection Counts and Defined Outbreaks for Simulated Data"
> plot(disProgObj, title = title)
> plot(disProgObj, title = title, xaxis.years = FALSE)
> 
> # Plotting of measles data
> data(measles.weser)
> # one plot
> plot(measles.weser, title = "measles cases in the district Weser-Ems")
> # plot cases for each "Kreis" 
> plot(measles.weser, as.one = FALSE)
> plot(measles.weser, as.one = FALSE, same.scale = FALSE)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("plot.disProg", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("plot.survRes")
> ### * plot.survRes
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: plot.survRes
> ### Title: Plot a 'survRes' object
> ### Aliases: plot.survRes
> ### Keywords: hplot internal
> 
> ### ** Examples
> 
> data(ha)
> ctrl <- list(range = 209:290, b = 2, w = 6, alpha = 0.005)
> plot(algo.bayes(aggregate(ha), control = ctrl))
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("plot.survRes", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("poly2adjmat")
> ### * poly2adjmat
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: poly2adjmat
> ### Title: Derive Adjacency Structure of '"SpatialPolygons"'
> ### Aliases: poly2adjmat
> ### Keywords: spatial graphs
> 
> ### ** Examples
> 
> if (requireNamespace("spdep")) {
+     ## generate adjacency matrix for districts of Bayern and Baden-Wuerttemberg
+     data("fluBYBW")
+     adjmat <- poly2adjmat(fluBYBW@map)
+ 
+     ## same as already stored in the neighbourhood slot (in different order)
+     stopifnot(all.equal(adjmat,
+                         neighbourhood(fluBYBW)[rownames(adjmat),colnames(adjmat)]))
+ 
+     ## a visual check of the district-specific number of neighbours
+     plot(fluBYBW@map)
+     text(coordinates(fluBYBW@map), labels=rowSums(adjmat==1), font=2, col=2)
+ }
Loading required namespace: spdep
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("poly2adjmat", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("polyAtBorder")
> ### * polyAtBorder
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: polyAtBorder
> ### Title: Indicate Polygons at the Border
> ### Aliases: polyAtBorder
> ### Keywords: spatial
> 
> ### ** Examples
> 
> ## Load districts of Germany
> load(system.file("shapes", "districtsD.RData", package = "surveillance"))
> 
> ## Determine districts at the border and check the result on the map
> if (requireNamespace("sf")) {
+     atBorder <- polyAtBorder(districtsD, method = "sf")
+     if (interactive()) plot(districtsD, col = atBorder)
+     table(atBorder)
+ }
atBorder
FALSE  TRUE 
  324    89 
> 
> ## For method = "polyclip", a higher snapping tolerance is required
> ## to obtain the correct result
> if (requireNamespace("polyclip")) {
+     atBorder <- polyAtBorder(districtsD, snap = 1e-6, method = "polyclip")
+     if (interactive()) plot(districtsD, col = atBorder)
+     table(atBorder)
+ }
atBorder
FALSE  TRUE 
  324    89 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("polyAtBorder", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("print.algoQV")
> ### * print.algoQV
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: print.algoQV
> ### Title: Print Quality Value Object
> ### Aliases: print.algoQV
> ### Keywords: print
> 
> ### ** Examples
> 
> # Create a test object
> disProgObj <- sim.pointSource(p = 0.99, r = 0.5, length = 200, A = 1,
+                               alpha = 1, beta = 0, phi = 0,
+                               frequency = 1, state = NULL, K = 1.7)
> 
> # Let this object be tested from rki1
> survResObj <- algo.rki1(disProgObj, control = list(range = 50:200))
> 
> # Compute the quality values in a nice formatted way
> algo.quality(survResObj) 
     TP FP TN  FN Sens Spec      dist       mlag
[1,] 3  6  142 0  1    0.9594595 0.04054054 0   
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("print.algoQV", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("runifdisc")
> ### * runifdisc
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: runifdisc
> ### Title: Sample Points Uniformly on a Disc
> ### Aliases: runifdisc
> ### Keywords: datagen distribution internal
> 
> ### ** Examples
> 
> x <- surveillance:::runifdisc(1000, 3)
> plot(x)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("runifdisc", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("scores")
> ### * scores
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: scores
> ### Title: Proper Scoring Rules for Poisson or Negative Binomial
> ###   Predictions
> ### Aliases: scores scores.default logs rps dss ses
> ### Keywords: univar
> 
> ### ** Examples
> 
> mu <- c(0.1, 1, 3, 6, 3*pi, 100)
> size <- 0.5
> set.seed(1)
> y <- rnbinom(length(mu), mu = mu, size = size)
> scores(y, mu = mu, size = size)
           logs          rps       dss        ses
[1,] 0.09116078  0.007716168 -2.036930    0.01000
[2,] 3.97867440  3.426697928  6.431946   16.00000
[3,] 2.59855792  1.082239930  3.044522    0.00000
[4,] 4.41783713  7.502890265  5.395170   81.00000
[5,] 1.49409082  3.277020067  5.706334   88.82644
[6,] 4.43768017 29.629367920 10.311460 8100.00000
> scores(y, mu = mu, size = 1)  # ses ignores the variance
           logs          rps       dss        ses
[1,] 0.09531018  0.008333333 -2.116366    0.01000
[2,] 4.15888308  3.395833333  8.693147   16.00000
[3,] 2.24934058  0.816964286  2.484907    0.00000
[4,] 4.25817035  6.957676628  5.666241   81.00000
[5,] 2.34418547  4.474983721  5.491602   88.82644
[6,] 4.71462383 40.808634720 10.022271 8100.00000
> scores(y, mu = 1, size = size)
          logs        rps       dss ses
[1,] 0.5493061  0.2600427  1.431946   1
[2,] 3.9786744  3.4266979  6.431946  16
[3,] 2.9288523  1.6863948  2.431946   4
[4,] 8.5660046 13.2620454 66.431946 196
[5,] 0.5493061  0.2600427  1.431946   1
[6,] 6.3401095  8.2776897 28.098612  81
> 
> ## apply a specific scoring rule
> scores(y, mu = mu, size = size, which = "rps")
              rps
[1,]  0.007716168
[2,]  3.426697928
[3,]  1.082239930
[4,]  7.502890265
[5,]  3.277020067
[6,] 29.629367920
> rps(y, mu = mu, size = size)
[1]  0.007716168  3.426697928  1.082239930  7.502890265  3.277020067
[6] 29.629367920
> ## Don't show: 
> # failed in surveillance <= 1.19.1
>     stopifnot(!is.unsorted(rps(3, mu = 10^-(0:8)), strictly = TRUE))
> ## End(Don't show)
> ## rps() gives NA (with a warning) if the NegBin is too wide
> rps(1e5, mu = 1e5, size = 1e-5)
Warning in (function (x, mu, size, k = 40, tolerance = sqrt(.Machine$double.eps))  :
  quasi-continuous NegBin distribution (too wide); returning NA
[1] NA
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("scores", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("shadar")
> ### * shadar
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: shadar
> ### Title: Salmonella Hadar cases in Germany 2001-2006
> ### Aliases: shadar
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(shadar)
> plot(shadar)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("shadar", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("sim.pointSource")
> ### * sim.pointSource
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: sim.pointSource
> ### Title: Simulate Point-Source Epidemics
> ### Aliases: sim.pointSource
> ### Keywords: datagen
> 
> ### ** Examples
> 
> set.seed(123)
> disProgObj <- sim.pointSource(p = 0.99, r = 0.5, length = 208,
+                               A = 1, alpha = 1, beta = 0, phi = 0,
+                               frequency = 1, state = NULL, K = 2)
> plot(disProgObj)
> 
> ## with predefined state chain
> state <- rep(c(0,0,0,0,0,0,0,0,1,1), 20)
> disProgObj <- sim.pointSource(state = state, K = 1.2)
> plot(disProgObj)
> 
> ## simulate epidemic, send to RKI 1 system, plot, and compute quality values
> testSim <- function (..., K = 0, range = 200:400) {
+   disProgObj <- sim.pointSource(..., K = K)
+   survResults <- algo.call(disProgObj,
+     control = list(list(funcName = "rki1", range = range)))
+   plot(survResults[[1]], "RKI 1", "Simulation")
+   algo.compare(survResults)
+ }
> testSim(K = 2)
           TP FP TN  FN sens spec dist mlag
rki(6,6,0) 1  6  194 0  1    0.97 0.03 0   
> testSim(r = 0.5, K = 5)  # larger and more frequent outbreaks
           TP FP TN  FN sens spec      dist       mlag
rki(6,6,0) 5  7  189 0  1    0.9642857 0.03571429 0   
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("sim.pointSource", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("sim.seasonalNoise")
> ### * sim.seasonalNoise
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: sim.seasonalNoise
> ### Title: Generation of Background Noise for Simulated Timeseries
> ### Aliases: sim.seasonalNoise
> ### Keywords: datagen
> 
> ### ** Examples
> 
> season <- sim.seasonalNoise(length = 300)
> plot(season$seasonalBackground,type = "l")
> 
> # use a negative timetrend beta
> season <- sim.seasonalNoise(beta = -0.003, length = 300)
> plot(season$seasonalBackground,type = "l")
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("sim.seasonalNoise", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("stK")
> ### * stK
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: stK
> ### Title: Diggle et al (1995) K-function test for space-time clustering
> ### Aliases: stKtest plot.stKtest
> ### Keywords: htest
> 
> ### ** Examples
> 
> if (requireNamespace("splancs")) {
+     data("imdepi")
+     imdepiB <- subset(imdepi, type == "B")
+     mainpoly <- coordinates(imdepiB$W@polygons[[1]]@Polygons[[5]])
+     SGRID <- c(10, 25, 50, 100, 150)
+     TGRID <- c(1, 7, 14, 21)
+     B <- 19  # limited here for speed
+     ## Don't show: 
+ if (!interactive()) B <- 4
+ ## End(Don't show)
+  
+     imdBstKtest <- stKtest(imdepiB, eps.s = SGRID, eps.t = TGRID, B = B,
+                            cores = 2, seed = 1, poly = list(mainpoly))
+     print(imdBstKtest)
+     plot(imdBstKtest)
+ }
Loading required namespace: splancs
Note: dropped type(s) "C"

	Diggle et al (1995) K-function test for space-time clustering

data:  imdepiB
U = 4750840, B = 4, p-value = 0.2

> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("stK", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("stcd")
> ### * stcd
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: stcd
> ### Title: Spatio-temporal cluster detection
> ### Aliases: stcd
> ### Keywords: cluster
> 
> ### ** Examples
> 
> if (require("splancs")) {
+     # load the data from package "splancs"
+     data(burkitt, package="splancs")
+ 
+     # order the times
+     burkitt <- burkitt[order(burkitt$t), ]
+ 
+     #Parameters for the SR detection
+     epsilon <- 0.5 # relative change within the cluster
+     radius <- 20 # radius
+     threshold <- 161 # threshold limit
+ 
+     res <- stcd(x=burkitt$x,
+                 y=burkitt$y,
+                 t=burkitt$t,
+                 radius=radius,
+                 epsilon=epsilon,
+                 areaA=1,
+                 areaAcapBk=1,
+                 threshold=threshold)
+ 
+     #Index of the event
+     which.max(res$R >= threshold)
+ }
Loading required package: splancs

Spatial Point Pattern Analysis Code in S-Plus
 
 Version 2 - Spatial and Space-Time analysis

[1] 148
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("stcd", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()

detaching ‘package:splancs’

> nameEx("sts-class")
> ### * sts-class
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: sts-class
> ### Title: Class '"sts"' - surveillance time series
> ### Aliases: sts sts-class alarms,sts-method alarms<-,sts-method
> ###   upperbound,sts-method upperbound<-,sts-method control,sts-method
> ###   control<-,sts-method epoch,sts-method epoch<-,sts-method
> ###   observed,sts-method observed<-,sts-method population,sts-method
> ###   population<-,sts-method multinomialTS,sts-method
> ###   multinomialTS<-,sts-method neighbourhood,sts-method
> ###   neighbourhood<-,sts-method dim,sts-method dimnames,sts-method year
> ###   year,sts-method epochInYear epochInYear,sts-method as.data.frame.sts
> ###   as.data.frame,sts-method as.ts.sts coerce,sts,ts-method
> ###   coerce,ts,sts-method as.xts.sts
> ### Keywords: classes ts methods
> 
> ### ** Examples
> 
> showClass("sts")
Class "sts" [package "surveillance"]

Slots:
                                                                      
Name:            epoch            freq           start        observed
Class:         numeric         numeric         numeric          matrix
                                                                      
Name:            state           alarm      upperbound   neighbourhood
Class:          matrix          matrix          matrix          matrix
                                                                      
Name:   populationFrac             map         control     epochAsDate
Class:          matrix SpatialPolygons            list         logical
                      
Name:    multinomialTS
Class:         logical

Known Subclasses: "stsBP", "stsNC"
> 
> ## create an sts object from time-series data
> salmonellaDF <- read.table(system.file("extdata/salmonella.agona.txt",
+                                        package = "surveillance"), header = TRUE)
> str(salmonellaDF)
'data.frame':	312 obs. of  3 variables:
 $ week    : int  199001 199002 199003 199004 199005 199006 199007 199008 199009 199010 ...
 $ observed: int  1 0 5 2 1 2 0 4 0 0 ...
 $ state   : int  0 0 0 0 0 0 0 0 0 0 ...
> salmonella <- with(salmonellaDF,
+                    sts(observed = observed, state = state,
+                        start = c(1990, 1), frequency = 52))
> salmonella
-- An object of class sts -- 
freq:		 52 
start:		 1990 1 
dim(observed):	 312 1 

Head of observed:
     observed1
[1,]         1
> plot(salmonella)
> 
> ## these data are also available as a legacy "disProg" object in the package
> data(salmonella.agona)
> stopifnot(all.equal(salmonella, disProg2sts(salmonella.agona)))
> 
> 
> ## A typical dataset with weekly counts of measles from several districts
> data("measlesWeserEms")
> measlesWeserEms
-- An object of class sts -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 104 17 

Head of observed:
     03401 03402 03403 03404 03405 03451 03452 03453 03454 03455 03456 03457
[1,]     0     0     0     0     0     0     0     0     0     0     0     0
     03458 03459 03460 03461 03462
[1,]     0     0     0     0     0

map: 17 Polygons, 6 variables
Head of map@data:
                 GEN     AREA POPULATION vaccdoc.2004 vacc1.2004 vacc2.2004
03401 SK Delmenhorst 72177996      75986    0.9297573  0.9519231  0.7870879

Head of neighbourhood:
      03401 03402 03403 03404 03405 03451 03452 03453 03454 03455 03456 03457
03401     0     4     2     4     3     2     4     2     3     2     4     3
      03458 03459 03460 03461 03462
03401     1     3     2     1     3
> 
> ## reconstruct data("measlesWeserEms") from its components
> counts <- observed(measlesWeserEms)
> map <- measlesWeserEms@map
> populationFrac <- population(measlesWeserEms)
> weserems_nbOrder <- neighbourhood(measlesWeserEms)
> ## orders of adjacency can also be determined from the map
> if (requireNamespace("spdep")) {
+     stopifnot(identical(weserems_nbOrder,
+                         nbOrder(poly2adjmat(map))))
+ }
> mymeasles <- sts(counts, start = c(2001, 1), frequency = 52,
+                  population = populationFrac,
+                  neighbourhood = weserems_nbOrder, map = map)
> stopifnot(identical(mymeasles, measlesWeserEms))
> 
> ## convert ts/mts object to sts
> z <- ts(matrix(rpois(300,10), 100, 3), start = c(1961, 1), frequency = 12)
> z.sts <- as(z, "sts")
> plot(z.sts)
> 
> ## conversion of "sts" objects to the quasi-standard "xts" class
> if (requireNamespace("xts")) {
+     z.xts <- as.xts.sts(z.sts)
+     plot(z.xts)
+ }
Loading required namespace: xts
Failed with error:  ‘there is no package called ‘xts’’
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("sts-class", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("stsAggregate")
> ### * stsAggregate
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: aggregate-methods
> ### Title: Aggregate an '"sts"' Object Over Time or Across Units
> ### Aliases: aggregate.sts aggregate,sts-method
> ### Keywords: methods
> 
> ### ** Examples
> 
> data("ha.sts")
> dim(ha.sts)
[1] 290  12
> dim(aggregate(ha.sts, by = "unit"))
[1] 290   1
> dim(aggregate(ha.sts, nfreq = 13))
[1] 73 12
> ## Don't show: 
> ## population(ha.sts) are trivial fractions, aggregate() should keep them
> stopifnot(population(aggregate(ha.sts)) == 1/ncol(ha.sts))
> ## failed in surveillance <= 1.16.2
> ## End(Don't show)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("stsAggregate", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("stsXtrct")
> ### * stsXtrct
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: stsXtrct
> ### Title: Subsetting '"sts"' Objects
> ### Aliases: [,sts-method [,sts,ANY,ANY,ANY-method
> ### Keywords: methods
> 
> ### ** Examples
> 
> data("ha.sts")
> haagg <- aggregate(ha.sts, nfreq=13)
> 
> plot(haagg[, 3])       # Single series
> plot(haagg[1:30, 3])   # Somewhat shorter
> 
> #Counts at time 20
> plot(haagg[20, ], type = observed ~ unit)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("stsXtrct", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("sts_animate")
> ### * sts_animate
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: sts_animate
> ### Title: Animated Maps and Time Series of Disease Counts or Incidence
> ### Aliases: animate.sts
> ### Keywords: hplot dynamic spatial
> 
> ### ** Examples
> 
> data("measlesWeserEms")
> 
> ## animate the weekly counts of measles (during weeks 12-16 only, for speed)
> if (interactive() && require("animation")) {
+     oldwd <- setwd(tempdir())  # to not clutter up the current working dir
+     saveHTML(animate(measlesWeserEms, tps=12:16),
+              title="Evolution of the measles epidemic in the Weser-Ems region",
+              ani.width=500, ani.height=600)
+     setwd(oldwd)
+ }
> 
> ## Not run: 
> ##D ## animate the weekly incidence of measles (per 100'000 inhabitants),
> ##D ## and label the time series plot with dates in a specified format
> ##D animate(measlesWeserEms, tps=12:16,
> ##D         population = measlesWeserEms@map$POPULATION / 100000,
> ##D         timeplot = list(as.Date = TRUE,
> ##D                         scales = list(x = list(format = "%G/%V"))))
> ## End(Not run)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("sts_animate", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("sts_creation")
> ### * sts_creation
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: sts_creation
> ### Title: Simulate Count Time Series with Outbreaks
> ### Aliases: sts_creation
> 
> ### ** Examples
> 
> set.seed(12345)
> # Time series parameters
> scenario4 <- c(1.6,0,0.4,0.5,2)
> theta <- 1.6
> beta <- 0
> gamma1 <-0.4
> gamma2 <- 0.5
> overdispersion <- 1
> m <- 1
> # Dates
> firstDate <- "2006-01-01"
> lengthT=350
> dates <- as.Date(firstDate) + 7 * 0:(lengthT - 1)
> # Maximal delay in weeks
> D=10
> # Dates and sizes of the outbreaks
> datesOutbreak <- as.Date(c("2008-03-30","2011-09-25"))
> sizesOutbreak <- c(2,5)
> # Delay distribution
> data("salmAllOnset")
> in2011 <- which(isoWeekYear(epoch(salmAllOnset))$ISOYear == 2011)
> rT2011 <- salmAllOnset@control$reportingTriangle$n[in2011,]
> densityDelay <- apply(rT2011,2,sum, na.rm=TRUE)/sum(rT2011, na.rm=TRUE)
> # alpha for the upperbound
> alpha <- 0.05
> # Create the sts with the full time series
> stsSim <- sts_creation(theta=theta,beta=beta,gamma1=gamma1,gamma2=gamma2,m=m,
+                        overdispersion=overdispersion,
+                        dates=dates,
+                        sizesOutbreak=sizesOutbreak,datesOutbreak=datesOutbreak,
+                        delayMax=D,densityDelay=densityDelay,
+                        alpha=alpha)
> plot(stsSim)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("sts_creation", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("sts_ggplot")
> ### * sts_ggplot
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: sts_ggplot
> ### Title: Time-Series Plots for '"sts"' Objects Using 'ggplot2'
> ### Aliases: autoplot.sts
> ### Keywords: hplot ts
> 
> ### ** Examples
> 
> ## compare traditional plot() with ggplot2-based autoplot.sts()
> if (requireNamespace("ggplot2")) {
+     data("measlesDE")
+     plot(measlesDE, units = 1:2)
+     autoplot.sts(measlesDE, units = 1:2)
+ }
Loading required namespace: ggplot2
Failed with error:  ‘there is no package called ‘ggplot2’’
> 
> ## weekly incidence: population(measlesDE) gives population fractions,
> ## which we need to multiply by the total population
> if (require("ggplot2", quietly = TRUE)) {
+     autoplot.sts(measlesDE, population = 1000000/82314906) +
+         ylab("Weekly incidence [per 1'000'000 inhabitants]")
+ }
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("sts_ggplot", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("sts_observation")
> ### * sts_observation
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: sts_observation
> ### Title: Create an 'sts' object with a given observation date
> ### Aliases: sts_observation
> 
> ### ** Examples
> 
> data("salmAllOnset")
> salmAllOnsety2014m01d20 <- sts_observation(salmAllOnset,
+   dateObservation="2014-01-20",cut=FALSE)
> plot(salmAllOnset)
> lines(observed(salmAllOnsety2014m01d20),type="h",col="red")
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("sts_observation", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("sts_tidy")
> ### * sts_tidy
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: tidy.sts
> ### Title: Convert an '"sts"' Object to a Data Frame in Long (Tidy) Format
> ### Aliases: tidy.sts
> ### Keywords: manip
> 
> ### ** Examples
> 
> data("momo")
> momodat <- tidy.sts(momo)
> head(momodat)
  epoch  unit year freq epochInYear epochInPeriod       date observed state
1  8768 [0,1) 1994   52           1    0.01923077 1994-01-03       11     0
2  8775 [0,1) 1994   52           2    0.03846154 1994-01-10       11     0
3  8782 [0,1) 1994   52           3    0.05769231 1994-01-17        6     0
4  8789 [0,1) 1994   52           4    0.07692308 1994-01-24        8     0
5  8796 [0,1) 1994   52           5    0.09615385 1994-01-31       14     0
6  8803 [0,1) 1994   52           6    0.11538462 1994-02-07        9     0
  alarm upperbound population
1    NA         NA      67360
2    NA         NA      67360
3    NA         NA      67360
4    NA         NA      67360
5    NA         NA      67360
6    NA         NA      67360
> 
> ## tidy.sts(stsObj) is the same as as.data.frame(stsObj, tidy = TRUE)
> stopifnot(identical(as.data.frame(momo, tidy = TRUE), momodat))
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("sts_tidy", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("stsplot_space")
> ### * stsplot_space
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: stsplot_space
> ### Title: Map of Disease Counts/Incidence accumulated over a Given Period
> ### Aliases: stsplot_space
> ### Keywords: hplot spatial
> 
> ### ** Examples
> 
> data("measlesWeserEms")
> 
> # default plot: total region-specific counts over all weeks
> plot(measlesWeserEms, type = observed ~ unit)
> stsplot_space(measlesWeserEms)  # the same
> 
> # cumulative incidence (per 100'000 inhabitants),
> # with region labels and white borders
> plot(measlesWeserEms, observed ~ unit,
+      population = measlesWeserEms@map$POPULATION / 100000,
+      labels = list(labels = "GEN", cex = 0.7, font = 3),
+      col = "white", lwd = 2,
+      sub = "cumulative incidence (per 100'000 inhabitants)")
> 
> # incidence in a particular week, manual color breaks, display total
> plot(measlesWeserEms, observed ~ unit, tps = 62,
+      population = measlesWeserEms@map$POPULATION / 100000,
+      at = c(0, 1, 5),
+      total.args = list(x = 0, label = "Overall incidence: "))
> 
> # if we had only observed a subset of the regions
> plot(measlesWeserEms[,5:11], observed ~ unit,
+      gpar.missing = list(col = "gray", lty = 4))
Note: selection of units could invalidate the 'neighbourhood'
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("stsplot_space", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("stsplot_spacetime")
> ### * stsplot_spacetime
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: stsplot_spacetime
> ### Title: Animated Map of Disease Incidence (DEPRECATED)
> ### Aliases: stsplot_spacetime
> ### Keywords: hplot dynamic spatial internal
> 
> ### ** Examples
> 
> data("ha.sts")
> print(ha.sts)
-- An object of class sts -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 290 12 

Head of observed:
     chwi frkr lich mahe mitt neuk pank rein span zehl scho trko
[1,]    0    0    0    0    0    0    0    0    0    0    0    0

map: 12 Polygons, 3 variables
Head of map@data:
     Id                     BEZIRK SNAME
chwi  0 Charlottenburg-Wilmersdorf  chwi
> 
> ## Not run: 
> ##D # map of total counts by district (compare old vs. new implementation)
> ##D plot(ha.sts, type = observed ~ 1 | unit) # deprecated
> ##D plot(ha.sts, type = observed ~ unit, labels = TRUE)
> ##D 
> ##D # space-time animation
> ##D plot(aggregate(ha.sts,nfreq=13), type = observed ~ 1 | unit * time)
> ##D 
> ##D #print the frames to a png device
> ##D #and do the animation without extra sleeping between frames
> ##D imgname <- file.path(tempdir(), "berlin")
> ##D plot(aggregate(ha.sts,nfreq=13), type = observed ~ 1 | unit * time,
> ##D      wait.ms=0, dev.printer=list(name=imgname))
> ##D 
> ##D #Use ImageMagick (you might have to adjust the path to 'convert')
> ##D system(paste0("convert -delay 50 ", imgname,
> ##D               "*.png ", imgname, "-animated.gif"))
> ## End(Not run)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("stsplot_spacetime", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("stsplot_time")
> ### * stsplot_time
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: stsplot_time
> ### Title: Time-Series Plots for '"sts"' Objects
> ### Aliases: stsplot_time stsplot_time1 stsplot_alarm
> ### Keywords: hplot ts
> 
> ### ** Examples
> 
> data("ha.sts")
> print(ha.sts)
-- An object of class sts -- 
freq:		 52 
start:		 2001 1 
dim(observed):	 290 12 

Head of observed:
     chwi frkr lich mahe mitt neuk pank rein span zehl scho trko
[1,]    0    0    0    0    0    0    0    0    0    0    0    0

map: 12 Polygons, 3 variables
Head of map@data:
     Id                     BEZIRK SNAME
chwi  0 Charlottenburg-Wilmersdorf  chwi
> 
> plot(ha.sts, type=observed ~ time | unit)  # default multivariate type
> plot(ha.sts, units=c("mitt", "pank"))      # selected units
> plot(ha.sts, type=observed ~ time)         # aggregated over all districts
> 
> ## Hook function example
> hookFunc <- function() grid(NA,NULL,lwd=1)
> plot(ha.sts, hookFunc=hookFunc)
> 
> ## another multivariate time series example plotted "as.one"
> data("measlesDE")
> plot(measlesDE, units=1:2, as.one=TRUE, legend.opts=list(cex=0.8))
> ## more sophisticated plots are offered by package "xts"
> if (requireNamespace("xts"))
+     plot(as.xts.sts(measlesDE))
Loading required namespace: xts
Failed with error:  ‘there is no package called ‘xts’’
> 
> ## Use ISO8601 date formatting (see ?strptime) and no legend
> data("salmNewport")
> plot(aggregate(salmNewport,by="unit"), xlab="Time (weeks)",
+      xaxis.tickFreq=list("%m"=atChange,"%G"=atChange),
+      xaxis.labelFreq=list("%G"=atMedian),xaxis.labelFormat="%G")
> 
> ## Formatting also works for daily data (illustrated by artificial
> ## outbreak converted to sts object via 'linelist2sts')
> set.seed(123)
> exposureTimes <-  as.Date("2014-03-12") + sample(x=0:25,size=99,replace=TRUE)
> sts <- linelist2sts(data.frame(exposure=exposureTimes),
+                                dateCol="exposure",aggregate.by="1 day")
> ## Plot it with larger ticks for days than usual
> surveillance.options("stsTickFactors"=c("%d"=1, "%W"=0.33,
+                 "%V"=0.33, "%m"=1.75, "%Q"=1.25, "%Y"=1.5, "%G"=1.5))
> plot(sts,xaxis.tickFreq=list("%d"=atChange,"%m"=atChange),
+      xaxis.labelFreq=list("%d"=at2ndChange),xaxis.labelFormat="%d-%b",
+      xlab="Time (days)")
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("stsplot_time", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("surveillance-package")
> ### * surveillance-package
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: surveillance-package
> ### Title: 'surveillance': Temporal and Spatio-Temporal Modeling and
> ###   Monitoring of Epidemic Phenomena
> ### Aliases: surveillance-package surveillance
> ### Keywords: package
> 
> ### ** Examples
> 
> ## Additional documentation and illustrations of the methods are
> ## available in the form of package vignettes and demo scripts:
> vignette(package = "surveillance")
Vignettes in package ‘surveillance’:

surveillance            Getting started with outbreak detection
                        (source, pdf)
monitoringCounts        Monitoring count time series in R: Aberration
                        detection in public health surveillance
                        (source, pdf)
glrnb                   algo.glrnb: Count data regression charts using
                        the generalized likelihood ratio statistic
                        (source, pdf)
hhh4_spacetime          hhh4 (spatio-temporal): Endemic-epidemic
                        modeling of areal count time series (source,
                        pdf)
hhh4                    hhh4: An endemic-epidemic modelling framework
                        for infectious disease counts (source, pdf)
twinSIR                 twinSIR: Individual-level epidemic modeling for
                        a fixed population with known distances
                        (source, pdf)
twinstim                twinstim: An endemic-epidemic modeling
                        framework for spatio-temporal point patterns
                        (source, pdf)

> demo(package = "surveillance")
Demos in package ‘surveillance’:

biosurvbook             Code from the book chapter on Danish mortality
                        monitoring (Hoehle and Mazick, 2010)
cost                    Code from the first paper about the R package
                        surveillance (Hoehle, 2007, Comput Stat)
                        illustrating some methods for aberration
                        detection
fluBYBW                 Code from Paul and Held (2011, Stat Med) to
                        illustrate hhh4() model fitting and predictive
                        model assessement with proper scoring rules: an
                        application to weekly influenza counts in
                        Southern Germany
v77i11                  Replication code from Meyer et al. (2017, JSS),
                        illustrating the spatio-temporal
                        endemic-epidemic modelling frameworks
                        'twinstim', 'twinSIR', and 'hhh4'

> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("surveillance-package", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("surveillance.options")
> ### * surveillance.options
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: surveillance.options
> ### Title: Options of the 'surveillance' Package
> ### Aliases: surveillance.options reset.surveillance.options
> ### Keywords: environment
> 
> ### ** Examples
> 
> surveillance.options()
$colors
     nowSymbol         piBars 
"springgreen4"       "orange" 

$stsTickFactors
  %d   %W   %V   %m   %Q   %Y   %G 
1.00 0.33 0.33 1.75 1.25 1.50 1.50 

$allExamples
[1] FALSE

$gpclib
[1] FALSE

> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("surveillance.options", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("toLatex.sts")
> ### * toLatex.sts
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: toLatex.sts
> ### Title: 'toLatex'-Method for '"sts"' Objects
> ### Aliases: toLatex.sts toLatex,sts-method
> ### Keywords: print
> 
> ### ** Examples
> 
> # Create a test object
> data("salmonella.agona")
> 
> # Create the corresponding sts object from the old disProg object
> salm <- disProg2sts(salmonella.agona)
> 
> control <- list(range=(260:312),
+                 noPeriods=1,populationOffset=FALSE,
+                 fitFun="algo.farrington.fitGLM.flexible",
+                 b=4,w=3,weightsThreshold=1,
+                 pastWeeksNotIncluded=3,
+                 pThresholdTrend=0.05,trend=TRUE,
+                 thresholdMethod="delta",alpha=0.1)
> salm <- farringtonFlexible(salm,control=control)
> 
> toLatex(salm, sanitize.text.function=identity, comment=FALSE)
\begin{table}[ht]
\centering
\begin{tabular}{rrrlr}
  \hline
 & year & week & observed1 & UB \\ 
  \hline
1 & 1994 & 52 & 3 & 3 \\ 
  2 & 1995 & 1 & \textbf{\textcolor{red}{4}} & 3 \\ 
  3 & 1995 & 2 & \textbf{\textcolor{red}{7}} & 3 \\ 
  4 & 1995 & 3 & \textbf{\textcolor{red}{6}} & 3 \\ 
  5 & 1995 & 4 & \textbf{\textcolor{red}{10}} & 3 \\ 
  6 & 1995 & 5 & 2 & 3 \\ 
  7 & 1995 & 6 & \textbf{\textcolor{red}{4}} & 3 \\ 
  8 & 1995 & 7 & 0 & 3 \\ 
  9 & 1995 & 8 & 3 & 4 \\ 
  10 & 1995 & 9 & 0 & 4 \\ 
  11 & 1995 & 10 & 1 &  \\ 
  12 & 1995 & 11 & 3 & 4 \\ 
  13 & 1995 & 12 & 0 &  \\ 
  14 & 1995 & 13 & 1 & 4 \\ 
  15 & 1995 & 14 & 1 & 3 \\ 
  16 & 1995 & 15 & 0 &  \\ 
  17 & 1995 & 16 & 1 &  \\ 
  18 & 1995 & 17 & 0 &  \\ 
  19 & 1995 & 18 & 1 &  \\ 
  20 & 1995 & 19 & 0 &  \\ 
  21 & 1995 & 20 & 1 &  \\ 
  22 & 1995 & 21 & 2 &  \\ 
  23 & 1995 & 22 & 2 & 3 \\ 
  24 & 1995 & 23 & \textbf{\textcolor{red}{4}} & 3 \\ 
  25 & 1995 & 24 & \textbf{\textcolor{red}{7}} & 3 \\ 
  26 & 1995 & 25 & \textbf{\textcolor{red}{6}} & 3 \\ 
  27 & 1995 & 26 & 1 & 3 \\ 
  28 & 1995 & 27 & \textbf{\textcolor{red}{4}} & 3 \\ 
  29 & 1995 & 28 & \textbf{\textcolor{red}{6}} & 3 \\ 
  30 & 1995 & 29 & \textbf{\textcolor{red}{4}} & 2 \\ 
  31 & 1995 & 30 & 2 & 3 \\ 
  32 & 1995 & 31 & \textbf{\textcolor{red}{4}} & 3 \\ 
  33 & 1995 & 32 & \textbf{\textcolor{red}{5}} & 4 \\ 
  34 & 1995 & 33 & 5 & 6 \\ 
  35 & 1995 & 34 & \textbf{\textcolor{red}{9}} & 7 \\ 
  36 & 1995 & 35 & \textbf{\textcolor{red}{8}} & 8 \\ 
  37 & 1995 & 36 & 6 & 8 \\ 
  38 & 1995 & 37 & 3 & 7 \\ 
  39 & 1995 & 38 & 2 & 7 \\ 
  40 & 1995 & 39 & 3 & 7 \\ 
  41 & 1995 & 40 & 4 & 7 \\ 
  42 & 1995 & 41 & 3 & 5 \\ 
  43 & 1995 & 42 & 3 & 4 \\ 
  44 & 1995 & 43 & 4 & 4 \\ 
  45 & 1995 & 44 & \textbf{\textcolor{red}{4}} & 4 \\ 
  46 & 1995 & 45 & 2 & 3 \\ 
  47 & 1995 & 46 & 1 & 3 \\ 
  48 & 1995 & 47 & 2 & 5 \\ 
  49 & 1995 & 48 & 3 & 5 \\ 
  50 & 1995 & 49 & 2 & 5 \\ 
  51 & 1995 & 50 & 2 & 4 \\ 
  52 & 1995 & 51 & 0 & 7 \\ 
  53 & 1995 & 52 & 4 & 11 \\ 
   \hline
\end{tabular}
\caption{} 
\label{ }
\end{table}
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("toLatex.sts", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("twinSIR")
> ### * twinSIR
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: twinSIR
> ### Title: Fit an Additive-Multiplicative Intensity Model for SIR Data
> ### Aliases: twinSIR
> ### Keywords: models optimize
> 
> ### ** Examples
> 
> data("hagelloch")
> summary(hagelloch)

AN SIR EPIDEMIC
  Time range: 0 -- 92.5452383686788 
  Number of individuals: 188 
  1 initially infected individuals:
    "184"
  0 never infected individuals
  Size of the epidemic: 187 

$ counters ('data.frame', 376 x 6 ): evolution of the epidemic:
         time type  id nSusceptible nInfectious nRemoved
1    0.000000                   187           1        0
2    1.136356    I 173          186           2        0
3    7.197762    R 173          186           1        1
       [....]                                           
375 85.688298    I 141            0           1      187
376 92.545238    R 141            0           0      188

> 
> # simple model with an overall constant baseline hazard rate
> fit1 <- twinSIR(~ household + cox(AGE), data = hagelloch)
Initialized 1 log-baseline interval:  0.00000 92.54524
Initial parameter vector:  1 0 0
iter   10 value 746.690987
final  value 742.374283 
converged
> fit1

Call:
twinSIR(formula = ~household + cox(AGE), data = hagelloch)

Coefficients:
       household  cox(logbaseline)          cox(AGE)  
         0.05377          -4.41141           0.04684  

Log-likelihood: -742.4

> summary(fit1)   # see also help("summary.twinSIR")

Call:
twinSIR(formula = ~household + cox(AGE), data = hagelloch)

Coefficients:
                  Estimate Std. Error z value Pr(>|z|)    
household         0.053769   0.006223   8.641   <2e-16 ***
cox(logbaseline) -4.411414   0.250644 -17.600   <2e-16 ***
cox(AGE)          0.046838   0.029218   1.603    0.109    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Total number of infections:  187 

One-sided AIC: 1489.7
Log-likelihood: -742.4
Number of log-likelihood evaluations: 23 

> plot(fit1)      # see also help("plot.twinSIR")
> checkResidualProcess(fit1)   # could be better
> 
> # fit a piecewise constant baseline hazard rate with 3 intervals using 
> # _un_penalized ML and estimated coefs from fit1 as starting values 
> fit2 <- twinSIR(~ household, data = hagelloch, nIntervals = 3,
+                 optim.args = list(par = coef(fit1)[c(1,2,2,2)]))
Initialized 3 log-baseline intervals:  0.00000 26.95444 33.51139 92.54524
Initial parameter vector:  0.05376881 -4.41141360 -4.41141360 -4.41141360
iter   10 value 674.375995
iter   20 value 668.543216
final  value 668.543216 
converged
> summary(fit2)

Call:
twinSIR(formula = ~household, data = hagelloch, nIntervals = 3, 
    optim.args = list(par = coef(fit1)[c(1, 2, 2, 2)]))

Coefficients:
                    Estimate Std. Error z value Pr(>|z|)    
household           0.026564   0.005578   4.762 1.92e-06 ***
cox(logbaseline.1) -4.731305   0.165790 -28.538  < 2e-16 ***
cox(logbaseline.2) -2.648247   0.173018 -15.306  < 2e-16 ***
cox(logbaseline.3) -1.563954   0.147733 -10.586  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Baseline intervals:
                  logbaseline.1       logbaseline.2        logbaseline.3      
Time interval     (0.00000;26.95444]  (26.95444;33.51139]  (33.51139;92.54524]
Number of events  63                  62                   62                 

One-sided AIC: 1344.1
Log-likelihood: -668.5
Number of log-likelihood evaluations: 30 

> 
> # fit a piecewise constant baseline hazard rate with 7 intervals
> # using _penalized_ ML
> fit3 <- twinSIR(~ household, data = hagelloch, nIntervals = 7,
+                 lambda.smooth = 0.1, penalty = 1)
Initialized 7 log-baseline intervals:  0.00000 21.71242 24.76697 30.20108 31.87247 33.77988 35.98953 92.54524
Note: non-equidistant knots. Using penalization matrix correcting for distance between knots.

Initial parameter vector:  1 0 0 0 0 0 0 0
iter   10 value 637.321579
iter   20 value 631.642234
final  value 631.639327 
converged
> summary(fit3)

Call:
twinSIR(formula = ~household, data = hagelloch, nIntervals = 7, 
    lambda.smooth = 0.1, penalty = 1)

Coefficients:
                    Estimate Std. Error z value Pr(>|z|)    
household           0.021791   0.005277   4.129 3.64e-05 ***
cox(logbaseline.1) -5.535069   0.265941 -20.813  < 2e-16 ***
cox(logbaseline.2) -2.938868   0.212663 -13.819  < 2e-16 ***
cox(logbaseline.3) -3.592069   0.278963 -12.877  < 2e-16 ***
cox(logbaseline.4) -1.950706   0.220394  -8.851  < 2e-16 ***
cox(logbaseline.5) -1.683555   0.208982  -8.056 7.88e-16 ***
cox(logbaseline.6) -1.313648   0.207552  -6.329 2.46e-10 ***
cox(logbaseline.7) -1.942733   0.233674  -8.314  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Baseline intervals:
                  logbaseline.1       logbaseline.2        logbaseline.3      
Time interval     (0.00000;21.71242]  (21.71242;24.76697]  (24.76697;30.20108]
Number of events  27                  27                   27                 
                  logbaseline.4        logbaseline.5        logbaseline.6      
Time interval     (30.20108;31.87247]  (31.87247;33.77988]  (33.77988;35.98953]
Number of events  26                   27                   27                 
                  logbaseline.7      
Time interval     (35.98953;92.54524]
Number of events  26                 

One-sided AIC: 1278.3
Log-likelihood: -631.6
Number of log-likelihood evaluations: 30 

> checkResidualProcess(fit3)
> 
> # plot the estimated log-baseline levels
> plot(x=fit2$intervals, y=coef(fit2)[c(2,2:4)], type="S", ylim=c(-6, -1))
> lines(x=fit3$intervals, y=coef(fit3)[c(2,2:8)], type="S", col=2)
> legend("right", legend=c("unpenalized 3", "penalized 7"), lty=1, col=1:2, bty="n")
> 
> 
> ## special use case: fit the model to a subset of the events only,
> ## while preserving epidemic contributions from the remainder
> ## (maybe some buffer area nodes)
> fit_subset <- twinSIR(~ household, data = hagelloch, subset = CL=="preschool")
Initialized 1 log-baseline interval:  0.00000 92.54524
Initial parameter vector:  1 0
iter   10 value 361.527866
final  value 361.485659 
converged
> summary(fit_subset)

Call:
twinSIR(formula = ~household, data = hagelloch, subset = CL == 
    "preschool")

Coefficients:
                  Estimate Std. Error z value Pr(>|z|)    
household         0.048221   0.007387   6.528 6.69e-11 ***
cox(logbaseline) -4.359000   0.184937 -23.570  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Total number of infections:  90 

One-sided AIC: 725.97
Log-likelihood: -361.5
Number of log-likelihood evaluations: 17 

> 
> ## Don't show: 
>     ## the eventTimes attribute was wrong in surveillance <= 1.15.0
>     stopifnot(
+         length(residuals(fit_subset)) == sum(fit_subset$model$survs$event)
+     )
> ## End(Don't show)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("twinSIR", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("twinSIR_intensityplot")
> ### * twinSIR_intensityplot
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: twinSIR_intensityplot
> ### Title: Plotting Paths of Infection Intensities for 'twinSIR' Models
> ### Aliases: plot.twinSIR intensityplot.twinSIR intensityplot.simEpidata
> ### Keywords: hplot aplot dplot methods
> 
> ### ** Examples
> 
> data("hagelloch")
> plot(hagelloch)
> 
> # a simplistic twinSIR model
> fit <- twinSIR(~ household, data = hagelloch)
Initialized 1 log-baseline interval:  0.00000 92.54524
Initial parameter vector:  1 0
iter   10 value 743.984462
final  value 743.982888 
converged
> 
> # overall total intensity
> plot(fit, which = "total")
> 
> # overall epidemic proportion
> epi <- plot(fit, which = "epidemic", ylim = c(0, 1))
> head(epi)
          stop epidemic proportion
[1,]  1.136356           0.1058473
[2,]  7.197762           0.1327105
[3,]  7.470164           0.1063558
[4,]  7.627762           0.1702113
[5,]  8.253432           0.2049618
[6,] 10.983840           0.2166022
> # add overall endemic proportion = 1 - epidemic proportion
> ende <- plot(fit, which = "endemic", add = TRUE, col = 2)
> legend("topleft", legend = "endemic proportion", lty = 1, col = 2, bty = "n")
> 
> # individual intensities
> tmp <- plot(fit, which = "total", aggregate = FALSE,
+     col = rgb(0, 0, 0, alpha = 0.1),
+     main = expression("Individual infection intensities " *
+         lambda[i](t) == Y[i](t) %.% (e[i](t) + h[i](t))))
> # return value: matrix of individual intensity paths
> str(tmp)
 num [1:375, 1:189] 1.14 7.2 7.47 7.63 8.25 ...
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr [1:189] "stop" "1" "2" "3" ...
> 
> # plot intensity path only for individuals 3 and 99
> matplot(x = tmp[,1], y = tmp[,1+c(3,99)], type = "S",
+         ylab = "Force of infection", xlab = "time",
+         main = expression("Paths of the infection intensities " *
+                           lambda[3](t) * " and " * lambda[99](t)))
> legend("topright", legend = paste("Individual", c(3,99)),
+        col = 1:2, lty = 1:2)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("twinSIR_intensityplot", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("twinSIR_methods")
> ### * twinSIR_methods
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: twinSIR_methods
> ### Title: Print, Summary and Extraction Methods for '"twinSIR"' Objects
> ### Aliases: print.twinSIR summary.twinSIR AIC.twinSIR extractAIC.twinSIR
> ###   vcov.twinSIR logLik.twinSIR print.summary.twinSIR
> ### Keywords: methods print htest
> 
> ### ** Examples
> 
> data("hagelloch")
> 
> # a simplistic twinSIR model
> fit <- twinSIR(~ household + cox(AGE), data = hagelloch)
Initialized 1 log-baseline interval:  0.00000 92.54524
Initial parameter vector:  1 0 0
iter   10 value 746.690987
final  value 742.374283 
converged
> 
> coef(fit)
       household cox(logbaseline)         cox(AGE) 
      0.05376881      -4.41141360       0.04683819 
> vcov(fit)
                     household cox(logbaseline)      cox(AGE)
household         3.872037e-05    -0.0001702059  4.018241e-06
cox(logbaseline) -1.702059e-04     0.0628226611 -6.508888e-03
cox(AGE)          4.018241e-06    -0.0065088877  8.536951e-04
> logLik(fit)
'log Lik.' -742.3743 (df=3)
> 
> summary(fit, correlation = TRUE, symbolic.cor = TRUE)

Call:
twinSIR(formula = ~household + cox(AGE), data = hagelloch)

Coefficients:
                  Estimate Std. Error z value Pr(>|z|)    
household         0.053769   0.006223   8.641   <2e-16 ***
cox(logbaseline) -4.411414   0.250644 -17.600   <2e-16 ***
cox(AGE)          0.046838   0.029218   1.603    0.109    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Total number of infections:  187 

One-sided AIC: 1489.7
Log-likelihood: -742.4
Number of log-likelihood evaluations: 23 

Correlation of Coefficients:
                      
household        1    
cox(logbaseline)   1  
cox(AGE)           + 1
---
Corr. codes:  0 ‘ ’ 0.3 ‘.’ 0.6 ‘,’ 0.8 ‘+’ 0.9 ‘*’ 0.95 ‘B’ 1

> 
> # AIC or OSAIC
> AIC(fit)
[1] 1489.749
attr(,"exact")
[1] TRUE
attr(,"type")
[1] "One-sided AIC"
> AIC(fit, one.sided = FALSE)
[1] 1490.749
attr(,"type")
[1] "Standard AIC"
attr(,"exact")
[1] TRUE
> extractAIC(fit)
     edf      AIC 
   3.000 1489.749 
attr(,"type")
[1] "One-sided AIC"
attr(,"exact")
[1] TRUE
> extractAIC(fit, one.sided = FALSE)
     edf      AIC 
   3.000 1490.749 
attr(,"type")
[1] "Standard AIC"
attr(,"exact")
[1] TRUE
> 
> # comparing models via AIC
> fit2 <- update(fit, nIntervals = 2)
Initialized 2 log-baseline intervals:  0.00000 31.21372 92.54524
Initial parameter vector:  1 0 0 0
iter   10 value 714.623228
iter   20 value 661.345112
final  value 661.345112 
converged
> AIC(fit, fit2)   # the 2nd column should be named "OSAIC" here
     df      AIC
fit   3 1489.749
fit2  4 1329.357
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("twinSIR_methods", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("twinSIR_profile")
> ### * twinSIR_profile
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: twinSIR_profile
> ### Title: Profile Likelihood Computation and Confidence Intervals
> ### Aliases: profile.twinSIR plot.profile.twinSIR
> ### Keywords: htest methods optimize dplot
> 
> ### ** Examples
> 
> data("hagelloch")
> fit <- twinSIR(~ household, data = hagelloch)
Initialized 1 log-baseline interval:  0.00000 92.54524
Initial parameter vector:  1 0
iter   10 value 743.984462
final  value 743.982888 
converged
> gridsize <- if (interactive()) 35 else 5  # for fast tests
> prof <- profile(fit, list(c(1, NA, NA, gridsize)))
Evaluating the profile log-likelihood on a grid ...
i=  1 / 1 
	j=  1 / 5 
	j=  2 / 5 
	j=  3 / 5 
	j=  4 / 5 
	j=  5 / 5 
Computing profile likelihood-based confidence intervals ...
1 / 1 
> prof$ci.hl
          idx     hl.low      hl.up   wald.low    wald.up        mle
household   1 0.04214442 0.06657017 0.04143094 0.06585112 0.05364103
> plot(prof)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("twinSIR_profile", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("twinSIR_simulation")
> ### * twinSIR_simulation
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: twinSIR_simulation
> ### Title: Simulation of Epidemic Data
> ### Aliases: simEpidata simulate.twinSIR
> ### Keywords: datagen models
> 
> ### ** Examples
> 
> ## Generate a data frame containing a hypothetic population with 100 individuals
> set.seed(1234)
> n <- 100
> pos <- matrix(rnorm(n*2), ncol=2, dimnames=list(NULL, c("x", "y")))
> pop <- data.frame(id=1:n, x=pos[,1], y=pos[,2], 
+                   gender=sample(0:1, n, replace=TRUE),
+                   I0col=c(rep(1,3),rep(0,n-3)), # 3 initially infectious
+                   start=rep(0,n), stop=rep(Inf,n))
> 
> ## Simulate an SIR epidemic in this population
> set.seed(123)
> infPeriods <- setNames(c(1:3/10, rexp(n-3, rate=1)), 1:n)
> epi <- simEpidata(
+     cbind(start,stop) ~ cox(gender), data = pop,
+     id.col = "id", I0.col = "I0col", coords.cols = c("x","y"),
+     beta = c(-2), h0 = -1, alpha = c(B1=0.1), f = list(B1=function(u) u<=1),
+     infPeriod = function(ids) infPeriods[ids],
+     ##remPeriod = function(ids) rexp(length(ids), rate=0.1), end = 30   # -> SIRS
+ )
> 
> ## extract event times by id
> head(summary(epi)$byID)
  id    time.I   time.R
1  1        NA 0.100000
2  2        NA 0.200000
3  3        NA 0.300000
4  4 2.6032827 3.446740
5  5 1.0517081 1.628318
6  6 0.2709287 1.599984
> 
> ## Plot the numbers of susceptible, infectious and removed individuals
> plot(epi)
> 
> 
> ## load the 1861 Hagelloch measles epidemic
> data("hagelloch")
> summary(hagelloch)

AN SIR EPIDEMIC
  Time range: 0 -- 92.5452383686788 
  Number of individuals: 188 
  1 initially infected individuals:
    "184"
  0 never infected individuals
  Size of the epidemic: 187 

$ counters ('data.frame', 376 x 6 ): evolution of the epidemic:
         time type  id nSusceptible nInfectious nRemoved
1    0.000000                   187           1        0
2    1.136356    I 173          186           2        0
3    7.197762    R 173          186           1        1
       [....]                                           
375 85.688298    I 141            0           1      187
376 92.545238    R 141            0           0      188

> plot(hagelloch)
> 
> ## fit a simplistic twinSIR model
> fit <- twinSIR(~ household, data = hagelloch)
Initialized 1 log-baseline interval:  0.00000 92.54524
Initial parameter vector:  1 0
iter   10 value 743.984462
final  value 743.982888 
converged
> 
> ## simulate a new epidemic from the above model
> ## with simulation period = observation period, re-using observed infPeriods
> sim1 <- simulate(fit, data = hagelloch)
> plot(sim1)
> 
> ## check if we find similar parameters in the simulated epidemic
> fitsim1 <- update(fit, data = sim1)
Initialized 1 log-baseline interval:  0.00000 92.54524
Initial parameter vector:  1 0
iter   10 value 654.682147
final  value 654.682146 
converged
> cbind(base = coef(fit), new = coef(fitsim1))
                        base         new
household         0.05364103  0.05617818
cox(logbaseline) -4.07676005 -4.10337393
> 
> 
> if (surveillance.options("allExamples")) {
+ 
+ ## simulate only 10 days, using random infPeriods ~ Exp(0.1)
+ sim2 <- simulate(fit, data = hagelloch, seed = 2, end = 10,
+     infPeriod = function(ids) rexp(length(ids), rate = 0.1))
+ plot(sim2)
+ 
+ ## simulate from a different model with manually specified parameters
+ set.seed(321)
+ simepi <- simEpidata(~ cox(AGE), data = hagelloch,
+     beta = c(0.1), h0 = -4, alpha = c(household = 0.05),
+     f = list(household = function(u) u == 0),
+     infPeriod = function(ids) rexp(length(ids), rate=1/8))
+ plot(simepi)
+ intensityplot(simepi)
+ 
+ ## see if we correctly estimate the parameters
+ fitsimepi <- twinSIR(~ cox(AGE) + household, data = simepi)
+ cbind(true = c(0.05, -4, 0.1), est = coef(fitsimepi), confint(fitsimepi))
+ 
+ }
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("twinSIR_simulation", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("twinstim")
> ### * twinstim
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: twinstim
> ### Title: Fit a Two-Component Spatio-Temporal Point Process Model
> ### Aliases: twinstim
> ### Keywords: models optimize
> 
> ### ** Examples
> 
> # Load invasive meningococcal disease data
> data("imdepi")
> 
> 
> ### first, fit a simple endemic-only model
> 
> m_noepi <- twinstim(
+     endemic = addSeason2formula(~ offset(log(popdensity)) + I(start/365-3.5),
+                                 S=1, period=365, timevar="start"),
+     data = imdepi, subset = !is.na(agegrp)
+ )
marked point pattern of 2 types
no epidemic component in model

minimizing the negative log-likelihood using 'nlminb()' ...
initial parameters:
            h.(Intercept)      h.I(start/365 - 3.5) h.sin(2 * pi * start/365) 
                -19.85955                   0.00000                   0.00000 
h.cos(2 * pi * start/365) 
                  0.00000 
negative log-likelihood and parameters in each iteration:
  0:     9689.1757: -19.8595  0.00000  0.00000  0.00000
  1:     9588.9760: -20.5435 -0.0777874 0.352955 0.481287
  2:     9579.2608: -20.3905 -0.0456755 0.293517 0.370125
  3:     9579.0650: -20.3690 -0.0440090 0.275220 0.352285
  4:     9579.0639: -20.3683 -0.0443585 0.273348 0.350858

MLE:
            h.(Intercept)      h.I(start/365 - 3.5) h.sin(2 * pi * start/365) 
             -20.36832391               -0.04435847                0.27334815 
h.cos(2 * pi * start/365) 
               0.35085784 
loglik(MLE) = -9579.064 

Done.
> 
> ## look at the model summary
> summary(m_noepi)

Call:
twinstim(endemic = addSeason2formula(~offset(log(popdensity)) + 
    I(start/365 - 3.5), S = 1, period = 365, timevar = "start"), 
    data = imdepi, subset = !is.na(agegrp))

Coefficients of the endemic component:
                           Estimate Std. Error  z value Pr(>|z|)    
h.(Intercept)             -20.36832    0.04189 -486.243  < 2e-16 ***
h.I(start/365 - 3.5)       -0.04436    0.01999   -2.219   0.0265 *  
h.sin(2 * pi * start/365)   0.27335    0.05755    4.750 2.04e-06 ***
h.cos(2 * pi * start/365)   0.35086    0.05805    6.044 1.51e-09 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

No epidemic component.

AIC:  19166
Log-likelihood: -9579

> 
> ## there is no evidence for a type-dependent endemic intercept (LR test)
> m_noepi_type <- update(m_noepi, endemic = ~(1|type) + .)
marked point pattern of 2 types
no epidemic component in model

minimizing the negative log-likelihood using 'nlminb()' ...
initial parameters:
                  h.typeB                   h.typeC      h.I(start/365 - 3.5) 
             -19.85954556              -19.85954556               -0.04435847 
h.sin(2 * pi * start/365) h.cos(2 * pi * start/365) 
               0.27334815                0.35085784 
negative log-likelihood and parameters in each iteration:
  0:     9677.1578: -19.8595 -19.8595 -0.0443585 0.273348 0.350858
  1:     9585.8335: -20.4342 -20.6194 -0.0453809 0.276457 0.340398
  2:     9578.1538: -20.3225 -20.4423 -0.0442621 0.271767 0.353067
  3:     9578.0989: -20.3146 -20.4253 -0.0443089 0.273205 0.351079
  4:     9578.0988: -20.3146 -20.4250 -0.0443757 0.273225 0.350704

MLE:
                  h.typeB                   h.typeC      h.I(start/365 - 3.5) 
             -20.31460914              -20.42500221               -0.04437566 
h.sin(2 * pi * start/365) h.cos(2 * pi * start/365) 
               0.27322536                0.35070383 
loglik(MLE) = -9578.099 

Done.
> pchisq(2*c(logLik(m_noepi_type)-logLik(m_noepi)), df=1, lower.tail=FALSE)
[1] 0.1647445
> 
> 
> ### add an epidemic component with just the intercept, i.e.
> ### assuming uniform dispersal in time and space up to a distance of
> ### eps.s = 200 km and eps.t = 30 days (see summary(imdepi))
> 
> m0 <- update(m_noepi, epidemic=~1, model=TRUE)
marked point pattern of 2 types
updating list of potential sources ...
assuming constant spatial interaction 'siaf.constant()'
assuming constant temporal interaction 'tiaf.constant()'

minimizing the negative log-likelihood using 'nlminb()' ...
initial parameters:
            h.(Intercept)      h.I(start/365 - 3.5) h.sin(2 * pi * start/365) 
             -20.36832391               -0.04435847                0.27334815 
h.cos(2 * pi * start/365)             e.(Intercept) 
               0.35085784               -9.00000000 
negative log-likelihood and parameters in each iteration:
  0:     197026.38: -20.3683 -0.0443585 0.273348 0.350858 -9.00000
  1:     83871.553: -20.3704 -0.0435641 0.272903 0.350409 -9.91095
  2:     38577.573: -20.3754 -0.0416650 0.271815 0.349316 -10.8223
  3:     20562.718: -20.3873 -0.0373506 0.269201 0.346726 -11.7353
  4:     13488.939: -20.4151 -0.0285950 0.263105 0.340856 -12.6556
  5:     10767.143: -20.4761 -0.0153056 0.249358 0.328506 -13.6144
  6:     9858.3517: -20.5829 -0.0121206 0.223245 0.309752 -14.5692
  7:     9611.5104: -20.6509 -0.0338945 0.195994 0.312465 -15.5374
  8:     9572.7815: -20.5171 -0.0411375 0.227098 0.352670 -16.4039
  9:     9570.0836: -20.4762 -0.0408643 0.243331 0.350150 -16.8656
 10:     9570.0589: -20.4810 -0.0409076 0.241554 0.350657 -16.8972
 11:     9570.0589: -20.4810 -0.0409040 0.241599 0.350495 -16.8972

MLE:
            h.(Intercept)      h.I(start/365 - 3.5) h.sin(2 * pi * start/365) 
             -20.48097879               -0.04090402                0.24159892 
h.cos(2 * pi * start/365)             e.(Intercept) 
               0.35049470              -16.89715586 
loglik(MLE) = -9570.059 

Done.
> 
> ## summarize the model fit
> summary(m0, correlation = TRUE, symbolic.cor = TRUE)

Call:
twinstim(endemic = ~offset(log(popdensity)) + I(start/365 - 3.5) + 
    sin(2 * pi * start/365) + cos(2 * pi * start/365), epidemic = ~1, 
    data = imdepi, subset = !is.na(agegrp), start = c(`h.(Intercept)` = -20.3683239124774, 
    `h.I(start/365 - 3.5)` = -0.0443584681503684, `h.sin(2 * pi * start/365)` = 0.273348150862402, 
    `h.cos(2 * pi * start/365)` = 0.350857838070866), optim.args = list(), 
    model = TRUE)

Coefficients of the endemic component:
                           Estimate Std. Error  z value Pr(>|z|)    
h.(Intercept)             -20.48098    0.05264 -389.044  < 2e-16 ***
h.I(start/365 - 3.5)       -0.04090    0.02195   -1.863 0.062429 .  
h.sin(2 * pi * start/365)   0.24160    0.06414    3.767 0.000165 ***
h.cos(2 * pi * start/365)   0.35049    0.06446    5.437 5.42e-08 ***

Coefficients of the epidemic component:
              Estimate Std. Error z value Pr(>|z|)    
e.(Intercept)  -16.897      0.265  -63.77   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

AIC:  19150
Log-likelihood: -9570

Correlation of Coefficients:
                                   
h.(Intercept)             1        
h.I(start/365 - 3.5)        1      
h.sin(2 * pi * start/365)     1    
h.cos(2 * pi * start/365)       1  
e.(Intercept)             .       1
---
Corr. codes:  0 ‘ ’ 0.3 ‘.’ 0.6 ‘,’ 0.8 ‘+’ 0.9 ‘*’ 0.95 ‘B’ 1

> 
> ## the default confint-method can be used for Wald-CI's
> confint(m0, level=0.95)
                                 2.5 %        97.5 %
h.(Intercept)             -20.58415983 -20.377797759
h.I(start/365 - 3.5)       -0.08393158   0.002123546
h.sin(2 * pi * start/365)   0.11589270   0.367305141
h.cos(2 * pi * start/365)   0.22414638   0.476843010
e.(Intercept)             -17.41647557 -16.377836153
> 
> ## same "untrimmed" R0 for every event (simple epidemic intercept model)
> summary(R0(m0, trimmed=FALSE))
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  0.173   0.173   0.173   0.173   0.173   0.173 
> 
> ## plot the path of the fitted total intensity
> plot(m0, "total intensity", tgrid=500)
> 
> if (surveillance.options("allExamples")) {
+ ## extract "residual process" integrating over space (takes some seconds)
+ res <- residuals(m0)
+ # if the model describes the true CIF well _in the temporal dimension_,
+ # then this residual process should behave like a stationary Poisson
+ # process with intensity 1
+ plot(res, type="l"); abline(h=c(0, length(res)), lty=2)
+ # easier, with CI and serial correlation:
+ checkResidualProcess(m0)
+ }
> 
> ## Not run: 
> ##D   ## NB: in contrast to nlminb(), optim's BFGS would miss the
> ##D   ##     likelihood maximum wrt the epidemic intercept
> ##D   m0_BFGS <- update(m_noepi, epidemic=~1, optim.args = list(method="BFGS"))
> ##D   format(cbind(nlminb=coef(m0), BFGS=coef(m0_BFGS)), digits=3, scientific=FALSE)
> ##D   m0_BFGS$fisherinfo   # singular Fisher information matrix here
> ##D   m0$fisherinfo
> ##D   logLik(m0_BFGS)
> ##D   logLik(m0)
> ##D   ## nlminb is more powerful since we make use of the analytical fisherinfo
> ##D   ## as estimated by the model during optimization, which optim cannot
> ## End(Not run)
> 
> 
> ### an epidemic-only model?
> ## for a purely epidemic model, all events must have potential source events
> ## (otherwise the intensity at the observed event would be 0)
> 
> ## let's focus on the C-type for this example
> imdepiC <- subset(imdepi, type == "C")
Note: dropped type(s) "B"
> table(summary(imdepiC)$nSources)

  0   1   2   3   4   5 
106  86  65  31   8   4 
> ## 106 events have no prior, close events (in terms of eps.s and eps.t)
> try(twinstim(epidemic = ~1, data = imdepiC))  # detects this problem
no endemic component in model
Error in twinstim(epidemic = ~1, data = imdepiC) : 
  found 106 events without .sources (impossible in a purely epidemic model)
> ## let's assume spatially unbounded interaction
> imdepiC_infeps <- update(imdepiC, eps.s = Inf)
> (s <- summary(imdepiC_infeps))
Observation period: 0 - 2557 
Observation window (bounding box): [4031.295, 4672.253] x [2684.102, 3549.931] 
Spatio-temporal grid (not shown): 84 time blocks x 413 tiles 
Overall number of events: 300 (single type)

Summary of event marks and number of potential sources:
      time                tile     type        eps.t        eps.s    
 Min.   :   0.7124   11000  : 12   C:300   Min.   :30   Min.   :Inf  
 1st Qu.: 479.8911   02000  :  7           1st Qu.:30   1st Qu.:Inf  
 Median :1186.8139   05162  :  6           Median :30   Median :Inf  
 Mean   :1172.9763   05913  :  6           Mean   :30   Mean   :Inf  
 3rd Qu.:1799.0683   05166  :  5           3rd Qu.:30   3rd Qu.:Inf  
 Max.   :2542.7800   09162  :  5           Max.   :30   Max.   :Inf  
                     (Other):259                                     
     sex           agegrp          x              y          |.sources|    
 female:139   [0,3)   : 88   Min.   :4052   Min.   :2724   Min.   : 0.000  
 male  :159   [3,19)  :137   1st Qu.:4151   1st Qu.:2907   1st Qu.: 2.000  
 NA's  :  2   [19,Inf): 75   Median :4283   Median :3110   Median : 3.000  
                             Mean   :4300   Mean   :3073   Mean   : 3.767  
                             3rd Qu.:4421   3rd Qu.:3224   3rd Qu.: 5.000  
                             Max.   :4638   Max.   :3470   Max.   :11.000  
                                                                           
> table(s$nSources)

 0  1  2  3  4  5  6  7  8  9 10 11 
11 31 61 60 36 39 25 13  9  7  6  2 
> ## for 11 events, there is no prior event within eps.t = 30 days
> ## (which is certainly true for the first event)
> plot(s$counter, main = "Number of infectious individuals over time (eps.t = 30)")
> rug(imdepiC_infeps$events$time)
> rug(imdepiC_infeps$events$time[s$nSources == 0], col = 2, lwd = 3)
> ## An endemic component would catch such events (from unobserved sources),
> ## otherwise a longer infectious period would need to be assumed and
> ## for the first event to happen, a prehistory is required (e.g., t0 = 31).
> ## As an example, we fit the data only until T = 638 (all events have ancestors)
> m_epi <- twinstim(epidemic = ~1, data = imdepiC_infeps, t0 = 31, T = 638)
updating list of potential sources ...
no endemic component in model
assuming constant spatial interaction 'siaf.constant()'
assuming constant temporal interaction 'tiaf.constant()'

minimizing the negative log-likelihood using 'nlminb()' ...
initial parameters:
e.(Intercept) 
           -9 
negative log-likelihood and parameters in each iteration:
  0:     120299.45: -9.00000
  1:     48958.012: -9.90909
  2:     20263.548: -10.8182
  3:     8751.1383: -11.7273
  4:     4161.2114: -12.6364
  5:     2360.2858: -13.5455
  6:     1683.0220: -14.4545
  7:     1458.4705: -15.3636
  8:     1416.3125: -16.2727
  9:     1416.1036: -16.2057
 10:     1416.1034: -16.2034

MLE:
e.(Intercept) 
    -16.20339 
loglik(MLE) = -1416.103 

Done.
> summary(m_epi)

Call:
twinstim(epidemic = ~1, data = imdepiC_infeps, t0 = 31, T = 638)

No coefficients in the endemic component.

Coefficients of the epidemic component:
              Estimate Std. Error z value Pr(>|z|)    
e.(Intercept)  -16.203      0.106  -152.9   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

AIC:  2834.2
Log-likelihood: -1416

> 
> 
> if (surveillance.options("allExamples")) withAutoprint({
+ 
+ ### full model with interaction functions (time-consuming)
+ ## estimate an exponential temporal decay of infectivity
+ m1_tiaf <- update(m0, tiaf=tiaf.exponential())
+ plot(m1_tiaf, "tiaf", scaled=FALSE)
+ 
+ ## estimate a step function for spatial interaction
+ summary(sourceDists <- getSourceDists(imdepi, "space"))
+ (knots <- quantile(sourceDists, c(5,10,20,40)/100))
+ m1_fstep <- update(m0, siaf=knots)
+ plot(m1_fstep, "siaf", scaled=FALSE)
+ rug(sourceDists, ticksize=0.02)
+ 
+ ## estimate a continuously decreasing spatial interaction function,
+ ## here we use the kernel of an isotropic bivariate Gaussian
+ m1 <- update(m0, siaf = siaf.gaussian())
+ AIC(m_noepi, m0, m1_fstep, m1)
+ summary(m1)  # e.siaf.1 is log(sigma), no test for H0: log(sigma) = 0
+ exp(confint(m1, "e.siaf.1"))  # a confidence interval for sigma
+ plot(m1, "siaf", scaled=FALSE)
+ ## alternative: siaf.powerlaw() with eps.s=Inf and untie()d data,
+ ##              see vignette("twinstim")
+ 
+ ## add epidemic covariates
+ m2 <- update(m1, epidemic = ~ 1 + type + agegrp)
+ AIC(m1, m2)   # further improvement
+ summary(m2)
+   
+ ## look at estimated R0 values by event type
+ tapply(R0(m2), imdepi$events@data[names(R0(m2)), "type"], summary)
+ 
+ })
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("twinstim", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("twinstim_epitest")
> ### * twinstim_epitest
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: twinstim_epitest
> ### Title: Permutation Test for Space-Time Interaction in '"twinstim"'
> ### Aliases: epitest coef.epitest plot.epitest
> ### Keywords: htest
> 
> ### ** Examples
> 
> data("imdepi", "imdepifit")
> 
> ## test for space-time interaction of the B-cases
> ## assuming spatial interaction to be constant within 50 km
> imdepiB50 <- update(subset(imdepi, type == "B"), eps.s = 50)
Note: dropped type(s) "C"
> imdfitB50 <- update(imdepifit, data = imdepiB50, subset = NULL,
+                     epidemic = ~1, epilink = "identity", siaf = NULL,
+                     start = c("e.(Intercept)" = 0))
assuming constant spatial interaction 'siaf.constant()'
assuming constant temporal interaction 'tiaf.constant()'

minimizing the negative log-likelihood using 'nlminb()' ...
initial parameters:
            h.(Intercept)      h.I(start/365 - 3.5) h.sin(2 * pi * start/365) 
             -20.52869499               -0.04574093                0.21728211 
h.cos(2 * pi * start/365)             e.(Intercept) 
               0.31810266                0.00000000 
negative log-likelihood and parameters in each iteration:
  0:     5003.2689: -20.5287 -0.0457409 0.217282 0.318103  0.00000
  1:     4976.8102: -20.4550 -0.0301407 0.180918 0.409589 1.32796e-07
  2:     4954.6046: -20.5107 -0.0215816 0.170495 0.427496 4.30414e-07
  3:     4943.3681: -20.5415 -0.0189837 0.164078 0.413779 8.00735e-07
  4:     4941.0764: -20.5504 -0.0188616 0.159460 0.407828 1.05463e-06
  5:     4940.9811: -20.5516 -0.0189533 0.158399 0.406644 1.11980e-06
  6:     4940.9809: -20.5516 -0.0189726 0.158301 0.406519 1.12284e-06
  7:     4940.9809: -20.5516 -0.0189745 0.158294 0.406508 1.12284e-06

MLE:
            h.(Intercept)      h.I(start/365 - 3.5) h.sin(2 * pi * start/365) 
            -2.055161e+01             -1.897446e-02              1.582939e-01 
h.cos(2 * pi * start/365)             e.(Intercept) 
             4.065077e-01              1.122844e-06 
loglik(MLE) = -4940.981 

Done.
> 
> ## simple likelihood ratio test
> epitest(imdfitB50, imdepiB50, method = "LRT")

	Likelihood Ratio Test for Space-Time Interaction

data:  imdepiB50
twinstim:  imdfitB50
D = 104.94, df = 1, p-value < 2.2e-16

> 
> ## permutation test
> et <- epitest(imdfitB50, imdepiB50,
+               B = 5,        # CAVE: limited here for speed
+               verbose = 2,  # (tracing does not work on Windows
+               .seed = 1, .parallel = 1)       # if parallelized)
Endemic/Epidemic log-likelihoods, LRT statistic, and simple R0:
l0 = -4993 | l1 = -4941 | D = 104.9 | simpleR0 = 0.26

Running B = 5 permutations of time ...
l0 = -4993 | l1 = -4955 | D = 76.2 | simpleR0 = 0.22
l0 = -4993 | l1 = -4956 | D = 75.2 | simpleR0 = 0.22
l0 = -4993 | l1 = -4956 | D = 74.0 | simpleR0 = 0.23
l0 = -4993 | l1 = -4962 | D = 62.2 | simpleR0 = 0.20
l0 = -4993 | l1 = -4958 | D = 71.6 | simpleR0 = 0.21
> et

	Monte Carlo Permutation Test for Space-Time Interaction

data:  imdepiB50
twinstim:  imdfitB50
simpleR0 = 0.26456, B = 5, p-value = 0.1667

> plot(et)
> 
> ## summary of parameter estimates under permutation
> summary(coef(et, which = "m1"))
 h.(Intercept)    h.I(start/365 - 3.5) h.sin(2 * pi * start/365)
 Min.   :-20.55   Min.   :-0.048191    Min.   :0.1953           
 1st Qu.:-20.53   1st Qu.:-0.029535    1st Qu.:0.2161           
 Median :-20.52   Median :-0.028398    Median :0.2399           
 Mean   :-20.52   Mean   :-0.027233    Mean   :0.2367           
 3rd Qu.:-20.50   3rd Qu.:-0.022584    3rd Qu.:0.2618           
 Max.   :-20.49   Max.   :-0.007459    Max.   :0.2701           
 h.cos(2 * pi * start/365) e.(Intercept)      
 Min.   :0.4108            Min.   :8.552e-07  
 1st Qu.:0.4166            1st Qu.:8.886e-07  
 Median :0.4216            Median :9.353e-07  
 Mean   :0.4398            Mean   :9.198e-07  
 3rd Qu.:0.4594            3rd Qu.:9.512e-07  
 Max.   :0.4905            Max.   :9.685e-07  
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("twinstim_epitest", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("twinstim_iaf")
> ### * twinstim_iaf
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: twinstim_iaf
> ### Title: Temporal and Spatial Interaction Functions for 'twinstim'
> ### Aliases: siaf.constant siaf.step siaf.gaussian siaf.exponential
> ###   siaf.powerlaw siaf.powerlaw1 siaf.powerlawL siaf.student
> ###   tiaf.constant tiaf.step tiaf.exponential
> ### Keywords: models utilities
> 
> ### ** Examples
> 
> # constant temporal dispersal
> tiaf.constant()
$g
function (t, pars, types) 
rep.int(1, length(t))

$G
function (t, pars, types) 
t

$npars
[1] 0

attr(,"constant")
[1] TRUE
> # step function kernel
> tiaf.step(c(3,7), maxRange=14, nTypes=2)
$g
function (t, logvals, types) 
heights(logvals)[(types - 1) * nallknots + .bincode(t, allknotsInf, 
    right = FALSE)]
<bytecode: 0x5ede03079578>
<environment: 0x5eddfd8484a8>

$G
function (t, logvals, types) 
{
    mapply(function(t, type) {
        knots2t <- c(0, pmin.int(knots, t), min(t, maxRange))
        sum(typeheights(logvals, type) * diff.default(knots2t))
    }, t, types, SIMPLIFY = TRUE, USE.NAMES = FALSE)
}
<environment: 0x5eddfd8484a8>

$deriv
function (t, logvals, types) 
{
    whichvals <- .bincode(t, knotsmax, right = FALSE)
    fixedheight <- is.na(whichvals)
    whichvals <- whichvals + (types - 1) * nknots
    whichvals[fixedheight] <- 0
    repL <- rep.int(L <- length(t), npars)
    Y <- rep.int(seq_len(npars), repL)
    Z <- rep.int(exp(logvals), repL)
    res <- (Y == whichvals) * Z
    dim(res) <- c(L, npars)
    res
}
<bytecode: 0x5ede02cfbf78>
<environment: 0x5eddfd8484a8>

$Deriv
function (t, logvals, types) 
{
    whichvals <- .bincode(t, knotsmax, right = FALSE)
    partwidth <- t - knots[whichvals]
    fixedheight <- is.na(whichvals)
    whichvals <- whichvals + (types - 1) * nknots
    whichvals[fixedheight] <- partwidth[fixedheight] <- 0
    repL <- rep.int(L <- length(t), npars)
    Y <- rep.int(seq_len(npars), repL)
    Z <- rep.int(exp(logvals), repL)
    W <- rep.int(.parintwidths, repL)
    res <- ((Y > (types - 1) * nknots & (Y < whichvals | t >= 
        maxRange)) * W + (Y == whichvals) * partwidth) * Z
    dim(res) <- c(L, npars)
    res
}
<environment: 0x5eddfd8484a8>

$npars
[1] 4

$validpars
NULL

attr(,"knots")
[1] 3 7
attr(,"maxRange")
[1] 14
> # exponential temporal decay
> tiaf.exponential()
$g
function (t, alpha, types) 
{
    exp(-alpha * t)
}
<environment: base>

$G
function (t, alpha, types) 
{
    if (alpha == 0) 
        t
    else -exp(-alpha * t)/alpha
}
<environment: base>

$deriv
function (t, alpha, types) 
{
    as.matrix(-t * exp(-alpha * t))
}
<environment: base>

$Deriv
function (t, alpha, types) 
{
    as.matrix(if (alpha == 0) 
        -t^2/2
    else (t + 1/alpha) * exp(-alpha * t)/alpha)
}
<environment: base>

$npars
[1] 1

$validpars
NULL

> 
> # Type-dependent Gaussian spatial interaction function using an adaptive
> # two-dimensional midpoint-rule to integrate it over polygonal domains
> siaf.gaussian(2, F.adaptive=TRUE)
$f
function (s, pars, types) 
{
    sds <- exp(pars)
    sLengthSquared <- .rowSums(s^2, L <- nrow(s), 2L)
    types <- rep_len(types, L)
    sdss <- sds[types]
    fvals <- exp(-sLengthSquared/2/sdss^2)
    fvals
}
<environment: base>

$F
function (polydomain, f, pars, type, adapt = 0.1) 
{
    sds <- exp(pars)
    sd <- sds[type]
    eps <- adapt * sd
    intf <- polyCub.midpoint(polydomain, f, pars, type, eps = eps)
    intf
}
<environment: namespace:surveillance>

$Fcircle
function (r, pars, type) 
{
    sds <- exp(pars)
    sd <- sds[type]
    val <- pchisq((r/sd)^2, 2)
    val <- val * 2 * pi * sd^2
    val
}
<environment: namespace:stats>

$effRange
function (pars) 
{
    sds <- exp(pars)
    6 * sds
}
<environment: base>

$deriv
function (s, pars, types) 
{
    sds <- exp(pars)
    sLengthSquared <- .rowSums(s^2, L <- nrow(s), 2L)
    types <- rep_len(types, L)
    sdss <- sds[types]
    deriv <- matrix(0, L, length(pars))
    frac <- sLengthSquared/2/sdss^2
    deriv[cbind(seq_len(L), types)] <- exp(-frac) * 2 * frac
    deriv
}
<environment: base>

$Deriv
function (polydomain, deriv, pars, type, nGQ = 20L) 
{
    sds <- exp(pars)
    sd <- sds[type]
    xrange <- polydomain$xrange
    a <- min(max(abs(xrange)), sqrt(2) * sd)
    if (sum(xrange) < 0) 
        a <- -a
    deriv.type <- function(s) deriv(s, pars, type)[, type, drop = TRUE]
    int <- polyCub.SV(polydomain, deriv.type, nGQ = nGQ, alpha = a)
    res <- numeric(length(pars))
    res[type] <- int
    res
}
<environment: namespace:surveillance>

$simulate
function (n, pars, type, ub) 
{
    sds <- exp(pars)
    sd <- sds[type]
    matrix(rnorm(2 * n, mean = 0, sd = sd), nrow = n, ncol = 2L)
}
<environment: namespace:stats>

$npars
[1] 2

$validpars
NULL

> 
> # Single-type Gaussian spatial interaction function (using polyCub.iso)
> siaf.gaussian()
$f
function (s, pars, types = 1L) 
{
    sds <- exp(pars)
    sLengthSquared <- .rowSums(s^2, L <- nrow(s), 2L)
    sdss <- sds
    fvals <- exp(-sLengthSquared/2/sdss^2)
    fvals
}
<environment: base>

$F
function (polydomain, f, siafpars, type = 1L, ...) 
siaf_polyCub_iso(polydomain$bdry, "intrfr.gaussian", siafpars, 
    list(...))
<environment: namespace:surveillance>

$Fcircle
function (r, pars, type = 1L) 
{
    sds <- exp(pars)
    sd <- sds
    val <- pchisq((r/sd)^2, 2)
    val <- val * 2 * pi * sd^2
    val
}
<environment: namespace:stats>

$effRange
function (pars) 
{
    sds <- exp(pars)
    6 * sds
}
<environment: base>

$deriv
function (s, pars, types = 1L) 
{
    sds <- exp(pars)
    sLengthSquared <- .rowSums(s^2, L <- nrow(s), 2L)
    sdss <- sds
    deriv <- matrix(0, L, length(pars))
    frac <- sLengthSquared/2/sdss^2
    deriv[cbind(seq_len(L), 1L)] <- exp(-frac) * 2 * frac
    deriv
}
<environment: base>

$Deriv
function (polydomain, deriv, siafpars, type = 1L, ...) 
{
    res1 <- siaf_polyCub_iso(polydomain$bdry, "intrfr.gaussian.dlogsigma", 
        siafpars, list(...))
    c(res1)
}
<environment: namespace:surveillance>

$simulate
function (n, pars, type = 1L, ub) 
{
    sds <- exp(pars)
    sd <- sds
    matrix(rnorm(2 * n, mean = 0, sd = sd), nrow = n, ncol = 2L)
}
<environment: namespace:stats>

$npars
[1] 1

$validpars
NULL

> 
> # Exponential kernel
> siaf.exponential()
$f
function (s, logsigma, types = NULL) 
{
    sigma <- exp(logsigma)
    sLength <- sqrt(.rowSums(s^2, nrow(s), 2L))
    exp(-sLength/sigma)
}
<environment: base>

$F
function (polydomain, f, siafpars, type, ...) 
siaf_polyCub_iso(polydomain$bdry, "intrfr.exponential", siafpars, 
    list(...))
<environment: namespace:surveillance>

$Fcircle
function (r, logsigma, type = NULL) 
{
    sigma <- exp(logsigma)
    fofr <- exp(-r/sigma)
    if (fofr == 0) 
        return(2 * pi * sigma^2)
    basevolume <- pi * r^2 * fofr
    Ifinvsq <- function(z) sigma^2 * z * ((log(z) - 1)^2 + 1)
    intfinvsq <- 2 * sigma^2 - Ifinvsq(fofr)
    basevolume + pi * intfinvsq
}
<environment: base>

$deriv
function (s, logsigma, types = NULL) 
{
    sigma <- exp(logsigma)
    sLength <- sqrt(.rowSums(s^2, nrow(s), 2L))
    z <- sLength/sigma
    matrix(z * exp(-z))
}
<environment: base>

$Deriv
function (polydomain, deriv, siafpars, type, ...) 
{
    res1 <- siaf_polyCub_iso(polydomain$bdry, "intrfr.exponential.dlogsigma", 
        siafpars, list(...))
    c(res1)
}
<environment: namespace:surveillance>

$simulate
function (n, siafpars, type, ub) 
{
    stopifnot(is.finite(ub))
    normconst <- intrfr.exponential(ub, siafpars, type)
    CDF <- function(q) intrfr.exponential(q, siafpars, type)/normconst
    QF <- function(p) uniroot(function(q) CDF(q) - p, lower = 0, 
        upper = ub)$root
    r <- vapply(X = runif(n), FUN = QF, FUN.VALUE = 0, USE.NAMES = FALSE)
    theta <- runif(n, 0, 2 * pi)
    r * cbind(cos(theta), sin(theta))
}
<environment: namespace:surveillance>

$npars
[1] 1

$validpars
NULL

> 
> # Power-law kernel
> siaf.powerlaw()
$f
function (s, logpars, types = NULL) 
{
    logsigma <- logpars[[1L]]
    logd <- logpars[[2L]]
    sigma <- exp(logsigma)
    d <- exp(logd)
    sLength <- sqrt(.rowSums(s^2, nrow(s), 2L))
    (sLength + sigma)^-d
}
<environment: base>

$F
function (polydomain, f, siafpars, type, ...) 
siaf_polyCub_iso(polydomain$bdry, "intrfr.powerlaw", siafpars, 
    list(...))
<environment: namespace:surveillance>

$Fcircle
function (r, logpars, type = NULL) 
{
    logsigma <- logpars[[1L]]
    logd <- logpars[[2L]]
    sigma <- exp(logsigma)
    d <- exp(logd)
    fofr <- (r + sigma)^-d
    fof0 <- sigma^-d
    basevolume <- if (is.infinite(r)) 
        0
    else pi * r^2 * fofr
    Ifinvsq <- function(z) {
        if (d == 1) {
            -1/z - 2 * sigma * log(z) + sigma^2 * z
        }
        else if (d == 2) {
            log(z) - 4 * sigma * sqrt(z) + sigma^2 * z
        }
        else {
            z^(1 - 2/d) * d/(d - 2) - z^(1 - 1/d) * 2 * sigma * 
                d/(d - 1) + sigma^2 * z
        }
    }
    intfinvsq <- Ifinvsq(fof0) - Ifinvsq(fofr)
    basevolume + pi * intfinvsq
}
<environment: base>

$deriv
function (s, logpars, types = NULL) 
{
    logsigma <- logpars[[1L]]
    logd <- logpars[[2L]]
    sigma <- exp(logsigma)
    d <- exp(logd)
    sLength <- sqrt(.rowSums(s^2, nrow(s), 2L))
    rsigma <- sLength + sigma
    rsigmad <- rsigma^d
    derivlogsigma <- -d * sigma/rsigmad/rsigma
    derivlogd <- -d * log(rsigma)/rsigmad
    cbind(derivlogsigma, derivlogd)
}
<environment: base>

$Deriv
function (polydomain, deriv, siafpars, type, ...) 
{
    res1 <- siaf_polyCub_iso(polydomain$bdry, "intrfr.powerlaw.dlogsigma", 
        siafpars, list(...))
    res2 <- siaf_polyCub_iso(polydomain$bdry, "intrfr.powerlaw.dlogd", 
        siafpars, list(...))
    c(res1, res2)
}
<environment: namespace:surveillance>

$simulate
function (n, siafpars, type, ub) 
{
    stopifnot(is.finite(ub))
    normconst <- intrfr.powerlaw(ub, siafpars, type)
    CDF <- function(q) intrfr.powerlaw(q, siafpars, type)/normconst
    QF <- function(p) uniroot(function(q) CDF(q) - p, lower = 0, 
        upper = ub)$root
    r <- vapply(X = runif(n), FUN = QF, FUN.VALUE = 0, USE.NAMES = FALSE)
    theta <- runif(n, 0, 2 * pi)
    r * cbind(cos(theta), sin(theta))
}
<environment: namespace:surveillance>

$npars
[1] 2

$validpars
NULL

> 
> # Power-law kernel with fixed sigma = 1
> siaf.powerlaw1()
$f
function (s, logd, types = NULL, sigma = 1) 
{
    d <- exp(logd)
    sLength <- sqrt(.rowSums(s^2, nrow(s), 2L))
    (sLength + sigma)^-d
}
<environment: base>

$F
function (polydomain, f, logd, type = NULL, logsigma = 0, ...) 
{
    logpars <- c(logsigma, logd)
    siaf_polyCub_iso(polydomain$bdry, "intrfr.powerlaw", logpars, 
        list(...))
}
<environment: namespace:surveillance>

$Fcircle
function (r, logd, type = NULL, sigma = 1) 
{
    d <- exp(logd)
    fofr <- (r + sigma)^-d
    fof0 <- sigma^-d
    basevolume <- if (is.infinite(r)) 
        0
    else pi * r^2 * fofr
    Ifinvsq <- function(z) {
        if (d == 1) {
            -1/z - 2 * sigma * log(z) + sigma^2 * z
        }
        else if (d == 2) {
            log(z) - 4 * sigma * sqrt(z) + sigma^2 * z
        }
        else {
            z^(1 - 2/d) * d/(d - 2) - z^(1 - 1/d) * 2 * sigma * 
                d/(d - 1) + sigma^2 * z
        }
    }
    intfinvsq <- Ifinvsq(fof0) - Ifinvsq(fofr)
    basevolume + pi * intfinvsq
}
<environment: base>

$deriv
function (s, logd, types = NULL, sigma = 1) 
{
    d <- exp(logd)
    sLength <- sqrt(.rowSums(s^2, nrow(s), 2L))
    tmp <- -d * log(sLength + sigma)
    matrix(tmp * exp(tmp))
}
<environment: base>

$Deriv
function (polydomain, deriv, logd, type = NULL, logsigma = 0, 
    ...) 
{
    logpars <- c(logsigma, logd)
    siaf_polyCub_iso(polydomain$bdry, "intrfr.powerlaw.dlogd", 
        logpars, list(...))
}
<environment: namespace:surveillance>

$simulate
function (n, logd, type, ub, logsigma = 0) 
{
    siafpars <- c(logsigma, logd)
    stopifnot(is.finite(ub))
    normconst <- intrfr.powerlaw(ub, siafpars, type)
    CDF <- function(q) intrfr.powerlaw(q, siafpars, type)/normconst
    QF <- function(p) uniroot(function(q) CDF(q) - p, lower = 0, 
        upper = ub)$root
    r <- vapply(X = runif(n), FUN = QF, FUN.VALUE = 0, USE.NAMES = FALSE)
    theta <- runif(n, 0, 2 * pi)
    r * cbind(cos(theta), sin(theta))
}
<environment: namespace:surveillance>

$npars
[1] 1

$validpars
NULL

> 
> # "lagged" power-law
> siaf.powerlawL()
$f
function (s, logpars, types = NULL) 
{
    logsigma <- logpars[[1L]]
    logd <- logpars[[2L]]
    sigma <- exp(logsigma)
    d <- exp(logd)
    sLength <- sqrt(.rowSums(s^2, L <- length(s)/2, 2L))
    fvals <- rep.int(1, L)
    inPLrange <- which(sLength > sigma)
    fvals[inPLrange] <- (sLength[inPLrange]/sigma)^-d
    fvals
}
<environment: base>

$F
function (polydomain, f, siafpars, type, ...) 
siaf_polyCub_iso(polydomain$bdry, "intrfr.powerlawL", siafpars, 
    list(...))
<environment: namespace:surveillance>

$Fcircle
function (r, logpars, type = NULL) 
{
    logsigma <- logpars[[1L]]
    logd <- logpars[[2L]]
    sigma <- exp(logsigma)
    d <- exp(logd)
    if (r <= sigma) 
        return(pi * r^2)
    fofr <- (r/sigma)^-d
    basevolume <- pi * r^2 * fofr
    intfinvsq <- sigma^2 * if (d == 2) 
        -d * log(sigma/r)
    else {
        d/(d - 2) * (1 - (sigma/r)^(d - 2))
    }
    basevolume + pi * intfinvsq
}
<environment: base>

$deriv
function (s, logpars, types = NULL) 
{
    logsigma <- logpars[[1L]]
    logd <- logpars[[2L]]
    sigma <- exp(logsigma)
    d <- exp(logd)
    sLength <- sqrt(.rowSums(s^2, L <- length(s)/2, 2L))
    derivlogsigma <- derivlogd <- numeric(L)
    inPLrange <- which(sLength > sigma)
    fPL <- (sLength[inPLrange]/sigma)^-d
    derivlogsigma[inPLrange] <- d * fPL
    derivlogd[inPLrange] <- fPL * log(fPL)
    cbind(derivlogsigma, derivlogd)
}
<environment: base>

$Deriv
function (polydomain, deriv, siafpars, type, ...) 
{
    res1 <- siaf_polyCub_iso(polydomain$bdry, "intrfr.powerlawL.dlogsigma", 
        siafpars, list(...))
    res2 <- siaf_polyCub_iso(polydomain$bdry, "intrfr.powerlawL.dlogd", 
        siafpars, list(...))
    c(res1, res2)
}
<environment: namespace:surveillance>

$simulate
function (n, logpars, type, ub) 
{
    sigma <- exp(logpars[[1L]])
    d <- exp(logpars[[2L]])
    theta <- runif(n, 0, 2 * pi)
    if (ub < sigma) {
        r <- ub * sqrt(runif(n))
        return(r * cbind(cos(theta), sin(theta)))
    }
    mass1 <- sigma^2/2
    mass2 <- sigma^d * if (d == 2) 
        log(ub/sigma)
    else (ub^(2 - d) - sigma^(2 - d))/(2 - d)
    unir <- runif(n) <= mass1/(mass1 + mass2)
    n1 <- sum(unir)
    r1 <- sigma * sqrt(runif(n1))
    n2 <- n - n1
    r2 <- if (d == 1) 
        runif(n2, sigma, ub)
    else {
        P2inv <- if (d == 2) {
            function(z) ub^z * sigma^(1 - z)
        }
        else {
            function(z) (z * ub^(2 - d) + (1 - z) * sigma^(2 - 
                d))^(1/(2 - d))
        }
        P2inv(runif(n2))
    }
    r <- c(r1, r2)
    r * cbind(cos(theta), sin(theta))
}
<environment: namespace:stats>

$npars
[1] 2

$validpars
NULL

> 
> # (reparametrized) t-kernel
> siaf.student()
$f
function (s, logpars, types = NULL) 
{
    logsigma <- logpars[[1L]]
    logd <- logpars[[2L]]
    sigma <- exp(logsigma)
    d <- exp(logd)
    s2 <- .rowSums(s^2, nrow(s), 2L)
    (s2 + sigma^2)^-d
}
<environment: base>

$F
function (polydomain, f, siafpars, type, ...) 
siaf_polyCub_iso(polydomain$bdry, "intrfr.student", siafpars, 
    list(...))
<environment: namespace:surveillance>

$deriv
function (s, logpars, types = NULL) 
{
    logsigma <- logpars[[1L]]
    logd <- logpars[[2L]]
    sigma <- exp(logsigma)
    d <- exp(logd)
    s2 <- .rowSums(s^2, nrow(s), 2L)
    fvals <- (s2 + sigma^2)^-d
    derivlogsigma <- -2 * d * sigma^2 * fvals/(s2 + sigma^2)
    derivlogd <- log(fvals) * fvals
    cbind(derivlogsigma, derivlogd, deparse.level = 0)
}
<environment: base>

$Deriv
function (polydomain, deriv, siafpars, type, ...) 
{
    res1 <- siaf_polyCub_iso(polydomain$bdry, "intrfr.student.dlogsigma", 
        siafpars, list(...))
    res2 <- siaf_polyCub_iso(polydomain$bdry, "intrfr.student.dlogd", 
        siafpars, list(...))
    c(res1, res2)
}
<environment: namespace:surveillance>

$simulate
function (n, siafpars, type, ub) 
{
    stopifnot(is.finite(ub))
    normconst <- intrfr.student(ub, siafpars, type)
    CDF <- function(q) intrfr.student(q, siafpars, type)/normconst
    QF <- function(p) uniroot(function(q) CDF(q) - p, lower = 0, 
        upper = ub)$root
    r <- vapply(X = runif(n), FUN = QF, FUN.VALUE = 0, USE.NAMES = FALSE)
    theta <- runif(n, 0, 2 * pi)
    r * cbind(cos(theta), sin(theta))
}
<environment: namespace:surveillance>

$npars
[1] 2

$validpars
NULL

> 
> # step function kernel
> siaf.step(c(10,20,50), maxRange=100)
Loading required namespace: memoise
$f
function (s, logvals, types = NULL) 
{
    sLength <- sqrt(.rowSums(s^2, length(s)/2, 2L))
    c(1, exp(logvals), 0)[.bincode(sLength, allknots, right = FALSE)]
}
<bytecode: 0x5ede000b0c10>
<environment: 0x5eddfeeb4880>

$F
function (polydomain, f, logvals, type = NULL, npoly = 256) 
{
    sum(c(1, exp(logvals)) * ringAreas(polydomain, npoly = npoly))
}
<bytecode: 0x5ede000b1690>
<environment: 0x5eddfeeb4880>

$Fcircle
function (r, logvals, type = NULL) 
{
    sum(c(1, exp(logvals)) * pi * diff(pmin.int(allknotsPos, 
        r)^2))
}
<bytecode: 0x5ede000abe80>
<environment: 0x5eddfeeb4880>

$deriv
function (s, logvals, types = NULL) 
{
    sLength <- sqrt(.rowSums(s^2, L <- length(s)/2, 2L))
    whichvals <- .bincode(sLength, allknots, right = FALSE) - 
        1L
    Y <- rep.int(seq_len(nknots), rep.int(L, nknots))
    Z <- rep.int(exp(logvals), rep.int(L, nknots))
    deriv <- (Y == whichvals) * Z
    dim(deriv) <- c(L, nknots)
    deriv
}
<bytecode: 0x5ede000ac5f0>
<environment: 0x5eddfeeb4880>

$Deriv
function (polydomain, deriv, logvals, type = NULL, npoly = 256) 
{
    ringAreas <- ringAreas(polydomain, npoly = npoly)
    exp(logvals) * ringAreas[-1L]
}
<bytecode: 0x5eddfeeb69d0>
<environment: 0x5eddfeeb4880>

$simulate
function (n, logvals, type = NULL, ub) 
{
    upper <- min(maxRange, ub)
    knots2upper <- c(knots[knots < upper], upper)
    heights <- c(1, exp(logvals))[seq_along(knots2upper)]
    rings <- sample.int(length(heights), size = n, replace = TRUE, 
        prob = heights * diff.default(c(0, knots2upper^2)))
    runifdisc(n, knots2upper[rings], c(0, knots2upper)[rings])
}
<bytecode: 0x5eddfeeb7028>
<environment: 0x5eddfeeb4880>

$npars
[1] 3

$validpars
NULL

attr(,"knots")
[1] 10 20 50
attr(,"maxRange")
[1] 100
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("twinstim_iaf", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("twinstim_iafplot")
> ### * twinstim_iafplot
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: twinstim_iafplot
> ### Title: Plot the Spatial or Temporal Interaction Function of a
> ###   'twimstim'
> ### Aliases: iafplot
> ### Keywords: hplot aplot
> 
> ### ** Examples
> 
> data("imdepifit")
> 
> iafplot(imdepifit, "tiaf", scaled=FALSE)   # tiaf.constant(), not very exciting
> iafplot(imdepifit, "siaf", scaled=FALSE)
> 
> # scaled version uses a Monte-Carlo-CI
> set.seed(1)  # result depends on .Random.seed
> iafplot(imdepifit, "siaf", scaled=TRUE, conf.type="MC", conf.B=199,
+         col.conf=gray(0.4), conf.level=NA)  # show MC samples
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("twinstim_iafplot", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("twinstim_intensity")
> ### * twinstim_intensity
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: twinstim_intensity
> ### Title: Plotting Intensities of Infection over Time or Space
> ### Aliases: intensityplot.twinstim intensity.twinstim
> ###   intensityplot.simEpidataCS
> ### Keywords: hplot aplot dplot methods
> 
> ### ** Examples
> 
> data("imdepi", "imdepifit")
> 
> # for the intensityplot we need the model environment, which can be
> # easily added by the intelligent update method (no need to refit the model)
> imdepifit <- update(imdepifit, model=TRUE)
Setting up the model environment ...
> 
> ## path of the total intensity
> opar <- par(mfrow=c(2,1))
> intensityplot(imdepifit, which="total intensity",
+               aggregate="time", tgrid=500)
> plot(imdepi, "time", breaks=100)
> par(opar)
> 
> ## time course of the epidemic proportion by event
> intensityplot(imdepifit, which="epidemic proportion",
+               aggregate="time", tgrid=500, types=1)
> intensityplot(imdepifit, which="epidemic proportion",
+               aggregate="time", tgrid=500, types=2, add=TRUE, col=2)
> legend("topright", legend=levels(imdepi$events$type), lty=1, col=1:2,
+        title = "event type")
> 
> ## endemic and total intensity in one plot
> intensity_endprop <- intensityplot(imdepifit, which="endemic proportion",
+                                    aggregate="time", plot=FALSE)
> intensity_total <- intensityplot(imdepifit, which="total intensity",
+                                  aggregate="time", tgrid=501, lwd=2)
> curve(intensity_endprop(x) * intensity_total(x), add=TRUE, col=2, lwd=2, n=501)
> text(2500, 0.36, labels="total", col=1, pos=2, font=2)
> text(2500, 0.08, labels="endemic", col=2, pos=2, font=2)
> 
> 
> ## spatial shape of the intensity (aggregated over time)
> 
>   ## load borders of Germany's districts
>   load(system.file("shapes", "districtsD.RData", package="surveillance"))
> 
>   # total intensity (using a rather sparse 'sgrid' for speed)
>   intensityplot(imdepifit, which="total intensity",
+                 aggregate="space", tiles=districtsD, sgrid=500,
+                 col.regions=rev(heat.colors(100))) 
> 
>   # epidemic proportion by type
>   maps_epiprop <- lapply(1:2, function (type) {
+       intensityplot(imdepifit, which="epidemic", aggregate="space",
+                     types=type, tiles=districtsD, sgrid=1000,
+                     main=rownames(imdepifit$qmatrix)[type],
+                     scales=list(draw=FALSE), at=seq(0,1,by=0.1),
+                     col.regions=rev(hcl.colors(10,"YlOrRd")),
+                     colorkey=list(title=list("Epidemic proportion", cex=1)))
+   })
>   plot(maps_epiprop[[1]], split=c(1,1,2,1), more=TRUE)
>   plot(maps_epiprop[[2]], split=c(2,1,2,1))
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("twinstim_intensity", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> graphics::par(get("par.postscript", pos = 'CheckExEnv'))
> cleanEx()
> nameEx("twinstim_methods")
> ### * twinstim_methods
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: twinstim_methods
> ### Title: Print, Summary and Extraction Methods for '"twinstim"' Objects
> ### Aliases: print.twinstim summary.twinstim coeflist.twinstim
> ###   vcov.twinstim logLik.twinstim nobs.twinstim print.summary.twinstim
> ###   toLatex.summary.twinstim xtable.twinstim xtable.summary.twinstim
> ### Keywords: methods print htest
> 
> ### ** Examples
> 
> # load a fit of the 'imdepi' data, see the example in ?twinstim
> data("imdepifit")
> 
> # print method
> imdepifit

Call:
twinstim(endemic = addSeason2formula(~offset(log(popdensity)) + 
    I(start/365 - 3.5), S = 1, period = 365, timevar = "start"), 
    epidemic = ~type + agegrp, siaf = siaf.gaussian(), data = imdepi, 
    subset = !is.na(agegrp), optim.args = list(control = list(reltol = sqrt(.Machine$double.eps))), 
    model = FALSE, cumCIF = FALSE)

Coefficients:
            h.(Intercept)       h.I(start/365 - 3.5)  
                -20.52869                   -0.04574  
h.sin(2 * pi * start/365)  h.cos(2 * pi * start/365)  
                  0.21728                    0.31810  
            e.(Intercept)                    e.typeC  
                -12.51659                   -0.90832  
           e.agegrp[3,19)           e.agegrp[19,Inf)  
                  0.70612                   -0.24084  
                 e.siaf.1  
                  2.76774  

Log-likelihood: -9475

> 
> # extract point estimates (in a single vector or listed by model component)
> coef(imdepifit)
            h.(Intercept)      h.I(start/365 - 3.5) h.sin(2 * pi * start/365) 
             -20.52869499               -0.04574093                0.21728211 
h.cos(2 * pi * start/365)             e.(Intercept)                   e.typeC 
               0.31810266              -12.51659414               -0.90832081 
           e.agegrp[3,19)          e.agegrp[19,Inf)                  e.siaf.1 
               0.70611556               -0.24083969                2.76773501 
> coeflist(imdepifit)
$endemic
            h.(Intercept)      h.I(start/365 - 3.5) h.sin(2 * pi * start/365) 
             -20.52869499               -0.04574093                0.21728211 
h.cos(2 * pi * start/365) 
               0.31810266 

$epidemic
   e.(Intercept)          e.typeC   e.agegrp[3,19) e.agegrp[19,Inf) 
     -12.5165941       -0.9083208        0.7061156       -0.2408397 

$siaf
e.siaf.1 
2.767735 

$tiaf
named numeric(0)

> 
> # variance-covariance matrix of endemic parameters
> # (inverse of expected Fisher information)
> unname(vcov(imdepifit)[1:4,1:4])
              [,1]          [,2]          [,3]          [,4]
[1,]  0.0022312570  1.206606e-04 -0.0003558063 -6.247614e-04
[2,]  0.0001206606  4.891827e-04  0.0001547397 -1.969791e-05
[3,] -0.0003558063  1.547397e-04  0.0041821595 -1.598263e-04
[4,] -0.0006247614 -1.969791e-05 -0.0001598263  4.070886e-03
> 
> # the default confint() method may be used for Wald CI's
> confint(imdepifit, parm="e.typeC", level=0.95)
            2.5 %    97.5 %
e.typeC -1.432455 -0.384187
> 
> # log-likelihood and AIC of the fitted model
> logLik(imdepifit)
'log Lik.' -9474.918 (df=9)
> AIC(imdepifit)
[1] 18967.84
> nobs(imdepifit)
[1] 635
> 
> # produce a summary with parameter correlations and runtime information
> (s <- summary(imdepifit, correlation=TRUE, symbolic.cor=TRUE, runtime=TRUE))

Call:
twinstim(endemic = addSeason2formula(~offset(log(popdensity)) + 
    I(start/365 - 3.5), S = 1, period = 365, timevar = "start"), 
    epidemic = ~type + agegrp, siaf = siaf.gaussian(), data = imdepi, 
    subset = !is.na(agegrp), optim.args = list(control = list(reltol = sqrt(.Machine$double.eps))), 
    model = FALSE, cumCIF = FALSE)

Coefficients of the endemic component:
                           Estimate Std. Error  z value Pr(>|z|)    
h.(Intercept)             -20.52869    0.04724 -434.597  < 2e-16 ***
h.I(start/365 - 3.5)       -0.04574    0.02212   -2.068  0.03863 *  
h.sin(2 * pi * start/365)   0.21728    0.06467    3.360  0.00078 ***
h.cos(2 * pi * start/365)   0.31810    0.06380    4.986 6.18e-07 ***

Coefficients of the epidemic component:
                  Estimate Std. Error z value Pr(>|z|)    
e.(Intercept)    -12.51659    0.32326 -38.720  < 2e-16 ***
e.typeC           -0.90832    0.26742  -3.397 0.000682 ***
e.agegrp[3,19)     0.70612    0.32706   2.159 0.030852 *  
e.agegrp[19,Inf)  -0.24084    0.46124  -0.522 0.601563    
e.siaf.1           2.76774    0.08152      NA       NA    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

AIC:  18968
Log-likelihood: -9475
Number of log-likelihood evaluations: 14
Number of score function evaluations: 14
Runtime: 6.488 seconds

Correlation of Coefficients:
                                           
h.(Intercept)             1                
h.I(start/365 - 3.5)        1              
h.sin(2 * pi * start/365)     1            
h.cos(2 * pi * start/365)       1          
e.(Intercept)                     1        
e.typeC                             1      
e.agegrp[3,19)                    +   1    
e.agegrp[19,Inf)                  .   . 1  
e.siaf.1                          .       1
---
Corr. codes:  0 ‘ ’ 0.3 ‘.’ 0.6 ‘,’ 0.8 ‘+’ 0.9 ‘*’ 0.95 ‘B’ 1

> 
> # create LaTeX code of coefficient table
> toLatex(s, digits=2)
\begin{tabular}{lrrrr}
\hline
 & Estimate & Std. Error & $z$ value & $P(|Z|>|z|)$ \\
\hline
\hline 
 \texttt{h.(Intercept)} & $-20.529$ & $0.047$ & $-434.6$ & $<1\cdot{}10^{-04}$ \\ 
  \texttt{h.I(start/365-3.5)} & $-0.046$ & $0.022$ & $-2.1$ & $0.04$ \\ 
  \texttt{h.sin(2*pi*start/365)} & $0.217$ & $0.065$ & $3.4$ & $8\cdot{}10^{-04}$ \\ 
  \texttt{h.cos(2*pi*start/365)} & $0.318$ & $0.064$ & $5.0$ & $<1\cdot{}10^{-04}$ \\ 
  \hline 
 \texttt{e.(Intercept)} & $-12.517$ & $0.323$ & $-38.7$ & $<1\cdot{}10^{-04}$ \\ 
  \texttt{e.typeC} & $-0.908$ & $0.267$ & $-3.4$ & $7\cdot{}10^{-04}$ \\ 
  \texttt{e.agegrp[3,19)} & $0.706$ & $0.327$ & $2.2$ & $0.03$ \\ 
  \texttt{e.agegrp[19,Inf)} & $-0.241$ & $0.461$ & $-0.5$ & $0.60$ \\ 
  \texttt{e.siaf.1} & $2.768$ & $0.082$ &  &  \\ 
  \hline 
\end{tabular}
> ## Don't show: 
> .opt <- options(xtable.comment = FALSE)
> ## End(Don't show)
> # or using the xtable-method (which produces rate ratios)
> xtable(s)
\begin{table}[ht]
\centering
\begin{tabular}{lrrr}
  \hline
 & RR & 95\% CI & p-value \\ 
  \hline
h.I(start/365 - 3.5) & 0.955 & 0.91--1.00 & 0.039 \\ 
  h.sin(2 * pi * start/365) & 1.243 & 1.09--1.41 & 0.0008 \\ 
  h.cos(2 * pi * start/365) & 1.375 & 1.21--1.56 & $<$0.0001 \\ 
  e.typeC & 0.403 & 0.24--0.68 & 0.0007 \\ 
  e.agegrp[3,19) & 2.026 & 1.07--3.85 & 0.031 \\ 
  e.agegrp[19,Inf) & 0.786 & 0.32--1.94 & 0.60 \\ 
   \hline
\end{tabular}
\end{table}
> ## Don't show: 
> options(.opt)
> ## End(Don't show)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("twinstim_methods", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("twinstim_plot")
> ### * twinstim_plot
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: twinstim_plot
> ### Title: Plot methods for fitted 'twinstim"s
> ### Aliases: plot.twinstim
> ### Keywords: hplot
> 
> ### ** Examples
> 
> # see the examples for iafplot() and intensityplot.twinstim()
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("twinstim_plot", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("twinstim_profile")
> ### * twinstim_profile
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: twinstim_profile
> ### Title: Profile Likelihood Computation and Confidence Intervals for
> ###   'twinstim' objects
> ### Aliases: profile.twinstim
> ### Keywords: htest methods optimize dplot
> 
> ### ** Examples
> 
> # profiling takes a while
> ## Not run: 
> ##D #Load the twinstim model fitted to the IMD data
> ##D data("imdepi", "imdepifit")
> ##D # for profiling we need the model environment
> ##D imdepifit <- update(imdepifit, model=TRUE)
> ##D 
> ##D #Generate profiling object for a list of parameters for the new model
> ##D names <- c("h.(Intercept)","e.typeC")
> ##D coefList <- lapply(names, function(name) {
> ##D   c(pmatch(name,names(coef(imdepifit))),NA,NA,11)
> ##D })
> ##D 
> ##D #Profile object (necessary to specify a more loose convergence
> ##D #criterion). Speed things up by using do.ltildeprofile=FALSE (the default)
> ##D prof <- profile(imdepifit, coefList,
> ##D   control=list(reltol=0.1, REPORT=1), do.ltildeprofile=TRUE)
> ##D 
> ##D #Plot result for one variable
> ##D par(mfrow=c(1,2))
> ##D for (name in names) {
> ##D   with(as.data.frame(prof$lp[[name]]),
> ##D        matplot(grid,cbind(profile,estimated,wald),
> ##D                type="l",xlab=name,ylab="loglik"))
> ##D   legend(x="bottomleft",c("profile","estimated","wald"),lty=1:3,col=1:3)
> ##D }
> ## End(Not run)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("twinstim_profile", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("twinstim_siaf_simulatePC")
> ### * twinstim_siaf_simulatePC
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: siaf.simulatePC
> ### Title: Simulation from an Isotropic Spatial Kernel via Polar
> ###   Coordinates
> ### Aliases: siaf.simulatePC
> ### Keywords: internal
> 
> ### ** Examples
> 
> simfun <- siaf.powerlaw()$simulate
> ## is internally generated as siaf.simulatePC(intrfr.powerlaw)
> 
> set.seed(1)
> simfun(n=10, siafpars=log(c(sigma=1, d=2)), ub=5)
             [,1]        [,2]
 [1,]  0.34038134  1.19895527
 [2,]  0.74365537  1.49548989
 [3,] -0.98366399 -2.35478211
 [4,] -3.27846360  2.92333137
 [5,]  0.12441928 -0.99283465
 [6,] -4.32999206  0.06259911
 [7,] -0.93507686 -4.53230791
 [8,]  2.98033179 -0.15169708
 [9,] -2.05962487  1.93325995
[10,]  0.07560301 -0.43406777
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("twinstim_siaf_simulatePC", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("twinstim_simEndemicEvents")
> ### * twinstim_simEndemicEvents
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: twinstim_simEndemicEvents
> ### Title: Quick Simulation from an Endemic-Only 'twinstim'
> ### Aliases: simEndemicEvents
> ### Keywords: datagen models
> 
> ### ** Examples
> 
> data("imdepi", "imdepifit")
> load(system.file("shapes", "districtsD.RData", package="surveillance"))
> 
> ## Fit an endemic-only twinstim()
> m_noepi <- update(imdepifit, epidemic = ~0, siaf = NULL, model = TRUE,
+                   T = 120)  # using a restricted time range, for speed
marked point pattern of 2 types
no epidemic component in model

minimizing the negative log-likelihood using 'nlminb()' ...
initial parameters:
            h.(Intercept)      h.I(start/365 - 3.5) h.sin(2 * pi * start/365) 
             -20.52869499               -0.04574093                0.21728211 
h.cos(2 * pi * start/365) 
               0.31810266 
negative log-likelihood and parameters in each iteration:
  0:     615.41060: -20.5287 -0.0457409 0.217282 0.318103
  1:     613.30014: -20.5437 0.124010  1.12037 0.395413
  2:     613.24452: -19.6568 0.373041  1.09147 0.430787
  3:     613.21423:  30.7603  15.3176 -0.729385  2.29075
  4:     613.21421:  31.0758  15.4117 -0.738867  2.30508
  5:     613.21421:  31.0762  15.4119 -0.738881  2.30510

MLE:
            h.(Intercept)      h.I(start/365 - 3.5) h.sin(2 * pi * start/365) 
               31.0762030                15.4118731                -0.7388808 
h.cos(2 * pi * start/365) 
                2.3050950 
loglik(MLE) = -613.2142 

Done.
> 
> ## Simulate events from the above endemic model
> set.seed(1)
> s1 <- simEndemicEvents(m_noepi, tiles = districtsD)
> class(s1)  # just a "SpatialPointsDataFrame"
[1] "SpatialPointsDataFrame"
attr(,"package")
[1] "sp"
> summary(s1@data)
      time              tile    type  
 Min.   :  2.448   11000  : 3   B:23  
 1st Qu.: 39.161   08215  : 2   C:17  
 Median : 62.464   02000  : 1         
 Mean   : 63.507   03241  : 1         
 3rd Qu.: 87.287   03361  : 1         
 Max.   :119.966   03454  : 1         
                   (Other):31         
> plot(imdepi$W, lwd = 2, asp = 1)  
> plot(s1, col = s1$type, cex = 0.5, add = TRUE)
> 
> ## Compare with the generic simulation method (slower)
> s0 <- simulate(m_noepi, seed = 1, data = imdepi, tiles = districtsD)

Checking the supplied arguments ...
(no events from 'data$events' were considered as prehistory)

Simulating a spatio-temporal point pattern with 
	- 2 event types 
	- no prehistory
	- 4 coefficients:

            h.(Intercept)      h.I(start/365 - 3.5) h.sin(2 * pi * start/365) 
               31.0762030                15.4118731                -0.7388808 
h.cos(2 * pi * start/365) 
                2.3050950 

Simulating (starting from t=0) ...
Simulation has ended @t = 120 with 54 simulated events.

Preparing simulated events for "epidataCS" ...
Done.
> class(s0)  # gives a full "simEpidataCS" with several methods applicable
[1] "simEpidataCS" "epidataCS"   
> methods(class = "epidataCS")
 [1] [           animate     as.epidata  as.stepfun  coerce      head       
 [7] initialize  marks       nobs        plot        print       show       
[13] slotsFromS3 subset      summary     tail        untie       update     
see '?methods' for accessing help and source code
> plot(s0, "time")
> plot(s0, "space", points.args = list(pch = 3), lwd = 2)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("twinstim_simEndemicEvents", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("twinstim_simulation")
> ### * twinstim_simulation
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: twinstim_simulation
> ### Title: Simulation of a Self-Exciting Spatio-Temporal Point Process
> ### Aliases: simEpidataCS simulate.twinstim
> ### Keywords: datagen models
> 
> ### ** Examples
> 
> data("imdepi", "imdepifit")
> 
> ## load borders of Germany's districts (originally obtained from
> ## the German Federal Agency for Cartography and Geodesy,
> ## https://gdz.bkg.bund.de/), simplified by the "modified Visvalingam"
> ## algorithm (level=6.6%) using MapShaper.org (v. 0.1.17):
> load(system.file("shapes", "districtsD.RData", package="surveillance"))
> if (surveillance.options("allExamples")) {
+   plot(districtsD)
+   plot(stateD, add=TRUE, border=2, lwd=2)
+ }
> 
> ## simulate 2 realizations (over a short period, for speed)
> ## considering events from data(imdepi) before t=31 as prehistory
> ## IGNORE_RDIFF_BEGIN
> mysims <- simulate(imdepifit, nsim=2, seed=1, data=imdepi,
+                    tiles=districtsD, newcoef=c("e.typeC"=-1),
+                    t0=31, T=if (interactive()) 180 else 45, # for CRAN
+                    simplify=TRUE)

Time at beginning of simulation: 2024-09-02 16:55:03.880373 
Simulation 1 / 2 ...
-------------------------------------------------------------------------------

Checking the supplied arguments ...

Simulating a marked spatio-temporal point pattern with 
	- 2 event types 
	- 4 events in the prehistory
	- 9 coefficients:

            h.(Intercept)      h.I(start/365 - 3.5) h.sin(2 * pi * start/365) 
             -20.52869499               -0.04574093                0.21728211 
h.cos(2 * pi * start/365)             e.(Intercept)                   e.typeC 
               0.31810266              -12.51659414               -1.00000000 
           e.agegrp[3,19)          e.agegrp[19,Inf)                  e.siaf.1 
               0.70611556               -0.24083969                2.76773501 

Simulating (starting from t=31) ...
Simulation has ended @t = 45 with 3 simulated events.

Preparing simulated events for "epidataCS" ...
Done.

-------------------------------------------------------------------------------
Runtime of first simulation: 0.097 seconds
Estimated finishing time: 2024-09-02 16:55:04.074785 

Simulation 2 / 2 ...	simulated 5 events up to time 45 

Done (2024-09-02 16:55:04.256737).
> ## IGNORE_RDIFF_END
> ## Don't show: 
>     ## check construction and selection from "simEpidataCSlist"
>     local({
+         mysim_from_list <- mysims[[1]]
+         capture.output(mysim_single <- eval("[[<-"(attr(mysims, "call"), "nsim", 1)))
+         mysim_from_list$runtime <- mysim_single$runtime <- NULL
+         stopifnot(all.equal(mysim_single, mysim_from_list,
+                             check.attributes = FALSE))
+     })
>     ## check equivalence of Lambdag from simulation and residuals via twinstim
>     stopifnot(all.equal(
+         residuals(mysims[[1]]),
+         suppressMessages(surveillance:::residuals.twinstim(surveillance:::as.twinstim.simEpidataCS(mysims[[1]])))
+     ))
> ## End(Don't show)
> 
> ## plot both simulations using the plot-method for simEpidataCSlist's
> mysims

Call:
simulate.twinstim(object = imdepifit, nsim = 2, seed = 1, data = imdepi, 
    tiles = districtsD, newcoef = c(e.typeC = -1), t0 = 31, T = if (interactive()) 180 else 45, 
    simplify = TRUE)

Simplified list of 2 simulated epidemics of class "simEpidataCS" (not printed)

> plot(mysims, aggregate="time")
Note: ignoring events of the prehistory (before "stgrid")
Note: ignoring events of the prehistory (before "stgrid")
> 
> ## extract the second realization -> object of class simEpidataCS
> mysim2 <- mysims[[2]]
> summary(mysim2)
Observation period: 31 - 45 
Observation window (bounding box): [4031.295, 4672.253] x [2684.102, 3549.931] 
Spatio-temporal grid (not shown): 1 time block, x 413 tiles 
Overall number of events: 9 (2 types, prehistory: 4)

Summary of event marks and number of potential sources:
      time             tile   type      eps.t        eps.s         sex   
 Min.   : 5.591   01053  :1   B:4   Min.   :30   Min.   :200   female:2  
 1st Qu.:22.060   03454  :1   C:5   1st Qu.:30   1st Qu.:200   male  :7  
 Median :32.453   05113  :1         Median :30   Median :200             
 Mean   :26.805   05170  :1         Mean   :30   Mean   :200             
 3rd Qu.:35.257   05314  :1         3rd Qu.:30   3rd Qu.:200             
 Max.   :43.459   05554  :1         Max.   :30   Max.   :200             
                  (Other):3                                              
      agegrp      source     lambda.h        lambda.e    Lambdag      
 [0,3)   :2   Min.   :0   Min.   :0e+00   Min.   :0   Min.   :0.5326  
 [3,19)  :5   1st Qu.:0   1st Qu.:0e+00   1st Qu.:0   1st Qu.:0.9549  
 [19,Inf):2   Median :0   Median :0e+00   Median :0   Median :1.5766  
              Mean   :0   Mean   :2e-06   Mean   :0   Mean   :1.9560  
              3rd Qu.:0   3rd Qu.:5e-06   3rd Qu.:0   3rd Qu.:2.1333  
              Max.   :0   Max.   :6e-06   Max.   :0   Max.   :4.5828  
              NA's   :4   NA's   :4       NA's   :4   NA's   :4       
       x              y          |.sources|    
 Min.   :4090   Min.   :2742   Min.   :0.0000  
 1st Qu.:4115   1st Qu.:2916   1st Qu.:0.0000  
 Median :4134   Median :3143   Median :0.0000  
 Mean   :4224   Mean   :3092   Mean   :0.4444  
 3rd Qu.:4360   3rd Qu.:3223   3rd Qu.:0.0000  
 Max.   :4463   Max.   :3370   Max.   :2.0000  
                                               
> plot(mysim2, aggregate="space")
> 
> 
> ### compare the observed _cumulative_ number of cases in the first 90 days to
> nsim <- 20
> ### simulations from the fitted model
> ## Don't show: 
> if (!interactive()) nsim <- 2
> ## End(Don't show)
> sims <- simulate(imdepifit, nsim=nsim, seed=1, data=imdepi, t0=0, T=90,
+                  tiles=districtsD, simplify=TRUE)

Time at beginning of simulation: 2024-09-02 16:55:04.390162 
Simulation 1 / 2 ...
-------------------------------------------------------------------------------

Checking the supplied arguments ...
(no events from 'data$events' were considered as prehistory)

Simulating a marked spatio-temporal point pattern with 
	- 2 event types 
	- no prehistory
	- 9 coefficients:

            h.(Intercept)      h.I(start/365 - 3.5) h.sin(2 * pi * start/365) 
             -20.52869499               -0.04574093                0.21728211 
h.cos(2 * pi * start/365)             e.(Intercept)                   e.typeC 
               0.31810266              -12.51659414               -0.90832081 
           e.agegrp[3,19)          e.agegrp[19,Inf)                  e.siaf.1 
               0.70611556               -0.24083969                2.76773501 

Simulating (starting from t=0) ...
Simulation has ended @t = 90 with 35 simulated events.

Preparing simulated events for "epidataCS" ...
Done.

-------------------------------------------------------------------------------
Runtime of first simulation: 0.45 seconds
Estimated finishing time: 2024-09-02 16:55:05.289979 

Simulation 2 / 2 ...	simulated 21 events up to time 90 

Done (2024-09-02 16:55:05.309639).
> 
> ## extract cusums
> getcsums <- function (events) {
+     tapply(events$time, events@data["type"],
+            function (t) cumsum(table(t)), simplify=FALSE)
+ }
> csums_observed <- getcsums(imdepi$events)
> csums_simulated <- lapply(sims$eventsList, getcsums)
> 
> ## plot it
> plotcsums <- function (csums, ...) {
+     mapply(function (csum, ...) lines(as.numeric(names(csum)), csum, ...),
+            csums, ...)
+     invisible()
+ }
> plot(c(0,90), c(0,35), type="n", xlab="Time [days]",
+      ylab="Cumulative number of cases")
> plotcsums(csums_observed, col=c(2,4), lwd=3)
> legend("topleft", legend=levels(imdepi$events$type), col=c(2,4), lwd=1)
> invisible(lapply(csums_simulated, plotcsums,
+                  col=adjustcolor(c(2,4), alpha.f=0.5)))
> 
> 
> ## Not run: 
> ##D ### Experimental code to generate 'nsim' simulations of 'nm2add' months
> ##D ### beyond the observed time period:
> ##D nm2add <- 24
> ##D nsim <- 5
> ##D ### The events still infective by the end of imdepi$stgrid will be used
> ##D ### as the prehistory for the continued process.
> ##D 
> ##D origT <- tail(imdepi$stgrid$stop, 1)
> ##D ## extend the 'stgrid' by replicating the last block 'nm2add' times
> ##D ## (i.e., holding "popdensity" constant)
> ##D stgridext <- local({
> ##D     gLast <- subset(imdepi$stgrid, BLOCK == max(BLOCK))
> ##D     gAdd <- gLast[rep(1:nrow(gLast), nm2add),]; rownames(gAdd) <- NULL
> ##D     newstart <- seq(origT, by=30, length.out=nm2add)
> ##D     newstop <- c(newstart[-1], max(newstart) + 30)
> ##D     gAdd$start <- rep(newstart, each=nlevels(gAdd$tile))
> ##D     gAdd$stop <- rep(newstop, each=nlevels(gAdd$tile))
> ##D     rbind(imdepi$stgrid, gAdd, make.row.names = FALSE)[,-1]
> ##D })
> ##D ## create an updated "epidataCS" with the time-extended 'stgrid'
> ##D imdepiext <- update(imdepi, stgrid = stgridext)
> ##D newT <- tail(imdepiext$stgrid$stop, 1)
> ##D 
> ##D ## simulate beyond the original period
> ##D simsext <- simulate(imdepifit, nsim=nsim, seed=1, t0=origT, T=newT,
> ##D                     data=imdepiext, tiles=districtsD, simplify=TRUE)
> ##D 
> ##D ## Aside to understand the note from checking events and tiles:
> ##D # marks(imdepi)["636",]  # tile 09662 is attributed to this event, but:
> ##D # plot(districtsD[c("09678","09662"),], border=1:2, lwd=2, axes=TRUE)
> ##D # points(imdepi$events["636",])
> ##D ## this mismatch is due to polygon simplification
> ##D 
> ##D ## plot the observed and simulated event numbers over time
> ##D plot(imdepiext, breaks=c(unique(imdepi$stgrid$start),origT),
> ##D      cumulative=list(maxat=330))
> ##D for (i in seq_along(simsext$eventsList))
> ##D     plot(simsext[[i]], add=TRUE, legend.types=FALSE,
> ##D          breaks=c(unique(simsext$stgrid$start),newT),
> ##D          subset=!is.na(source),  # have to exclude the events of the prehistory
> ##D          cumulative=list(offset=c(table(imdepi$events$type)), maxat=330, axis=FALSE),
> ##D          border=NA, density=0)  # no histogram
> ##D abline(v=origT, lty=2, lwd=2)
> ##D 
> ## End(Not run)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("twinstim_simulation", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("twinstim_step")
> ### * twinstim_step
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: twinstim_step
> ### Title: Stepwise Model Selection by AIC
> ### Aliases: stepComponent add1.twinstim drop1.twinstim
> ### Keywords: models methods
> 
> ### ** Examples
> 
> data("imdepi", "imdepifit")
> 
> ## simple baseline model
> m0 <- update(imdepifit, epidemic=~1, siaf=NULL)
marked point pattern of 2 types
updating list of potential sources ...
assuming constant spatial interaction 'siaf.constant()'
assuming constant temporal interaction 'tiaf.constant()'

minimizing the negative log-likelihood using 'nlminb()' ...
initial parameters:
            h.(Intercept)      h.I(start/365 - 3.5) h.sin(2 * pi * start/365) 
             -20.52869499               -0.04574093                0.21728211 
h.cos(2 * pi * start/365)             e.(Intercept) 
               0.31810266              -12.51659414 
negative log-likelihood and parameters in each iteration:
  0:     14133.266: -20.5287 -0.0457409 0.217282 0.318103 -12.5166
  1:     11076.678: -20.5701 -0.0310564 0.208698 0.309972 -13.4245
  2:     9983.2567: -20.6411 -0.0189200 0.193150 0.297816 -14.3306
  3:     9647.4312: -20.6949 -0.0296824 0.177116 0.297946 -15.2505
  4:     9575.8472: -20.5511 -0.0416673 0.213118 0.347406 -16.2197
  5:     9570.1582: -20.4719 -0.0408482 0.244762 0.350597 -16.8328
  6:     9570.0589: -20.4810 -0.0409010 0.241569 0.350774 -16.8975
  7:     9570.0589: -20.4810 -0.0409027 0.241609 0.350495 -16.8972

MLE:
            h.(Intercept)      h.I(start/365 - 3.5) h.sin(2 * pi * start/365) 
             -20.48097919               -0.04090266                0.24160901 
h.cos(2 * pi * start/365)             e.(Intercept) 
               0.35049475              -16.89716012 
loglik(MLE) = -9570.059 

Done.
> 
> ## AIC-based step-wise backward selection of the endemic component
> m0_step <- stepComponent(m0, "endemic", scope=list(lower=~I(start/365-3.5)))
Start:  AIC=19150.12
~offset(log(popdensity)) + I(start/365 - 3.5) + sin(2 * pi * 
    start/365) + cos(2 * pi * start/365)

trying -sin(2 * pi * start/365)
trying -cos(2 * pi * start/365)
                          Df   AIC
<none>                       19150
- sin(2 * pi * start/365)  1 19162
- cos(2 * pi * start/365)  1 19178
> ## nothing is dropped from the model
> 
> ## Don't show: 
> m0_step$anova <- NULL
> stopifnot(identical(m0, m0_step))
> ## End(Don't show)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("twinstim_step", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("twinstim_update")
> ### * twinstim_update
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: twinstim_update
> ### Title: 'update'-method for '"twinstim"'
> ### Aliases: update.twinstim
> ### Keywords: models methods
> 
> ### ** Examples
> 
> data("imdepi", "imdepifit")
> 
> ## add another epidemic covariate
> ## (but fix siaf-parameter so that this example runs quickly)
> imdepifit2 <- update(imdepifit, epidemic = ~. + log(popdensity),
+                      optim.args = list(fixed="e.siaf.1"))
marked point pattern of 2 types
updating list of potential sources ...
assuming constant temporal interaction 'tiaf.constant()'

fixed parameters during optimization:
e.siaf.1 
2.767735 
pre-evaluating 'siaf' integrals with fixed parameters ...

minimizing the negative log-likelihood using 'nlminb()' ...
initial parameters:
            h.(Intercept)      h.I(start/365 - 3.5) h.sin(2 * pi * start/365) 
             -20.52869499               -0.04574093                0.21728211 
h.cos(2 * pi * start/365)             e.(Intercept)                   e.typeC 
               0.31810266              -12.51659414               -0.90832081 
           e.agegrp[3,19)          e.agegrp[19,Inf)         e.log(popdensity) 
               0.70611556               -0.24083969                0.00000000 
negative log-likelihood and parameters in each iteration:
  0:     9474.9175: -20.5287 -0.0457409 0.217282 0.318103 -12.5166 -0.908321 0.706116 -0.240840  0.00000
  1:     9473.4254: -20.5330 -0.0455406 0.217504 0.318555 -13.3940 -0.841016 0.607922 -0.380855 0.153688
  2:     9473.3675: -20.5329 -0.0453648 0.217693 0.318373 -13.8130 -0.802286 0.726754 -0.282393 0.202383
  3:     9473.3276: -20.5322 -0.0454086 0.217748 0.318156 -13.6401 -0.844498 0.737156 -0.252909 0.174743
  4:     9473.3268: -20.5325 -0.0453998 0.217689 0.318182 -13.6633 -0.840718 0.726770 -0.268530 0.180169
  5:     9473.3264: -20.5324 -0.0454111 0.217679 0.318166 -13.6336 -0.844072 0.727926 -0.264191 0.175397
  6:     9473.3263: -20.5324 -0.0454084 0.217675 0.318176 -13.6433 -0.842295 0.726177 -0.267047 0.177159
  7:     9473.3263: -20.5324 -0.0454089 0.217677 0.318174 -13.6411 -0.842558 0.726667 -0.266376 0.176737

MLE:
            h.(Intercept)      h.I(start/365 - 3.5) h.sin(2 * pi * start/365) 
             -20.53241768               -0.04540888                0.21767699 
h.cos(2 * pi * start/365)             e.(Intercept)                   e.typeC 
               0.31817435              -13.64114144               -0.84255760 
           e.agegrp[3,19)          e.agegrp[19,Inf)         e.log(popdensity) 
               0.72666680               -0.26637601                0.17673722 
loglik(MLE) = -9473.326 

Done.
> 
> ## compare by AIC
> AIC(imdepifit, imdepifit2)
           df      AIC
imdepifit   9 18967.84
imdepifit2 10 18966.65
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("twinstim_update", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("unionSpatialPolygons")
> ### * unionSpatialPolygons
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: unionSpatialPolygons
> ### Title: Compute the Unary Union of '"SpatialPolygons"'
> ### Aliases: unionSpatialPolygons
> ### Keywords: spatial
> 
> ### ** Examples
> 
> ## Load districts of Germany
> load(system.file("shapes", "districtsD.RData", package = "surveillance"))
> plot(districtsD, border = "gray", asp = 1)  
> 
> ## Union these districts using either "sf" or "polyclip"
> if (requireNamespace("sf"))  {
+     stateD <- unionSpatialPolygons(districtsD, method = "sf")
+     plot(stateD, add = TRUE, border = 2, lwd = 2)
+ }
> if (requireNamespace("polyclip")) {
+     stateD_pc <- unionSpatialPolygons(districtsD, method = "polyclip")
+     plot(stateD_pc, add = TRUE, border = 1, lwd = 2, lty = 2)
+ }
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("unionSpatialPolygons", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("untie")
> ### * untie
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: untie
> ### Title: Randomly Break Ties in Data
> ### Aliases: untie untie.epidataCS untie.matrix untie.default
> ### Keywords: utilities manip dplot
> 
> ### ** Examples
> 
> # vector example
> set.seed(123)
> untie(c(rep(1,3), rep(1.2, 4), rep(3,3)), direction="left", sort=FALSE)
 [1] 0.9424845 0.8423390 0.9182046 1.0233965 1.0119065 1.1908887 1.0943789
 [8] 2.8215162 2.8897130 2.9086771
> 
> # spatial example
> data(imdepi)
> coords <- coordinates(imdepi$events)
> table(duplicated(coords))

FALSE  TRUE 
  509   127 
> plot(coords, cex=sqrt(multiplicity(coords)))
> set.seed(1)
> coords_untied <- untie(coords)
> stopifnot(!anyDuplicated(coords_untied))
> points(coords_untied, col=2) # shifted by very small amount in this case
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("untie", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("zetaweights")
> ### * zetaweights
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: zetaweights
> ### Title: Power-Law Weights According to Neighbourhood Order
> ### Aliases: zetaweights
> ### Keywords: spatial utilities
> 
> ### ** Examples
> 
> nbmat <- matrix(c(0,1,2,2,
+                   1,0,1,1,
+                   2,1,0,2,
+                   2,1,2,0), 4, 4, byrow=TRUE)
> zetaweights(nbmat, d=1, normalize=FALSE) # harmonic: o^-1
     [,1] [,2] [,3] [,4]
[1,]  0.0    1  0.5  0.5
[2,]  1.0    0  1.0  1.0
[3,]  0.5    1  0.0  0.5
[4,]  0.5    1  0.5  0.0
> zetaweights(nbmat, d=1, normalize=TRUE)  # rowSums=1
          [,1] [,2]      [,3]      [,4]
[1,] 0.0000000  0.5 0.2500000 0.2500000
[2,] 0.3333333  0.0 0.3333333 0.3333333
[3,] 0.2500000  0.5 0.0000000 0.2500000
[4,] 0.2500000  0.5 0.2500000 0.0000000
> zetaweights(nbmat, maxlag=1, normalize=FALSE) # results in adjacency matrix
     [,1] [,2] [,3] [,4]
[1,]    0    1    0    0
[2,]    1    0    1    1
[3,]    0    1    0    0
[4,]    0    1    0    0
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("zetaweights", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> ### * <FOOTER>
> ###
> cleanEx()
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  52.443 0.771 54.067 1.331 0.14 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
